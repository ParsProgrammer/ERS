{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrzVYQNxJm_W",
        "outputId": "8f98d417-6c2d-47ff-a041-84238103eba9"
      },
      "outputs": [],
      "source": [
        "#%pip install tensorflow-gpu==2.9\n",
        "#%pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BTOV54y-ckzq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1u4wpNQOEUc9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import gc\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTkARkSuo9PR",
        "outputId": "8548446d-69cd-4727-8b8f-851569dd33d5"
      },
      "outputs": [],
      "source": [
        "#%pip install gensim==4.2\n",
        "#%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnDuJU4fpMLE",
        "outputId": "ecfd7d10-b929-43ce-cd99-0e2213f4e376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mobin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 11:38:37.842255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:37.861142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:37.861308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:37.862166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 11:38:37.863496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:37.863652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:37.863761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:38.166647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:38.166806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:38.166926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-16 11:38:38.167020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2132 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install tensorboard\n",
        "# %pip install -U tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tf.config.optimizer.set_jit(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyypFCrlw2SV"
      },
      "source": [
        "# **Data Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p7IbgFIxRQb-"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    name=b'\"verified\": \\\"true\\\",'\n",
        "    l=l.replace(b'\"verified\": true,',bytes(name))\n",
        "    name1=b'\"verified\": \\\"false\\\",'\n",
        "    l=l.replace(b'\"verified\": false,',bytes(name))\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('/home/mobin/Downloads/reviews_Grocery_and_Gourmet_Food_5.json.gz')\n",
        "\n",
        "# dataset link\n",
        "# Grocery and Gourmet Food\n",
        "# https://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_auxwvSRYsvu"
      },
      "source": [
        "Dataset Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E9FGFZINRQOn",
        "outputId": "0dad1216-9ec6-4528-fa44-32ab26a94602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151249</th>\n",
              "      <td>A2L6QS8SVHT9RG</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>Delicious gluten-free oatmeal: we tried both t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151250</th>\n",
              "      <td>AFJFXN42RZ3G2</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>With the many selections of instant oatmeal ce...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151251</th>\n",
              "      <td>ASEBX8TBYWQWA</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>While I usually review CDs and DVDs, as well a...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151252</th>\n",
              "      <td>ANKQGTXHREOI5</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>My son and I enjoyed these oatmeal packets.  H...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151253</th>\n",
              "      <td>A2CF66KIQ3RKX3</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>I like to eat oatmeal i the mornings. I usuall...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151254 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userID      itemID  \\\n",
              "0       A1VEELTKS8NLZB  616719923X   \n",
              "1       A14R9XMZVJ6INB  616719923X   \n",
              "2       A27IQHDZFQFNGG  616719923X   \n",
              "3       A31QY5TASILE89  616719923X   \n",
              "4       A2LWK003FFMCI5  616719923X   \n",
              "...                ...         ...   \n",
              "151249  A2L6QS8SVHT9RG  B00KCJRVO2   \n",
              "151250   AFJFXN42RZ3G2  B00KCJRVO2   \n",
              "151251   ASEBX8TBYWQWA  B00KCJRVO2   \n",
              "151252   ANKQGTXHREOI5  B00KCJRVO2   \n",
              "151253  A2CF66KIQ3RKX3  B00KCJRVO2   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "151249  Delicious gluten-free oatmeal: we tried both t...     4.0  \n",
              "151250  With the many selections of instant oatmeal ce...     4.0  \n",
              "151251  While I usually review CDs and DVDs, as well a...     5.0  \n",
              "151252  My son and I enjoyed these oatmeal packets.  H...     4.0  \n",
              "151253  I like to eat oatmeal i the mornings. I usuall...     4.0  \n",
              "\n",
              "[151254 rows x 4 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\",\"overall\":\"rating\"},inplace=True)\n",
        "df=df[['userID','itemID','reviewText','rating']]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 15126  15127  15128 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 136126 136127 136128] 136129\n"
          ]
        }
      ],
      "source": [
        "current_fold=10\n",
        "kfold = KFold(10)\n",
        "random_iterator=kfold.split(df)\n",
        "for i in range(current_fold):\n",
        "  train_index, test_index = next(random_iterator, None)\n",
        "  print(train_index,len(train_index))\n",
        "  train_df, test_df =df.iloc[train_index], df.iloc[test_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136124</th>\n",
              "      <td>A74CGCGJ11Y23</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I've made rice pilaf from scratch. I've also t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136125</th>\n",
              "      <td>A36MP37DITBU6F</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This is a slightly mild flavored rice pilaf. t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136126</th>\n",
              "      <td>A1JBBR4MNGQ70G</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I added a package of Albacore tuna to this mix...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136127</th>\n",
              "      <td>A2P739KOM4U5JB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I am happy to report that Side Mates were grea...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136128</th>\n",
              "      <td>AT53ZTTO707MB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This was a nice combo of rice, pasta and herbs...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136129 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userID      itemID  \\\n",
              "0       A1VEELTKS8NLZB  616719923X   \n",
              "1       A14R9XMZVJ6INB  616719923X   \n",
              "2       A27IQHDZFQFNGG  616719923X   \n",
              "3       A31QY5TASILE89  616719923X   \n",
              "4       A2LWK003FFMCI5  616719923X   \n",
              "...                ...         ...   \n",
              "136124   A74CGCGJ11Y23  B009M516NE   \n",
              "136125  A36MP37DITBU6F  B009M516NE   \n",
              "136126  A1JBBR4MNGQ70G  B009M516NE   \n",
              "136127  A2P739KOM4U5JB  B009M516NE   \n",
              "136128   AT53ZTTO707MB  B009M516NE   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "136124  I've made rice pilaf from scratch. I've also t...     4.0  \n",
              "136125  This is a slightly mild flavored rice pilaf. t...     4.0  \n",
              "136126  I added a package of Albacore tuna to this mix...     3.0  \n",
              "136127  I am happy to report that Side Mates were grea...     4.0  \n",
              "136128  This was a nice combo of rice, pasta and herbs...     3.0  \n",
              "\n",
              "[136129 rows x 4 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYb9dMRLXjZT"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yY4NJsolgtl"
      },
      "source": [
        "**User Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9kPFQ1GJr_I"
      },
      "source": [
        "determining all unique users with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "l_eSbOjWRQD3",
        "outputId": "63fd7abe-5957-46a2-aa85-8ca3721bdec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00177463W0XWB16A9O05</td>\n",
              "      <td>[It is a good stand by coffee you can count on...</td>\n",
              "      <td>[5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A022899328A0QROR32DCT</td>\n",
              "      <td>[awesome texture for even the gluten eating ea...</td>\n",
              "      <td>[5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 1.0, 2.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A04309042SDSL8YX2HRR7</td>\n",
              "      <td>[I love roasted garlic &amp; sweet bell peppers. Y...</td>\n",
              "      <td>[5.0, 2.0, 4.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A068255029AHTHDXZURNU</td>\n",
              "      <td>[These bars are especially delicious for cocon...</td>\n",
              "      <td>[5.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A06944662TFWOKKV4GJKX</td>\n",
              "      <td>[UGH!  My stomach has been really killing me l...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14676</th>\n",
              "      <td>AZWRZZAMX90VT</td>\n",
              "      <td>[Very nice. Not spicy, not too salty, lots of ...</td>\n",
              "      <td>[5.0, 5.0, 2.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14677</th>\n",
              "      <td>AZXKAH2DE6C8A</td>\n",
              "      <td>[Could not imagine having such a rich tasting ...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14678</th>\n",
              "      <td>AZXON596A1VXC</td>\n",
              "      <td>[I was a bit skeptical when I bought this prod...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14679</th>\n",
              "      <td>AZYXC63SS008M</td>\n",
              "      <td>[This is just about the healthiest you can get...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14680</th>\n",
              "      <td>AZZ5ASC403N74</td>\n",
              "      <td>[Everybody loves homemade spaghetti sauce, but...</td>\n",
              "      <td>[5.0, 2.0, 3.0, 3.0, 4.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14681 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      userID  \\\n",
              "0      A00177463W0XWB16A9O05   \n",
              "1      A022899328A0QROR32DCT   \n",
              "2      A04309042SDSL8YX2HRR7   \n",
              "3      A068255029AHTHDXZURNU   \n",
              "4      A06944662TFWOKKV4GJKX   \n",
              "...                      ...   \n",
              "14676          AZWRZZAMX90VT   \n",
              "14677          AZXKAH2DE6C8A   \n",
              "14678          AZXON596A1VXC   \n",
              "14679          AZYXC63SS008M   \n",
              "14680          AZZ5ASC403N74   \n",
              "\n",
              "                                              reviewText  \\\n",
              "0      [It is a good stand by coffee you can count on...   \n",
              "1      [awesome texture for even the gluten eating ea...   \n",
              "2      [I love roasted garlic & sweet bell peppers. Y...   \n",
              "3      [These bars are especially delicious for cocon...   \n",
              "4      [UGH!  My stomach has been really killing me l...   \n",
              "...                                                  ...   \n",
              "14676  [Very nice. Not spicy, not too salty, lots of ...   \n",
              "14677  [Could not imagine having such a rich tasting ...   \n",
              "14678  [I was a bit skeptical when I bought this prod...   \n",
              "14679  [This is just about the healthiest you can get...   \n",
              "14680  [Everybody loves homemade spaghetti sauce, but...   \n",
              "\n",
              "                                                  rating  \n",
              "0      [5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, ...  \n",
              "1      [5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 1.0, 2.0, 3.0, ...  \n",
              "2                              [5.0, 2.0, 4.0, 4.0, 4.0]  \n",
              "3          [5.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 5.0]  \n",
              "4          [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0]  \n",
              "...                                                  ...  \n",
              "14676  [5.0, 5.0, 2.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, ...  \n",
              "14677  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, ...  \n",
              "14678                [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "14679                     [5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "14680                          [5.0, 2.0, 3.0, 3.0, 4.0]  \n",
              "\n",
              "[14681 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_df=df[['userID','reviewText','rating']].groupby('userID')['rating','reviewText'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['rating'])],index=['reviewText', 'rating'])).reset_index()\n",
        "user_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frXwp0g9RxQa",
        "outputId": "e64ec82c-1531-4930-aa50-9666b627ee3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['It is a good stand by coffee you can count on.  I would reley on it for the daily use catagory.', 'I like the &#34;wake up&#34; factor of this blend.  I could drink it all day long and never get tired of it.', 'I am pleased with the brew, but not enthused.  I have had better for the price, but its ok. Thats it', 'Much better than the Daybreak blend.  Much Bolder taste and better richness.  Could be a lil fresher though.  I would buy it again at lower price.', 'ypiuy y yu 8t 8t o t875t9t uf5o g r6  t9 t7r rf8y0[8uyr  d8oy p0t8y 897 77u7td8t 7t 7ty yr f8', 'It is an ok tea,not the best or worst.  It seems a lil weak if you ask me.  I wish it had a stronger taste!', 'I really went through this off brand coffee.  I found it in the corner of the site,give it a try!It is a great value,and will get it in the future.', 'Impressed with the price and taste of this coffee.  I also like the lower price compared with the competition. Winner!', 'I love the packaging and brew of this coffee.  Yes works great in the Keurig.  I like the organic brew.  Certainly taste the difference!', 'I really like this coffee.  It has a very unique taste ,and comes in a heavy box,which I like how it is dispensed.', 'Love the packaging of this coffee. Seems to brew just fine with the Keurig.  I think it has a great taste and should be part of my norm.  Hope others will support organic coffee! (-:', 'I received this coffee for the first time.  Has a good full flavor and peps you up! I will but on some Raggie and jam on it!', 'Its ok, not much of a choc kinda freak. Not my cup of tea really.  Might be asking the wrong person.']\n",
            "[5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0]\n"
          ]
        }
      ],
      "source": [
        "print(user_df['reviewText'][0])\n",
        "print(user_df['rating'][0])\n",
        "# user_df.loc[0][1] --->the same as above code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAbgOc7q3Tp"
      },
      "source": [
        "**Item Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arvKphT7KCTg"
      },
      "source": [
        "determining all unique items with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "qAjW8mmJq9Cj",
        "outputId": "e03f94a0-8923-417b-c9c0-fd8cd33ea676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>616719923X</td>\n",
              "      <td>[Just another flavor of Kit Kat but the taste ...</td>\n",
              "      <td>[4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9742356831</td>\n",
              "      <td>[This curry paste makes a delicious curry.  I ...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B00004S1C5</td>\n",
              "      <td>[These dyes create awesome colors for kids cra...</td>\n",
              "      <td>[5.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0000531B7</td>\n",
              "      <td>[I really enjoy these bars as a quick breakfas...</td>\n",
              "      <td>[5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00005344V</td>\n",
              "      <td>[Traditional Medicinals' \"Breathe Easy\" is an ...</td>\n",
              "      <td>[5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8708</th>\n",
              "      <td>B00JGPG60I</td>\n",
              "      <td>[We switched to this formula 5 days ago and fo...</td>\n",
              "      <td>[4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8709</th>\n",
              "      <td>B00JL6LTMW</td>\n",
              "      <td>[We have enjoyed Larabar's variety of bars for...</td>\n",
              "      <td>[4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8710</th>\n",
              "      <td>B00K00H9I6</td>\n",
              "      <td>[This 100% pure Canadian maple syrup is a Grad...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8711</th>\n",
              "      <td>B00KC0LGI8</td>\n",
              "      <td>[I followed the directions on the box exactly ...</td>\n",
              "      <td>[2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8712</th>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>[Usually the label &amp;#34;gluten free&amp;#34; is a ...</td>\n",
              "      <td>[5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8713 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          itemID                                         reviewText  \\\n",
              "0     616719923X  [Just another flavor of Kit Kat but the taste ...   \n",
              "1     9742356831  [This curry paste makes a delicious curry.  I ...   \n",
              "2     B00004S1C5  [These dyes create awesome colors for kids cra...   \n",
              "3     B0000531B7  [I really enjoy these bars as a quick breakfas...   \n",
              "4     B00005344V  [Traditional Medicinals' \"Breathe Easy\" is an ...   \n",
              "...          ...                                                ...   \n",
              "8708  B00JGPG60I  [We switched to this formula 5 days ago and fo...   \n",
              "8709  B00JL6LTMW  [We have enjoyed Larabar's variety of bars for...   \n",
              "8710  B00K00H9I6  [This 100% pure Canadian maple syrup is a Grad...   \n",
              "8711  B00KC0LGI8  [I followed the directions on the box exactly ...   \n",
              "8712  B00KCJRVO2  [Usually the label &#34;gluten free&#34; is a ...   \n",
              "\n",
              "                                                 rating  \n",
              "0     [4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, ...  \n",
              "1     [5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...  \n",
              "2                   [5.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0]  \n",
              "3         [5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0]  \n",
              "4                   [5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 5.0]  \n",
              "...                                                 ...  \n",
              "8708  [4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 2.0, ...  \n",
              "8709  [4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, ...  \n",
              "8710           [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "8711  [2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, ...  \n",
              "8712  [5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, ...  \n",
              "\n",
              "[8713 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_df=df[['itemID','reviewText','rating']].groupby('itemID')['reviewText','rating'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['rating'])],index=['reviewText', 'rating'])).reset_index()\n",
        "item_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOAi0ySLrPhl",
        "outputId": "ac4f63bb-b40f-4f78-8f8a-5af36423755f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....', \"I bought this on impulse and it comes from Japan,  which amused my family,  all those weird stamps and markings on the package. So that was fun.  It said it would take about a month to arrive and it did take that long.  I was hoping for a more interesting taste but to our family,  it just tasted a bit less flavorful or weaker than the standard milk chocolate kit kat.  The green tea flavor was too subtle for the sugar and it just tasted sweet. The wafers were very crispy, and that was good,  but it tasted a bit anemic to us.I'm happy I bought it, but don't need to buy it again.\", 'Really good. Great gift for any fan of green tea! Just so expensive to purchase candy from across the sea.', 'I had never had it before, was curious to see what it was like. Smooth, great subtle good flavor. I am ordering more and plan to make it a routine.', \"I've been looking forward to trying these after hearing about how popular they were in Japan, and among Kit Kat fans as well. I do not recommend ordering these during warm weather, because they can melt and become smushy. I ordered mine right when summer began, and they were a bit mushy so I let them solidify under room temp. Afterwards, I tried some and they tasted fine. I was expecting a stronger green tea or matcha flavor, but it is actually quite subtle. The outer coating was creamy and not overly sugary, which I liked. Overall, I wouldn't say it's insanely good, but definitely a yummy treat.\", \"These Kit-kats are very good, but if you're looking for a strong green tea flavor- you will be disappointed. The green tea flavor is very subtle.\", 'I found these in a Mitsuwa Marketplace in Illinois.I actually expected them to taste better than the did.  they were okay but seem smaller than standard kit kats and the taste was a tad mild compared to other green tea candies I have tried.But still, they were pleasant enough and nice for a change.', 'Creamy white chocolate infused with Matcha green tea surrounding layers of wafers. Much less sweeter than the traditional Kitkat. Small size is perfect to satisfy the chocolate craving w/o the guilt. Was in LA last week and picked up a bag on a whim at the Japanese store in Little Tokyo. Now, back in WI and regretting not picking up a handful more. Not only were these Kitkats delicious, the bags were only $5 each!', \"After hearing mixed opinions about these Kit Kats, I decided to try them. They are excellent, and I do not regret purchasing them at all. They taste like matcha with a bit of a vanilla and milky flavor as well. They are not too sweet or too plain. These are the best Kit Kats I've ever had, and I would recommend them to anyone who likes matcha-flavored candies or anyone wanting to try an unusual kind of Kit Kat.\", 'I love green tea, I love Kit Kats, but the two do not belong together. I hate the after taste of them.', 'I ordered these in Summer so they of course arrived melted, a trip the freezer made them awesome again though. Just order them in cooler times of the year and you should get them in good condition.I love these so much more than the regular chocolate Kit-Kat bars. I hope some day to see them on store shelves in the US some day.', 'These are definitely THE BEST candy bar out there!  I just wish I was able to find them in a local store instead of having to buy them online!', \"Yes - this is one of the most expensive candies around, because it only comes imported. But my goodness - are these ever good. The KitKat folks could really clean up if they started selling these in the US. Once you try them you can't wait for more. So yummy and delivered quickly and fresh.\", 'I love the green tea kitkat, taste so good, not as sweet as the milk chocolate one, and it comes with 12 small pack, easy to keep on a diet, i love this one and the dark chocolate one!', \"I love Kit Kat & green tea....together they are okay.  Nothing to get excited about.  I wouldn't order this again.\", \"I tried this for the first time today and it is delicious but I don't quite taste the Matcha flavor as you would in like say a Green Tea ice cream. To me it tasted like white chocolate with a grainy texture which I'm guessing is the Matcha tea powder. I think my favorite KitKat flavor mix is the Mocha.\"]\n",
            "[4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 3.0, 4.0]\n"
          ]
        }
      ],
      "source": [
        "print(item_df['reviewText'][0])\n",
        "print(item_df['rating'][0])\n",
        "# item_df.loc[0][1] --->the same as above code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCekVFHgXtom"
      },
      "source": [
        "##   Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "cZb_XiBoGHSa",
        "outputId": "f1cb72ea-8d50-467a-d412-92d75a9d167e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean          4.243042\n",
              "std           1.090003\n",
              "min           1.000000\n",
              "25%           4.000000\n",
              "50%           5.000000\n",
              "75%           5.000000\n",
              "max           5.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.groupby('rating').size().plot(kind=\"bar\");\n",
        "df['rating'].describe()\n",
        "#histogram of ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "hPn4ftb2vqn-",
        "outputId": "91fde917-2de7-4a70-ea94-2e4ae376ea5a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_means=user_df.rating.apply(lambda x: np.mean(x))\n",
        "user_means[:50].plot(kind=\"bar\", grid=False, figsize=(16, 6), title=\"Mean ratings for 50 users\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZuVzD2bTv4iE",
        "outputId": "8533423d-08da-4eeb-c78b-51397de9ecff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2304x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(32,6), sharey=True)\n",
        "user_means.nlargest(50).plot(kind=\"bar\", ax=ax1, title=\"Top 50 users in data set\")\n",
        "user_means.nsmallest(50).plot(kind=\"bar\", ax=ax2, title=\"Bottom 50 users in data set\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FChjMJ0MvtiU",
        "outputId": "81b5374f-986d-4079-8cb6-a99614f56d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7e6590fb50>]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_means = df.groupby(\"userID\").rating.mean().sort_values()\n",
        "_, ax = plt.subplots(figsize=(20, 6))\n",
        "ax.plot(np.arange(len(user_means)), user_means.values, \"k-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "VQfmX7OwGaRN",
        "outputId": "65757a6a-d630-49fc-a97c-0742c3a1b7a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "item_means=item_df.rating.apply(lambda x: np.mean(x))\n",
        "item_means[:50].plot(kind=\"bar\", grid=False, figsize=(16, 6), title=\"Mean ratings for 50 items\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "6Dyp-7KeGyoK",
        "outputId": "6d657471-73d2-4291-aa92-49de438f0a59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABxUAAAGFCAYAAAA7Pa3iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABg8ElEQVR4nO3dd7g1V1k3/u+dQg1JgIRECCFU6TUUX+AHiFJE6UhviihIERANii+CogFFRAR8UYr03qQHCU0IJCQhEBJ6SOgBAgSkZ/3+WHPIzsl59plzZp/n7Cd8Ptc119ln9r5n1p69pq17Zk211gIAAAAAAACwI7ttdwEAAAAAAACA5SapCAAAAAAAAMwlqQgAAAAAAADMJakIAAAAAAAAzCWpCAAAAAAAAMwlqQgAAAAAAADMJakIwIZU1YlVdfPtLsesqrp3Vb1zQdO6eVV9aRHTAgAAgHmq6uCq+n5V7b7dZZlVVf9WVX+1oGn9dVW9ZBHTAmB7SSoCbLPh5GFlOKuqfjjz/70XNI8XVtVPVs1r95n3b1lVJ1fV/1bVkVV1mR1Nq7V2tdbae4a4pTgxaK29tLV2q50936p6QFV9YBvmuxTLHQAAYLOq6pSZ898zquotVXXpkbHnOhcbznv/dmtKu2YZTll1/v7OVe8/qqq+VlXfq6rnV9X515pOa+3U1tperbWfD3HvqaoH7YzvME9r7Y9aa3+zs+e7s3/HmfkuxXIHWHaSigDbbDh52Ku1tleSU5P8zsy4ly5wVk+dndfMCct+SV6X5K+SXCzJMUleucD5AgAAwFp+ZzgX/pUkX0/yzG0uz0bNnr//4kLXqrp1ksOS3DLJZZJcLskTt6mMALAwkooAS6qqzl9V/1xVXxmGf165snGli86q+ouq+uZwheRm72q8c5ITW2uvbq39KMlfJ7lWVV15B+U6pap+o6puk+Qvktx9uCrzY8P7+1TV86rqq1X15ar625W7IoerSf+nqp5eVd+pqs9X1f8Zxp9WVd+oqvvPzOu3quqTVXXmMK0/3UGZznGValW1qvqjqvrMMJ9nVVXtIPaCw5WQZ1TVJ5Ncf9X7h1XV54YyfLKq7jSMv0qSf0vya8P3/84w/nZVddxwNeppVfXXO1rwVbVfVb15KOO3q+r9VbXb8N4lq+q1VXV6VX2hqh4xjF9zuQMAAOyqhnPR1yS56sq44dzyRcM50Rer6vFVtdta52JV9eAk907yZ8O4/xqmcZXhDrTvVH+Ux+1npv/Cqnp2Vb1tiPmfqjpwOPc+o3pvPtfZ5Fe6f5LntdZObK2dkeRvkjxgrQ9W1SHDOeweVfXkJDdN8q9Dmf51+MyVq+qI4bzxU1X1u5v9HlX158P59ZnDtG65g3L94o7BOrsN4jHDeftXq+qBO/ryVXXZqnrvMI8jkuy36v1XV7+L87tV9b6qutowfke/45rn5TuY9w2q6pjhnPzrVfVPM+/dqKo+ONSHj9XwaJcdLXcAzk1SEWB5/WWSGyW5dpJrJblBksfPvH9g+oH5pdJPWJ5bVb86Z3oPHU5APlpVd5kZf7Ukv0hMtdZ+kORzw/gdaq29PcnfJXnlcFXmtYa3XpjkZ0mukOQ6SW6VZLYLkRsmOSHJxZO8LMkr0hN5V0hyn/SD+L2Gzz4vyR+21i6S5OpJ3j2vTKv89jDdayb53SS33sHnnpDk8sNw6/RlOetz6ScX+6RfWfqSqvqV1tpJSf4oyYeG77/v8PkfJLlfkn2T3C7JQ6rqjjuY92OSfCnJ/kkOSE8WtiGx+F/pv8ul0q9u/ZOquvWc5Q4AALBLqqoLJbl7kqNmRj8z/Tzsckluln6e9cC1zsVaa89N8tKc3UPP71TVnunnVe9McokkD0/y0lXnzb+bfp69X5IfJ/lQkmOH/1+T5J8y30uHpOc7q2r23Owc59nD6wOq6uLzJtZa+8sk70/ysOF7PKyqLpzkiPTz50skuUeSZ1fVVWdCR32P4bs/LMn1h/PsWyc5ZZ3vuOLA9N/jUkl+P8mzquqiO/jsy5J8dJj/3+Tc59lvS3LF4fscm/7bZa3fcfj8muflO5j3M5I8o7W2d/p5/quG736pJG9J8rfpvTT9aZLXVtX+ay33cYsE4JePpCLA8rp3kie11r7RWjs9/cD5vqs+81ettR+31t6bfnD8u6snMviXnH3A/ldJXlhVNx7e2yvJd1d9/rtJLrLRAlfVAUl+K8mftNZ+0Fr7RpKnp5/0rPhCa+0FQ/err0xy6eF7/ri19s4kP0lPMCbJT5Nctar2bq2d0Vo7dgPFOby19p3W2qlJjkxPzq7ld5M8ubX27dbaaenL6heGOzi/0lo7q7X2yiSfSU/wrqm19p7W2seHz5+Q5OXpJ8Br+Wl6Nz+Xaa39tLX2/tZaS0+G7t9ae1Jr7Settc8n+fecczkCAADs6t5QvdeX7yb5zST/kCTVe7u5R5LHtdbObK2dkuRpOfc58Tw3Sj/fPXw4r3p3kjcnuefMZ17fWvvocKfk65P8qLX2opnz1Xl3Kt47ySHp3ZsemeQdVbXv8N7q8+yV1xs+z06/YPaU4Tz6Z62145K8NsndNvE9fp7k/Onn2Xu21k5prX1uZDl+mn7u/tPW2luTfD/JuS5srqqD089pV9or3pee3P2F1trzh9/1xzm7t6R9djTjDZ6X/zTJFapqv9ba91trK4nq+yR5a2vtrcN0jkh//Mtvjfz+AERSEWCZXTLJF2f+/+IwbsUZw12FO3r/F1prx7bWvjWcgLw1/cq/Ow9vfz/J3qtC9k5y5ibKfJkkeyb56tCdyHeS/L/0ZOaKr8+8/uFQvtXjVu5UvEv6Af4Xh65Tfm0DZfnazOv/nZnmapdMctrM/7PLPFV1v6o6fub7XD2rum5Z9fkbVtWRw9Wq302/gnZHn/+HJJ9N8s7qXcEeNoy/TJJLrsxzmO9fpN/NCAAAcF5xx6HXlwuk30H33qpa6ZVnz5z7nPhSG5j2JZOc1lo7a840Vp+L7ujc9Fxaa//TWvtha+1/W2t/n+Q76XfTJec+z155vdnz7BuuOj+8d/qdgxv6Hq21zyb5k/RE3jeq6hVVtWY7whq+1Vr72cz/OzrPvmTWbq9I0hPGVXX40J3p93L2nZLzzrM3cl7++0mulOTkqjq6qn57GH+ZJHdbtRxvkn6hLwAjSSoCLK+vpB/0rjh4GLfiokM3KDt6f56WZOUZgyemd6+aJBmmeflh/JjpzDotvauV/YYuaPZtre3dWpvbleoOJ97a0a21O6QnJd+QoduSBftq+t2SKw5eeVFVl0m/Q/BhSS4+nOx+Imcvu9XfP+ndvLwpyaVba/ukP+tjzec5DldmPqa1drkkt0/y6OF5Fqel39G578xwkdbayhWUa80XAABgl9Ra+3lr7XXpd9LdJMk30+84W31O/OWVkLUms+r/ryS59PB4ibWmsWg7PM8eXn+9tfatkdOZdVqS9646P9yrtfaQTRWytZe11m6SvmxbkqdsZjpzfDVrt1esuFeSOyT5jfTuTA8Zxq95nj3ivPwcWmufaa3dM70d4SlJXjOU5bQkL161HC/cWjt8rfkCsDZJRYDl9fIkj6+q/atqvyT/N8lLVn3miVV1vqq6aXqXKK9ea0JVddeq2qv6Q+1vld7tx5uGt1+f5OpVdZequsAwnxNaayePKOPXkxyycpLWWvtq+vMqnlZVew/zu3xV7aj7zx0avte9q2qf1tpPk3wvyVnrxW3Cq5I8rqouWlUHpT9nY8WF008sTh/K9MD0KyJXfD3JQVV1vplxF0ny7dbaj6rqBuknTGuqqt+uqitUVaV3h/Pz9O/4kSRnVtWfV9UFhys5r15V15+Z7y+WOwAAwK6sujskuWiSk4ZuO1+V5MlVdZEhsfTonH1OvNa52NfTn7+44sPpd9P9WVXtWVU3T/I7SV6xgPIeXFU3Hs5bL1BVj02/c+5/ho+8KMnvV9VVhy5RH5/khSMnv/p7vDnJlarqvsP32LOqrl9VV9lEuX+1qn69qs6f5EfpdzEu9Dy7tfbF9G5FV9orbpK+3FdcJP1i5G8luVCSv1s1idXff73z8nOoqvsMz0k8K/3u0aR/x5ck+Z2quvVwjn2Bqrr50A6w1nwBWIPGSIDl9bfpB+InJPl4+sPL/3bm/a8lOSP96suXJvmjOYnAR6Zfjfmd9C43/6C19p4kaf15jXdJ8uRhejfM+Gf3rSQxv1VVK887vF+S8yX55DC912Tz3YncN8kpQ5cof5TexcuiPTG9K5YvpCdEX7zyRmvtk+nP7fhQ+gnGNXL2SWKSvDv9CtSvVdU3h3EPTfKkqjozPUE77+7KKyZ5V3rXOB9K8uzW2pHDCfRvpz8H8gvpV+n+R/pVnMnayx0AAGBX819V9f30i0ifnOT+rbWVXnMenuQHST6f5APpvcI8f3hvrXOx56U/K/A7VfWG1tpP0pNZt00/p3p2kvuNvIB2PRdJ8pz0c94vJ7lNktuu3InYWnt7kqemP2vx1PRzzieMnPYzkty1qs6oqn9prZ2Z5Fbp5+lfSW8LeEr6sxE36vxJDk9fHl9Lv5vvcZuYznruld628O307/2imfdelL48vpzebnDUqtjVv+N65+Wr3SbJiUO9ekaSewzd1J6WfofkX6QnKE9L8tic3T5+juW+ua8NcN5XrbmzG2BXM1xh+ZLW2kHrfBQAAAAAACZzpyIAAAAAAAAwl6QiAAAAAAAAMJfuTwEAAAAAAIC53KkIAAAAAAAAzCWpCAAAAAAAAMy1x1ZMdL/99muHHHLIVkwaAABg0z760Y9+s7W2/3aXA5w3AwAAy2jeefOWJBUPOeSQHHPMMVsxaQAAgE2rqi9udxkgcd4MAAAsp3nnzbo/BQAAAAAAAOaSVAQAAAAAAADmklQEAAAAAAAA5pJUBAAAAAAAAOaSVAQAAAAAAADmklQEAAAAAAAA5pJUBAAAAAAAAOaSVAQAAAAAAADmklQEAAAAAAAA5pJUBAAAAAAAAObaY8yHquqUJGcm+XmSn7XWDt3KQgEAAAAAAADLY1RScXCL1to3t6wkAAAAAAAAwFLS/SkAAAAAAAAw19ikYkvyzqr6aFU9eCsLBAAAAAAAACyXsd2f3qS19uWqukSSI6rq5Nba+2Y/MCQbH5wkBx988DmCDznsLXMnfsrht5v7/q4evwxlWPb4ZSjDdscvQxmWPX4ZyrDd8ctQhmWPX4YyLHv8MpRhu+OXoQzLHr8MZdju+GUow7LHL0MZFvEdYGeZd94MAACw7Ebdqdha+/Lw9xtJXp/kBmt85rmttUNba4fuv//+iy0lAAAA7OKcNwMAALuydZOKVXXhqrrIyuskt0ryia0uGAAAAAAAALAcxnR/ekCS11fVyudf1lp7+5aWCgAAAAAAAFga6yYVW2ufT3KtnVAWAAAAAAAAYAmNeqYiAAAAAAAA8MtLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYS1IRAAAAAAAAmEtSEQAAAAAAAJhLUhEAAAAAAACYa3RSsap2r6rjqurNW1kgAAAAAAAAYLls5E7FRyY5aasKAgAAAAAAACynUUnFqjooye2S/MfWFgcAAAAAAABYNmPvVPznJH+W5KytKwoAAAAAAACwjNZNKlbVbyf5Rmvto+t87sFVdUxVHXP66acvrIAAAABwXuC8GQAA2JWNuVPxxkluX1WnJHlFkl+vqpes/lBr7bmttUNba4fuv//+Cy4mAAAA7NqcNwMAALuydZOKrbXHtdYOaq0dkuQeSd7dWrvPlpcMAAAAAAAAWApjn6kIAAAAAAAA/JLaYyMfbq29J8l7tqQkAAAAAAAAwFJypyIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMNe6ScWqukBVfaSqPlZVJ1bVE3dGwQAAAAAAAIDlsMeIz/w4ya+31r5fVXsm+UBVva21dtQWlw0AAAAAAABYAusmFVtrLcn3h3/3HIa2lYUCAAAAAAAAlseoZypW1e5VdXySbyQ5orX24S0tFQAAAAAAALA0RiUVW2s/b61dO8lBSW5QVVdf/ZmqenBVHVNVx5x++ukLLiYAAADs2pw3AwAAu7JRScUVrbXvJDkyyW3WeO+5rbVDW2uH7r///gsqHgAAAJw3OG8GAAB2ZesmFatq/6rad3h9wSS/meTkLS4XAAAAAAAAsCT2GPGZX0nyn1W1e3oS8lWttTdvbbEAAAAAAACAZbFuUrG1dkKS6+yEsgAAAAAAAABLaEPPVAQAAAAAAAB++UgqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHPtsd0FAAAAAAAAgEU75LC3zH3/lMNvt6Xxy1CGRXyHFe5UBAAAAAAAAOZypyIAAAAAAABLZ5F32TGdpCIAAAAAAMCS2e5uL5eh60+Wi6QiAAAAAADAgkmocV7jmYoAAAAAAADAXO5UBAAAAAAAFmq7u97c6vgx04DzGncqAgAAAAAAAHO5UxEAAAAAADgHzwMEVpNUBAAAAACA8xAJQWArSCoCAAAAAMCMZX+en6QgsB08UxEAAAAAAACYy52KAAAAAACD7b7DbKvjl6EMyx4PwNrcqQgAAAAAAADMJakIAAAAAAAAzCWpCAAAAAAAAMwlqQgAAAAAAADMJakIAAAAAAAAzLXHdhcAAAAAAGARDjnsLet+5pTDb7cTSgIA5z2SigAAAADAUlgvKSghCADbR/enAAAAAAAAwFySigAAAAAAAMBckooAAAAAAADAXJ6pCAAAAAAshGciAsB5lzsVAQAAAAAAgLncqQgAAAAACzD1Lr1F3OW3DGUAAM6b3KkIAAAAAAAAzCWpCAAAAAAAAMwlqQgAAAAAAADMJakIAAAAAAAAzCWpCAAAAAAAAMy1x3YXAAAAAACWwSGHvWXu+6ccfrudVBIAgOXjTkUAAAAAAABgrnWTilV16ao6sqo+WVUnVtUjd0bBAAAAAAAAgOUwpvvTnyV5TGvt2Kq6SJKPVtURrbVPbnHZAAAAAAAAgCWw7p2KrbWvttaOHV6fmeSkJJfa6oIBAAAAAAAAy2FDz1SsqkOSXCfJh7ekNAAAAAAAAMDSGdP9aZKkqvZK8tokf9Ja+94a7z84yYOT5OCDD15YAQEAAOC8wHkzy+6Qw94y9/1TDr/dtsbvjDIAALBjo+5UrKo90xOKL22tvW6tz7TWnttaO7S1duj++++/yDICAADALs95MwAAsCtbN6lYVZXkeUlOaq3909YXCQAAAAAAAFgmY+5UvHGS+yb59ao6fhh+a4vLBQAAAAAAACyJdZ+p2Fr7QJLaCWUBAAAAAAAAltC6SUUAAAAAlt8hh71l7vunHH67nVQSAADOi8Z0fwoAAAAAAAD8EpNUBAAAAAAAAOaSVAQAAAAAAADm8kxFAAAAgG223vMQE89EBABge0kqAgAAAEy0XlJQQhAAgF2d7k8BAAAAAACAuSQVAQAAAAAAgLl0fwoAAAD80tN9KQAAzOdORQAAAAAAAGAuSUUAAAAAAABgLklFAAAAAAAAYC5JRQAAAAAAAGCuPba7AAAAAABTHXLYW+a+f8rht9tJJQEAgPMmdyoCAAAAAAAAc0kqAgAAAAAAAHPp/hQAAADYdrovBQCA5eZORQAAAAAAAGAuSUUAAAAAAABgLklFAAAAAAAAYC7PVAQAAIBfclOfZ+h5iAAAcN7nTkUAAAAAAABgLklFAAAAAAAAYC5JRQAAAAAAAGAuSUUAAAAAAABgLklFAAAAAAAAYK49trsAAAAAwDSHHPaWue+fcvjtdlJJAACA8yp3KgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc0kqAgAAAAAAAHNJKgIAAAAAAABzSSoCAAAAAAAAc62bVKyq51fVN6rqEzujQAAAAAAAAMByGXOn4guT3GaLywEAAAAAAAAsqXWTiq219yX59k4oCwAAAAAAALCEPFMRAAAAAAAAmGuPRU2oqh6c5MFJcvDBBy9qsgAAAHCeMO+8+ZDD3jI39pTDb7dl5QIAABhjYXcqttae21o7tLV26P7777+oyQIAAMB5gvNmAABgV6b7UwAAAAAAAGCudZOKVfXyJB9K8qtV9aWq+v2tLxYAAAAAAACwLNZ9pmJr7Z47oyAAAAAAAADActL9KQAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAw16ikYlXdpqo+VVWfrarDtrpQAAAAAAAAwPJYN6lYVbsneVaS2ya5apJ7VtVVt7pgAAAAAAAAwHIYc6fiDZJ8trX2+dbaT5K8IskdtrZYAAAAAAAAwLIYk1S8VJLTZv7/0jAOAAAAAAAA+CVQrbX5H6i6a5LbtNYeNPx/3yQ3bK09bNXnHpzkwcO/v5rkU3Mmu1+Sb2620OeB+GUow3bHL0MZdvX4ZSjDdscvQxm2O34ZyrDd8ctQhl09fhnKsN3xy1CG7Y5fhjLs6vHLUIbtjl+GMqwXf5nW2v4Tpg+b5rx5lyvDdscvQxl29fhlKMN2xy9DGbY7fhnKsKvHL0MZtjt+Gcqw3fHLUIZdPX4ZyrDd8ctQhu2OX4YybP68ubU2d0jya0neMfP/45I8br24daZ5zC9z/DKUYbvjl6EMu3r8MpRhu+OXoQzbHb8MZdju+GUow64evwxl2O74ZSjDdscvQxl29fhlKMN2xy9DGRbxHQyGZRi2e13Y7vhlKMN2xy9DGXb1+GUow3bHL0MZtjt+Gcqwq8cvQxm2O34ZyrDd8ctQhl09fhnKsN3xy1CG7Y5fhjJMiR/T/enRSa5YVZetqvMluUeSN42IAwAAAAAAAM4D9ljvA621n1XVw5K8I8nuSZ7fWjtxy0sGAAAAAAAALIV1k4pJ0lp7a5K3LnC+z/0lj1+GMmx3/DKUYVePX4YybHf8MpRhu+OXoQzbHb8MZdjV45ehDNsdvwxl2O74ZSjDrh6/DGXY7vhlKMMivgMsg+1eF7Y7fhnKsN3xy1CGXT1+Gcqw3fHLUIbtjl+GMuzq8ctQhu2OX4YybHf8MpRhV49fhjJsd/wylGG745ehDJuOr6H/VAAAAAAAAIA1jXmmIgAAAAAAAPBLTFIRAAAAAAAAmEtSEQAAAAAAAJhrS5OKVXXDqtp7eH3BqnpiVf1XVT2lqvbZynnDeqrqEttdBvhlVN0Nq+rOw3DDqqoJ03voxPJcbEr8RqdRVftOnd+caV95Z8RX1flmf7OqukVVPaaqbruJeV5sQb/B7TcRs39VXaeqrllVe02c/95Vdb2quuiEaWz4O6yK39ByrKo9Zl7vVVWHbua3mLocq+qAqrruMByw0fippsx/GZbhosowM43tqAMLWxcBWJyq+rvtLgPLYUpdGI5PrruV50EjyrDfJmIcn/ySq6oDq+rA4fX+Q/vF1Xbi/Bd23r0MFnHOfF4wdd+6DNvUqaa2421ifvvuzPntoAwLPW/fblt9p+Lzk/zv8PoZSfZJ8pRh3Au2eN5bamcmpIaK9qSqOrGqvltVp1fVUVX1gJHxe1TVH1bV26vqhGF4W1X9UVXtOSL+mjOv96yqx1fVm6rq76rqQiPid6uq36uqt1TVx6rq2Kp6RVXdfEz5h2kcO8z38mNjVsVfbNVw8SQfqaqLjlmBFzD/Sb/hqmlNaXg8eGVDWlWHVNVdq+rqG5zGoVV1p6q6fU1MYAzT20zj5aQG6LXq/diTjKE+7za8Pt9QhlHfYZEHhFN+h63akY0pR1XdKslnkvx1kt8ahicm+czw3nrxj141PCbJk1b+HxF/46o6aVgXb1hVRyQ5uqpOq6pfWy9+mMbjZ15ftao+neSjVXVKVd1wxCS+WVXvqqrf34IDm3fupPijk+ybJFX12CRPTnLBJI+uqr9fL3jYFr2iqk5P8uH07fE3hnGHjIi/86rhLkmeu/L/iPirVtW7knxomP+/J/l4Vb2wRl70VFUvWdluVNWtk3wi/Rjn+Kq62074DpPq4bD/+XpVfXrYBp0wlP9jVXXP9eJn5rvp5VhV166qo5K8J8lTh+G9w/7xuiPiLz3UmfdX1V/Mbtur6g07Yf4PyPYvw0llmLpNXED5F7EuXmP4zU6rqufWTCNFVX1kzDRgmVXVAxcwjd/cGWWoqitX1S1r1TlKVd1mRGxV1e9W1d2G17esqn+pqofWcOw9Yhr7rfr/PsM0Hlw17gK2qrpcVf1pVT2jqv6p+jnz3mNidzC9d2/gswdX1QWG11VVD6yqZ1bVQ2rm+H2D83/RBj77L6uGZyZ56Mr/G5jOlHqwiN9w71rjvL1m2jV2pqq6bPXju0WcO6+7LlY/R7zY8Hr/qnpRVX28ql5ZVQeNnM+kulBVz555fZMkn0zytPR9/G9t9XeoqttW1Req6gPV205OTPLhqvpSVd1yRPzk45PtVgu4yaOqHlFVl55QhkWsz1O2J5OWQVX9YXodOKqqHpLkzUlul+R1VfX7Y8o/TOcWVfWvVfXGqnpdVR1eVVcYGT7pvHuIu3VVPad6O+6bhtfrLr+Z+CtX1Z/PbA/+vKquMjJ20jnzIsqwg+ltZN84tR5N3rdO3aYOcZuuh9WPh2485rM7iJ/Ujrcgk9rhqurbVfUfw/ZowzdF1GLaDiZtk9eZ9sbPN1prWzYkOWnm9bGr3jt+5DT2SXJ4kpOTfDvJt5KcNIzbd0T8gUmek+RZSS6e3pD98SSvSvIrI8twsVXDxZOckuSiSS42Iv7QJEcmeUmSSyc5Isl303cO1xkR/8YkD0hyUJJHJ/mrJFdM8p9J/m5E/MuHZXCjYRoHDa+fk+SVI+KPnXn9tCQvTHKzJE9P8qIR8S8YlvtNkvxzkicl+c0k70ry8JG/wReS/GOSU5N8JMmjklxyA3XxrGEas8NPh7+f3wnzn/QbDtO46rDMPpvkJ+kHt18Yfo99RsQfNnz+5CQPGv4+L8mJSR49Iv5mSY4ZynBG+gHV/6Q3xl565Hd4/Krv8+mhTKckueGI+GsnOSp9G/CuYTh5GHfdEfG3SPKlJN9MT54cslY9nxN/xyRfT/LVJHcYfoP/Hqb5OyPiP5bkosPrxyb5YJLHp28T/n7kMpz0Owz18FvDsr9tks8P3+G0JPccW6d3MO1TR3zmpNnlPjP+spnZZ8yJPzPJK5P83yRPGIYzVl6PiP9Ikmsk+bWhHtxkGH/dJP8z8nvObhPfkuS2w+sbJPngiPiPJ/ntJC8dfos3JrlHkguOnP+/7GB4ZpLvbXX8MI1PzLw+ZqXsSfZIcsKI+A8luXuS3WfG7T4sh6NGxP90qPvPT9/HvGCoGy9I8vwR8Ucl+dWZ3+0/h9d/kOQ1I5fBx2def3ClXifZL8nHdsJ3WEQ93G9Y976X5PLD+APG/IaLWI5Jjs8a2/70Y5Qxy/CIJH+Uvm945vA7XHx477idMP9lWIaTypCJ28QFlH8R6+IHktwmvcHlT9OPa1aWw7r1wGBY9iEjjq+2ehpj4pM8Ismnkrwh/dj+DjPvjTnOfnaS1yR5U/p586uT3DfJK5I8Y2Q5Z/eNj0/yjiT3H6b19JHf4Z1D7AfT2xCenN54d/MR8SesGj6e5Mcr/4+I/0SSCw2vnzIsj/ukHyuMOTZ406rhv5J8f+X/EfGnDcv+fsNyu3+S01dej/wNptaDqb/h7yb5Svo+/sQk19/I/Gc+e+v09pKVZfmcJLcZGfuGmdd3SD/ffcGwXB4wtgw7mPaYdfGTM69fmd52cVD6eeARI+czqS6s+h2PzHCunuRySY7Z6u8w/P5XST+++VaSGw3jrzKyHi7i+ORi6eesD0pSSf4y/dj/HzK0CawTv9+q/++Tfs724CQ1Iv7EJHsMr5+b3hZ3k/Tz5teN/A7fHdan9yd5aJL9N1hfF7FNnrI9mbQM0rfhF0pvA/5+kgOH8RfN+Dbtv09f/++Tvk3/h6EeHZfkbiPip553/3OSt6afZ99kGO4xjFt335rkz4f16bDhO9xneH18ksPGLMOZ1xs+Z15QGabuG6fWo0XsW6duU6fWw9OH+vfF9Atx181lrIqf1I43M51bJPnX9Da016Xnhq4wMnZqO9ynkjwsvf31y+k3z91oA2VfRNvBpG3yOtPe8LnCQmY8p0CvTvLA4fULkhw6vL5SkqNHTuMdwwbkwJlxBw7j3jki/u1JHj5scE4Y4i49jHvjyDJMTUh9JL3x/p7DxuSuw/hbJvnQiPiPrfr/6OHvbklOHhH/6c28N/OZ42ZeH59kz+F1jan4qz+TocE4yfkzIokwfHZ2A3rT9JPOr6VvTB88Iv4xQ124xsy4L2ygLk+d/6TfcGW5ZVrD3YnpVzRdPH2Dvv8w/sKZOVCZVw9mYi6b5PXD698csy6usRw30wh+fKY1AB+d5GrD67um3zG3coJx3Ij449K3Pys7gZXf4zIZtyOfdEC4iN8h0xugpya0PpPhgGzV+PMl+eyI+IPT9y1PydmNLutuh2eX38zrk1a9N6qhYVU9Pm5H0x8Zf8H0xo/XpR/YvGxE/JnpJ5P3X2P45lbHD9P4YJKrD6/fnrOT5RfIuO3JZzbz3sxnrp+eDH/IzLgvbKAerN4mz/4mY/dLJybZe3j9gSS7zb63E77D1Hp4/Mzrr6x6b+z2aNJyXKcejNkeHL/q//sMv8vlx6zPi5z/Ni7DSWWYuk1cQPkXsS6unsYtMuzfx3wHg2EZhpw7GXWOpNTIaaxuNJttPPvBVpdh+Nxew+tD0o91Hzn8f9yY+OHvnunHROcb/t/QcfLM62OTXHhmmh8fU4YMFzylNyS/Z3h98MjvsJIQvXL6+cEh6ef/l0lymRHxs4mUj+acxxZjznWOHeZ/8/QLEW+efjHkzZLcbET8RdIbS1+W4QLabOA4e0H1YOpveHyGi8fTzzFPTnKnsfMfPvfPmdYIP/sdPpjkssPrsReeTV0XPzVbj1Yvn5HLYFJdyDn356vLMOb4YtJ3WDX/0zYRv4jjk7emn7M+J/0C4GemtyU9KSPaIjM9IbeImzyOS2+zulX6Bemnp5/73T/JRcbEz5ZhE+vz1O3JpGWw6jdYXSfWnf/Kd5h5vUeGi/bSE5Njzpunnnev2eab3p475rz70xnagFeNP9/I+EnnzAsqw9R949R6tIh969Rt6tR6eNzw90rpN8mcmL5/fUKSK42In9SON3x+amJ0ajvcsau+z58NdevzGXfD1/EzrzfbdjB1mzz5fGN22FQXGhvwoCTPqN5F1zeTfKiqTks/sH7QyGkc0lp7yuyI1trXkjylqn5vRPwBrbVnJr2/3plpPXMDt6s/Nr3B/rGttY8P0/pCa+2yI+P3bK29bYh7SmvtNcP3+O+q+scR8T+oqpu01j5Q/XlL3x7izxp5y+23h9vKX9taO2sox25J7pZ+ZcB69qmqO6VX3PO31n46zL9VVRsR/9Oqunxr7XPVuxP7yRD/45Hx59Bae3+S91fVw9N/l7unXy0yL+ZpVfXKJE8f6uATkmxk3r9YzpuZf6b/hklPQH1qiPtIVf3b8PrfR94u/vPW2g+r6idJfpi+4Uxr7Qcji7B7a+304fWp6SfHaa0dUVX/PPI7zLrkynoxfJ8Ljoi5cGvtw6tHttaOqqoLj4g/X2vtxCHmNVV1UnrXFX+ekfVh2P6kqk6d+T2+WOO6ZfpeVV29tfaJ9G3iBdJ/iz0yvjvqqb/Dz1tr30y/9f/7rbXPDfFfH1kPHpiepP/xGu+NuWX/+eld670ifV+Q9As97pG+U5yrtXZqkrtV1R2SHFFVTx9T6Bmzy/lxq94738hpXK6q3pS+XTioqi7UWlvp6nvdLqVzzu3JD9PvnH/V0HXGHUfEH51+4PfBc0246q93QnzS7w57aVV9LMk3khxTVe9Lv+NpzPMBPjp04fGfOWc9uH/6gdJcrbWjq3fl9vCqOjL9gqGNbNM/V1V/leTdSe6c3gC10jXy2HXxiUmOrKpnpV+t9uqhXtwi/cBuq7/D1Hp4avUucy6S5OSqelr6QfVvpJ9kjTF1Ob6tqt6S5EU5Zz24X0YswyR7VtUFWms/SpLW2kuq6mvpjS5j9glT578My3BqGaZuE6eWfxHrYqpqn9bad5OktXZk9e6EX5t+lwDsCg5IvzNq9blZpTcojnHT9IaW768xjRvshDLs1lr7fpK01k6p/qiL11TVZTJz7DPHz4bYn1bV0a21lXPGn1XVWSPik+SCVXWd9O3H7q21H8xM8+cjp7FHkp+nXwC71xB/ao14bEhr7fbDefNzk/xja+1NVfXT1toXR877tKr69dbau9Pvyrl0ki9Wf3THGIcmeWT6HVGPba0dX1U/bK29d0xwa+3MJH9SVddLP857Szb+yJyp9WDqb7h7a+2rQ8xHquoWSd48dBc29jjrt1prV1o9cmhP+HT6Mp5ndj57tNa+MJTnmyPr8tR18T1V9aT0Btj3VNWdWmuvH5bFd0fEL6IuXLmqThjKfEhVXbS1dsZwzjzm+GLqd/hO9a4r905yRlU9Kv2c6zdy7m3kWhZxfHLJ1tpvDe09X2qt3XwY//6qOn5E/Oz6cuckNx3abl6W3pC9nk9U1QNbay9I717v0NbaMVV1pfSbJMZoQxviO5O8c/j+KzdM/GOS/deJn7o+T92eTF0Grar2HNpAb7cysno31WPrwVlVdbHW2reTXDK9d54M68OY7zD1vPtHVXX91trRq8ZfP8mPxpR/KPfq/divDO+tZ9I584LKMGnfmIn1aEH71qnb1Kn1sA2f/3SSv0nyN9W7FL9n+gUUc7tRXUA7XpL8dmvtGkkytCe+t7X22Kp6Tfqde69eJ35qO9xs/KkZHp9SvWvzu4+IX0TbwdRt8iLON85Rmi0f0nfk10pyvfQk30Zi35me/T1gZtwB6Y1v7xoR/7GZ13+76r11r4yZ+exB6RX0n9IrwEau0vpQehb5bukbwTsO42+WcXc3XSv9bscz0q/sWLk7av8kjxgRf0j6bcbfSD8I/vTw+pUZrppbJ/6FObtrthes/Bbpd2z994j4X09Pfnw2/e7OG82U/6kjl+ErFlgfb59+19/XNhAzaf5JrrnqN7zSRn7D4bOvS78i5Mbp3dA+fxi/Z2au5Fvnd3xZ+i3eL0/y4iT3Tk/kvGpE/POHz957qDv/NIy/UMbfbfmdnH3F9OkZrlAZ3htzdcy/pN/hePck/2cY7j6M+9cR8cdk5q7nYdxB6ScJZ46IPy7DlVVJbjAzfveR5b9meheoLxqGzw3r1DFJ7jVyGU76HYbl//fpXQa8e6hLN05PtL9jRPy7k/yfHbz3hZHf4Srpd48/cxgOS3LVsevTzHQunH510vs2EHP72Xo3M/7ySf5s5DRutmpYuXrygCR/PCL+Tzf6XVfFX2yt77Cz4mems3v6Acwj0xPNd8+IbsmH2PMleUj6icTHh+Ht6V04nH+D5bhk+gHhRvbL+6YfBL45vVuziwzj98nGurC4QvrVdq9P3649J8mtN7EsN/MdptbDvdOTSIelN5reZVgez8747uEnL8ehDv3bsPz+a3j9WyNjH5U1ri5Ncp2M795ryvxXL8O77uxlOOd3fNaYMmTiNnEB5V9EHbrXWp9Nv4L038dMw2DY7iH92O4mO3hv3aunh8+9LcktdvDeusdKU8uQfox47VXj9kg/5v35yPLvtcb4A5N8ZOQyOHLVsHLH2sUz7rz7kelXbP97+hX4K70u7T9mGc5M58Lp7QZvTE8mjI279FDu9w37pDOG/49LcssNTGel7eJfs8mub9MbmP44yUs2GDe1Hkz9DT+YoSeWmXF7p/cOMfau3xMy023qzPgbZNzdVT9P7xHmzPQLqle+w/kyrheBqevinumPnzl1GM4ayvKyJAfvjLqQ4e7cmWHlzuP9ktx5q7/DsC79v/TjugPTjxk/kd5ucJUR8ftm+vHJCel3AR2cngg9ZKYuf3JE/Mnpx7TXy7nvkjt+RPw+6W1An0t/bMtP0++oeW+Sa438DsfNeW/d88kFrM9TtyeTlsHw263Vy9KlkvzGyGV49/R24COGuny7Yfz+Y9bn4bNTzruvN3z3T2ZIRKQ/kuaoJNcbEX+b9Lbct6VfMPPc9PP2z2Z8l9BXzIRz5kWUYZjOpvaNi1iXZqa12X3r1G3qpHo4b1uw0SGbaMcb4j6W4RF0w7p51Mx7Y3qKmtoO908T4yedt6/3O2TcNnny+cbsUEPg0qqqi6Yv8DskucQw+uvpDeOHt9bOWCf+SemJq++vGn+FIf6uGyzP7ZP8RfoBwYEjY66VfkByVvrBzEPS78b4cpI/aGvcLbLGNK6SvuM6ava7VNVtWmvrXt1RVTdMv7Lgc+ndsfxa+oHMW8d8hzWm96LW2v028PlKf87RNzcTv8b0bpJ+UP+J1to7R3z+hum3rH+vqi6UfoB63fRuZf6uDVe3j4y/YPqG4DrpO+ax8Se31r47zP/Ph/mPih+msW963btq+sb08NbamcNVFVdprR21Tvwe6Yntln6r+A3SG+JOTfKsNlw1Nid+z/Rby1fm//zW2s+H5XGJNuIK3Kq62apRH22tfb+qDkjvFvhZI6Zx2/TtwaWGUV9O7wd93bpcVb+R5PTW2sdWjd83vRH+yevEXz/9RPJHq8Yfkr5hfsmIMuyefpHBldIPiL+Unsz7znqxQ/yk36H6A6b/OL0e/Gv6AdoD0uvB37Thyt458RdL8qN29h1RLIGqunhr7VvbXQ4A4JdTVR2U5Gdt6NVj1Xs3bq39zyane+H03kq+MaFsuyW5wJjj16q6WvoFcJ9orZ282XkO07pWkl9rrf3bBuOuknOeKxzdhh6HNjid2yW5cWvtLzYau1lbWA92T7/wbO5vOCzzH7TWPrtq/J5Jfre19tIR87pe+gVCF0lf/klPUn03/Zzxo5v4CivnnFdprX1oM/GbnOc+6UmRDZ8nVNUerbWfDa/3Sm9H+nzrd7psZDoXS5KNxs3Eb/o7bKequmd6l4dJv3DyIcPrqyR5Ymttbm9X1XsymXWv1tpXq9+5/I7W2qEjy7F3+qNP9ki/yOHrI79CqupKrd+ZtFBjt8mL2p5MWQaLMKwDl0t/vMJ3FjC967bWxtytOhtzYGba0NZapnNid0tvP5xtgzu6tTa2B4DJFlmGze4bt7sezZRjU9vUKfWwqvZanVfZrAnlv3t6buXTSX41/TEyb6mq/dO7Jr/XIsq3M1XVJTZyfLtV2+RN22gWcpmGDFcO7uz49L53r76zypD+cOKTs/mHEz8h/SqUY9LvUPrv9Dve3pfkL0fEr/Vsjo081HZS/DCNj8y8/oP0O8uekH77/JgH865+sO7Ts7EH6059MO/kh2QbdrhsL7HN87/4dsafl4Ykbxvxmb2H7diLs+ruziTPHhF/YPqVcc9Kv0Lyr9PvkntVxl8dNGkaC4g/PMl+w+tD06+S+2z6lWc3GxF/bPpzOS6/3mfnTGOv9OeBnJjewHL6sJ95wMj4PZL8YfrVhiv9uL8tvXuXcz0vYYNle+6Iz+w+zP9vsurO2ySPnzDvdZ9TPPPZa8683nP4Td6U3o3NmKvMtjV+QWV42Exdvnz6cckZ6VeAXmNE/OXS797+26FO/nv6VeivznA1+Drxu6V36fzm9Is0jk3yiiQ3H/n9dxR/sw3Ug6llmK3LN95oXd7uerSDOvCdsXVgiHtd+t3757rDyWD4ZR8yXNG9E+d3cIa7J9J7y7lrhvPmEbHnS/pFz8P/t0i/I+O2G5j/pGlk5J0fW/kdtvM3WGe6o3t5WiP2oQv6blfeRMze6XfqXHQTsQcOsdfLqt5uNjGthayLY/Z1C1qXHpD+uJRPp98h9fn0dqTTktxzRPzBw/HM6enPOf5sem9Zr8i4Y7Sp6/LUY8RD0++se0l6QvmI9HOeo5NcZwPLcfec3Q60xzDdUeec60xzcq8zG5jfbjm7t6bzpV8cP6o+L6gubnr+a0zrCul3B224l6Q1pjVqm5iZY+VNzue6awxfSr/J4bpbPf+Z6ew/zPOaY7ZDM3GT1sWZ6VSSG6Z3BXzn4XVtIH5h9WgTy+73Zl4fNGxLz0i/s37d5xEOcZO2qTPTWevZlPttIP7QJHdK7+1m9D55geW/2FCGfTfxO+yT3pZ2cvojyb6Vftfu4WOml9473J+lPyLvAun7yTelJzrH7JsvtsZwSvod7Ruqi5tdH3cwrU0fo216psswZJNdeSwqfmeVIQt46H2GA4/0bjhWHpJ7wYzrfuO4THuo7aT41d8z/UBu/+H1hTOuC5KpD9bd1vjhcysbwJM2uQGcmoyZFD98bmoyZdJGODNdIwzL83npyYyXZUTXzJmezJkUv1J/0httLzfm82vEr3WC9J2MPEHK9GTSWgfF100/Wf/qiPjXDsvxjuk78Ndm6C5z9bq1g/i3J3l4+h3wJ6TfNXzpYdwbR36HSdNYQPzsQ7aPzNA9U/oV7WO6kflCen/rp6Z3y/yoDA8M30A9emP6QdRBSR6dfqHKFdOfkTjmIdUvT98W3GiYxkHD6+ckeeWI+LW2BRdL366s281Ykv9IX+//JP2O9X+aeW/dejR87syc3bXVyvDzlfEj4mcf9P209C5VbpZ+0cuLlj1+QWU4ceb1W5LcaXh98wwPj18n/n3pV30fln5y+phhXfr9JO8eEf+C9P3QTdIv9nlS+rOS35Xk4Vsdv6AyTKrL212PptaB4bNfTu+B4dvpxxN3ytAlkMGwqwzpjQJHpTfYPzczCZCM7/rzxunnBiemN7Ydkd5LzWnpd8ttaRmGbfEX0htrHjT8fd5QnkePiP/YyjzTG2w+mH7Me0SSvx+5DOZN4/AR8T8btr+/n801WE36Dun7sFekPxvoLzLT+JfkDTvhN7jzDoa7pPf2MmYZPHrV8Jj0Z8k/ekwZ1pn2mLaTl+Ts861bpx/vviv9fOtuI+czNQkwaV1cwDJYxLr08fRu9S6bfrx7+WH8ARnXhvSh9O72dp8Zt3uSe2Smy7qt+g6Zfoz4kZz9nKrT0ntVSpJbJvnQyGW4ZRcZZERjfhazX7ljek9xX03vLerD6QmRLyX5nYm/45ht8tT5HzmzPbhvepL8P4b6PeY4exHbxJ+nJ1H+Jpt75MtZw3I7cmb44fB3TF2eOv+rpm9DP5venfOH0/czL0yyz4j41evin25kXRymcauc3f3pfwzDSvent9oJ9Wjq8dHs+dKrkjw4Pcl5p4x4pNgQN3Wbeovh+34zvQvcQ9Yq35z4m6XnIt6VnhB9c/pNPu9JcumtLv+I6Y/ZJr4jve3twJlxBw7j3jki/lXp57vPHurPv6Y/z/wfkrx4RPxZw7ozO/x0+DvqMTgLWB8Xeow26UfbGUPOvoNh9fDxjOgTf2r8MpQhq/oGTm/Uf3v6cxqOHxF/3Fqvh//HxO+W3uh8RIb+zMdW+EXED5//WHri6Fx9r6/+TjuIf3XOfibGC5IcOry+Uvot80sdP3x26gZwajJmUvzwuanJlEkb4ZxzZ/4f6VdLXWaon28YET81mTMpfvjsFzIhIZSJJ0iZnkz6efqzEY5cY/jhiPjjV/3/l+kHMxcfWY+Pm3l96rxpb9U0FhB/Us6+4vWoVe+Nuchidj24afpB0deG3+DBI5fB6ud6HD383S3jnu25wzv65r23qh59ftW2YOX/n4yIP2Hm9R7pJwevS3L+jHxeQPozXl+Ucz7z+QtjYteoB8dnaDhMvwpz1AU/2xm/oDJ8aub10ave2+h3WL0urfs7rp7Hyvo01IOTtjp+0WXYTF3e7no0tQ7MliH94qf7Jnlr+gUvL8iIhgaDYRmG9Geu3yb9OV5/mp6MWGnEP27kND6S5Brpj7n4ZoZnpqRfvDXmQo1JZRg+f8H0Y7Izc86LQMc8e/wTM6+PSXLB4fUeG9geTJpG+vn5byd5afoFnG9Mb/C64E6a/xHpvTZcO/254x/M0KvJTvoNfpreMPWCNYZ1nz8/TOPM9Oe+/9/0XnmekN4A+YQkTxgR/y87GJ6ZcRdtzZ5vfTBnP8duv6w6fp0zjamN8FPXxdWNfrONf9/e6no4fPb4mddfWfXemLr8mc28t6jvkOnHiJPih89NTu7OmfaY5PIi9ivHpbc5rSSXf3UYf5mMa/+Y/DsucP5H5+zt6YVGzn8R28Tjklw9/dmcnx3qxWEZeXdWegLzvZlJRmeD55wT53/UzHK/QZL/HF7/QZLXjJn/jurtBurhSWuVd6gXY86XptajqcdHs+0vx29yGUzdph6d5GrD67um7+NutIHvcFzOPqa4bJLXD69/M+PaoyeVf8T0x2wTP7WZ91b/dunnuV9LfvFIwbHnvY9JbxO/xsy4L2zwe05dHycdo60e9sjyOyD9CrMzVo2v9J3yVscvQxm+XlXXbq0dnyStP4Put9NvIb/GiPifVNWFWu+v/Hq/mHnvm37dZzO0/vyGp1fVq4e/X0/G152p8YN90q/AryStqn6l9f7k9xrGredBSZ5RVY9PP7D/UFWdlp5UedAuEJ/0nehTZke03g/6U6rq90bEX761dpfh9Ruq6i+TvHt4TugYU+OT3vj+zCSpqofOfJ9nVtXvj4h/bPpO67GttY8P0/lCa+2yGyjDikNba9ceXj+9qu4/ImaPmWdLXLC1dnSStNY+XVXn3wnxSXJGa+1Pk/xpVd00PTl4bFWdlOTlbZ1nM6Q3+L4tSarqKa211wxl+O+q+scR8z+ktfbC4fU/VdXRrbW/qaoHpj8jdL1+6U9K8oettc+sfmNYJ9Zz/qrabdiupLX25Kr6cvoVcHuNiN9t5vWLVr23+4j4RUxjavyzk7y1qg5P8vaqekZ6EuHX0xv1R2utvT/J+6vq4enr1t3TkxLr+UFV3aS19oFhG/DtYXpnDc/QXc+3q+puSV678lsOz0m4W869r1zL55PcsrV26uo3Rtaj8628GNbHB1fVE9IT3mPqUVprjxieufPyqnpD+pVqbUzsYJ+qunP6Puz8rbWfDtNtVTVmOtsdv4hpvKaqXph+d97rq+pPkrw+vS6f67ddw1lVdaX0E7wLVdWhrbVjqj83e8y69NOqunxr7XNVdd30q/3SWvvxyPJPjV/ENKbW5X2q6k7p26XN1qMp8VPrQDKsd62176X3pvDi4XlDd0tvNFn32duwBC7SWnv78Pofq+qj6fv4+2b8vmXPmePj01trH0iS1tqx1Z+9vdVl+Hlr7YdV9ZP0uyi+Ncz/B+MODfK9qrp6a+0T6edLFxims0fOeey0ldP4aWvtzUnePCyz30lPKj6rqt7R1n9ez9T579/Ofv7iw6vqPkneNxxr7Yzf4IQk/ziU/xyqP5t+jKulX8l/4fTnxv1vVd2/tfbEkfEPTG94+/Ea791zRPxuVbX3sE84K8O+pLX2zaoa2wZxQvpFKvdM8qaq+kF6LxuvaK2dMiJ+6rr4d+l3PvxsjffG1KNFrEunVtXfpz9X8uSqelr6+cZvpN/ts56PVtWz0y88XTk2v3SS+6c3Tm/1d9jRMeIVM+4Y8UdVdav0dqhWVXdsrb2hqm6WnnQeY/fW2sp5zd2T3HRYPw9P733ocfOCq+pfdvRW+vdazyL2KyttTqmqU1trnxrGfXE4d1vP5Lo4cf4/rapLtda+nP4Iph8M43+ccfVgEdvENsT/ZZK/rKobpO9XPjB8p/+zTvBrq+odSf5maPd7TDZ2zjlp/untVivL/SNV9W/D63+vqkePmP/KurhPNne+lpz9fOHVvpz++IV1TaxHU9elg4b1uZLsX1V7rpwzjS1/pm9Tz9daOzFJWmuvGdoPX1dVfz7yO+zeWjt9eH1qekI2rbUjquqfd0L5F7FN/GJV/Vl6Iu7rwzQPSL9pYkwbUpJfnOe+tbXWZv5fdxm21p5WVa9Mb3/+UnpibyPrcjJ9fZx6jHYOu0JS8c3pXX8ev/qNqnrPTohfhjLcL6sOKIeGo/tV1f8bEf//tdZ+PMTNJhH3TF+BR2mtfSnJ3ao/1PZ7Y+MWEd9aO2QHb52Vfsv4evHfTfKA2uSDdbc7fjB1Azg1GTM1PpmYTFm1ET4t/WqKjWyELzFsaCvJ3lVVKzuCjDuonZrMWVgyKNl0QmjqCdLUZNJfZ8fL+uEj4v8rfXm9a2VEa+2FVfW19CuY1/PGGh4y3Vp7/MrI4aD2UyPiFzGNSfGttWdW1cfTuxG5Uvr25Irpz9392xHzP9eDnVt/wPnbh2GMhyT59+HE/MT07ktS/SHZzxoRf48kT0lvpPvOMG7f9Lsl7zEi/p/T715fK+nw1BHxx1TVbWZODtJae+KwTXvOiPiVmI8OJ5QPS7+C9AJjY4fP/87w+qiqOqC19vWqOjD9pHvZ4ydPo7X2l1X1gPSGusun31334PS6fO8R8/+z9G3CWel30T+uqq6Zvn37gxHxj01yZFX9OH09ukfyi3r85p0Qv4hpTK3L70t/JkayuXowKX6oAw/M5utA0huJVk/3W0n+bRhgl1BV+wznDGmtHVlVd0nvGeRiIycxe3y1urH6fBlhYhmOraqXpTdU/HeS/6yqt6cft31yRPwfJXlpVX0s/Tk7x1TV+9Ivov27MeVfwDR+cSzbWvtheldXr6p+Me4dd8L896yqC7TWfjSU4SXDMe470pfreqb+Bn+SHZ+nr3vOnSStX/B1t6q6Q5IjqurpY+JmHJ1+d9G5Lr6uqr8eEf/E9P3qs9J7M3l1Vb0pveu3sce5Uxvhp66Lx6b3ovPR1W9U1ZgLkhexLt0nyR+nP+7isPS7dB6Xfuz9gBHx90s/P3hikksN476c3uPR83bCd5h6jPhH6ecUZ6XfIPCQqnpBkq+kH6eMMTWhNjXBvoj9SmbagH5vZtzuGVeXJ9fFifN/VJJ3VtVr089Z3109QXeT9LsN1/MnmbhNzKqbIFprH0nykap6TJL/b8wEWmvfT/Ko6hcg/md6sn+sqfP/XFX9VfoFi3fO0G5VVXtmXD2ety6OXZeen+ToqnpFzpmQukfGbU+m1qOp69JjZ14fk95+esZwvvSmMfPP9G3qT6vqwJXkamvtxKq6Zfr55uVHxB9TVc9Lrwe3T+/2NFV1oYxLDk8tfzJ9m3j39P3Ze4e29JbeLe6bkvzuiPhjZtrxZuvR5dPvAFzXTF7k9ul3rV9oTNyMSevjAo7RzmHlVk1gyVXVRdM3gHdIcolh9MoG8PB29lVwO4p/avpt6e9aNf42SZ7ZWrviVsYPn31SkqcOB0Wz468wfIe7rjeNmZjbp98Vd0hr7cCRMU9YNerZrbXTh535U1tr9xsxjZvnnMmc09IbP58/JPu3Ov4VrbUxSZcdxV8rZ58gPWooy/3Td+h/sNYJ/Kr4a6Z3HbuSTPq91u+03D/JPVtrO7p6aHYaV04/kPjwbF1Y3TC+ifjbtuEuzK2c/xZ/h10ifvjsVYZpHLXJMtww/UDuc0munN5F1Cdba28dOf8bpDf6HF1VV01v7Dh5Z8WvMY2bpjdYHbOBMtwwyVkTvsO2xi+oDLPL8GpD/Emb/A5XS+/eeSP16NeS/GxC+SfFL2oaq6b3ojH7syWOf3Fr7b6bjV9EGWBnq6p7pXflf9Sq8Qcn+avW2rqN4MOx8bta751mdvzlk9yltTb3opupZah+F9jd0vftr0l/ltw905MQz2qt/WBO+Mo0dk9/dtLKcfKXkryjtfad9WIXMY2q+tPW2pieO7Zq/o9K7ybtvavGXyf9XOU314mf/BssUlVdOP2Cwhu21kY1nlfVxZL8aHU93uB8r5jeG9Dsb/CG1to7RsYf11q7zhrjK/2C7feuETb7uanr4q8m+VZr7VwX59Rw8c6I7zB5XdpuE9el86XX/S+31t5VVfdOf9bliUme286+S2jeNC6f3mh7UM7uEvelrd8FO6b810zvQeFjw6gbp1+MdY30Z2C/bJ34dyd5/A4S7F9o6/TWtKD9yvXTuxT+0arxh6R36/uSEdOY8jsuYv77JLnXqvm/sbV28nqxi1BV91rvt97g9Cr9zrmx9XDS/Ktq3/R2t6um1+XDW2tnDsv1Kqvr18hpvjnJ7ds5b3pZL+Yq6W2h50hItdbWvWBmaj1axLq03apfCH16a+1jq8bvk+RhrbUnrxO/Z/oFGSv14PmttZ9Xv/v+Eq21L25R0WfLMHWbeMP0c+zvVk+GHpbeLfmJ6Y9y+u468edPT0x+Zdiv3CvJ/0nvjW3sfuVy6fuVS6dfaPKJ9BuHxq7P+2ZB6+NmjtHONY0mqQi7vKp6YGttzJVWSxm/2WkMO7DLt9Y+sd3fYbvjl6EMY+Kr6hHpV72elP68mEe21t44vHdsa+2668Q/PP2usG2JX4YybPcynCnDQ5OcvMkyPCE9+bNH+hVaN0i/2u03008y1zuoXR1/w/S7HHdK/BZ9h10qfhnKsKvHL6gMq69urfTk9ruTpLU2t4vyNeKTfkfLLhG/g2lsaBkAzFNVl2itfWO7y7FdqurTrbUrbXMZLt76Heg7a34LTQLsioYGysel31l0ifRE9TfSnzN6+GaSkzuzLlXVS9OPrS6YfrflhdO7V79lejvo3B67hnOd305PAv5Wevd830m/O+2hrbX3jCzHlITa5AT7edHO3B4MiYeHpdf/Z6bfGXfn9HPgJ7VVF8tvURn2SL/D605JLjmM/nL6uvi8MYmM7bSIY/1d3ZBIenz6nc6HJ3l6+gXVJ6U/2umUEdNYXRfvnv68zZ1WFxdto/uEqdvEqjoxybVaaz+rquemd4f82vT9wrVaa3deJ35lv3Kh9P3BXuk9z90ySVprD1gn/hHpvTy9NxP2K0ulTXwYpsFg2P4hIx5Ku8zxy1CGXT1+GcowJj7Jx9O7g06SQ9K7f3jk8P9xyx6/DGXY7vgFlmH39AOy7yXZexh/wYx7yPW2xi9DGbY7fhnKsKvHL6gMxyV5SZKbJ7nZ8Perw+ub7QLxx06JX0QZDIZlGJIcmN5l8bOSXDz9yuGPp3e/+Ssjp/G69C4L99pkGQ5Nv8DmJelXUB+R3hh/dJJrj4jfK/35qCcOcacnOSrJ/UfOf+/0xrYXp/d+Mfves3fGNNK7MZsdLp7klPQu1y+2E+a/R5I/TO+m84RheFt6F4J77oTf4Mz0fdH3htdnpt+hdWaS7y2gnr9txGcOT7LfTJ38fJLPJvniyP3KhdK723ts+l0A90/v2eepm103NvE99xm+x8npj4r4Vnrj8eFJ9h0R/7CZZXCF9MTWd5J8OMk1RsTfZlVZnjfUpZclOWDkd3hHkj9PcuDMuAMzPKt4A3XpzGyiLi1gXTph+LtHeu9Ouw//VzZwjDdTp94zvD44I8+XtntIcs2Z13umJzXelN7t6IUWMP0x6/PU33Hq9mCt/dp30vdr1xkR/6r05489O71L6X9NctP0Z56+eORy2jvJ3w/L4F6bWAYvTz8+uFH6XbMHDa+fk+SVI+J3tF94wMjyzzs2GLMMJx+np58vPD7J5TZZV6f+BpPWpfRt+EPSt5+fSO/C89LpyeJ3j/wOk+rizDK8/DYtw0n7hEUM6b0h/WJ5rHrv+BHx275fydnHFydlc8cXk37H1cOu8ExFIElVnbCjt5IcsOzxy1CGXT1+GcqwgO+wWxuuomqtnVK9O9jXVNVlhmkse/wylGG74xcxjZ+1/hzH/62qz7Whu4fW2g+rakw3KNsdvwxl2O74ZSjDrh6/iGlcL8kj05/79NjW2vFV9cO2TtdsSxR/6MT4RZQBlsELk7wl/W6aI5O8NP0q5jumPxv0DiOmccP07u3/pareld4Q+ZbW2k9GluHZ6c8r3zfJB5M8qrX2m9WfufOc9Kvq53lp+p1At05/Ns2Fk7wiyeOr6ldba3+xTvwL0rsXfG2S36uqu6Y3ePw4vQF1jKnT+GZ6Y/WsS6U3xrUkl9vi+b84vcH7r9PvaEp6A/L90xtl775O/CJ+g33Tt6VfT8Z1KTar+jO/1nwrvXeL9dyutXbY8Pofkty99e7Br5SeFDt0nfgXpj9e4oLp69RJw3Run16P1+1eu6r2Sk9M3iV9+f8kvbv+f2utvXDEd3hV+l04N2/D86uqP27j/sN7t1on/iGttX8dXj8jydNba68fjrf/Lb0bzXn+Lmc/P/Jp6Q34v5N+h9X/y7jngx7SWnvK7Ijhuxxe/VnI65lal6auS7tV7wL1wumNt/ukN8CePz0pMMYe6Y3e509PzKS1dmr1bgDXVVV7p3dTd6kkb22tvXzmvWe31h66TvzUevjC9K79kt7gfPH0+nDH9Ho05tEvU9fnqb/j1O3BvP3as7P+fu1KrbXfrapKX49+o7XWquoDObtb2/WsXgZ3ycaWwfXaue/m+lL6s8w/PSJ+3n7hSiP2C1OX4SKO0y86zP891Z8z/PL0hOpXRsZP/Q1emGnr0kVaa89Jkqp6aGvtacP451XVw0Z+h6l1cWUZHrlNy3Dy8cU8VfW21tpt1/nYbA93H6uqQ1trxwzbkzF3/G77fiVnH1/cYpPHF1N/x3NaK9NoMBiWb0i/EuLaSS6zajgkvU/npY5fhjLs6vHLUIYFxL87q652T9+xvijJz5c9fhnKsN3xCyrDhzNc1ZeeoFwZv09WXTW2jPHLUIbtjl+GMuzq8YuaxvD5g5K8Ov2q1Q3fdb6rxy9qGgbDdg2ZuUJ5df3NiKunZ6eRfhXyfZO8Nf2OhBckudXEMhw3Iv5jq/4/evi7W/ozbNaLP37V/3+Z5H/SG+/GblMnTSP97oG3Z+ZusCRf2MDvOHX+n97Me4v6DYbPXi/9OO8RQ9znx37/If7nQ/yRaww/HBF/UpI9htdHrXrv42N/g/Skx9dy9iN/Rt1JMHz2jUkeMOxXHp3kr9KfJ/+f6c9dWi/+U5t5b63PrPyGM/+PuRvi2JnXq+vk8evFD597Z3pC64CZcQek3734rq2uSwtYlx6VflfbF4f5/3eSf0+/U+QJI+IfmX5357+n33H6wGH8/kneN/I7vDY9AXHH9LuaXpvk/Kt/oy2sh8fNLs8MdztvcF2Yuj5P/R2nbg9ml8Fm9mvHz7x+/qr3PrZe/IKWwVHpz8qdPU/YLf0ikw+PiJ+6b560DGc+u+nj9Jxzm3bT9GTm14Z6+OCd8BvMLoMNr0tJPpreBfL10y9eOnQYf4UNrIuT6uJ2L8MhZurxxXV3MFwvyVdHxO+TniD+XPo5+E/T9xPvTe/+dL34ZdivTD2+mPw7niN+owEGg2F7hvRuS26yg/detuzxy1CGXT1+GcqwgPiDMtONzqr3brzs8ctQhu2OX1AZzr+D8ftlXLdO2xq/DGXY7vhlKMOuHr+oaayKu11GNDSdV+MXNQ2DYWcPmWkQSvK3q94b2+B0rsaA9EaCP8qI7rWSfCj9Cue7pTeY3HEYf7Mkx4yI/2CGY8T0u8LeMfPemIaOkzLTaDqMe0B6l21fHLkMFjGNlYbPf0pykWwsETJp/pneeDzpN1g1z0ckeX9GXvg4E/uJJFfcwXunjYh/eHpC69fT79h8xlAHn5hxXbwdP/N6s0mAqY3wkxJySZ6c3vB5ufQ73f4k/SLOByZ584j4L6UnoR6T3gBaM++N3Z5cNMlT0hs+z0i/G+OkYdy6XQFPrUsLWpcvmeSSw+t9k9w1yQ02UIarDTFXHhuzo7o4/L/RRMbUevj59LtT75KZbv/WmvacaUxdn6duE6duD6bu1/4ja3SbnOTyST6wM+py+sXbr0x/pumnh+Ebw7jLjoifum+etAzXmN6Gj9OzRvIy/fERt0nygp3wG0xal9KfufepoRw3Sb/A4DPD73jHkctgUl1ca5uzM5fhTMyU44tJFznMTGfvJNdKT0aO6hJ8Jna79ytTjy8W8jv+InYzX8JgMBgMBoPBYDAYDAbD9CH9eUdrNRZdIclrRk5j1FXOc+Kvlf4ctbcluXJ64+0ZQ0PDmAuGrpnkI+ndd34gvauupF+B/YgR8U9N785r9fjbJPnMyO8weRozMbdPT/J9bQMxk+af6Y3HK7/BGZv5DdaY3q8k+dYGY+6a5Fd38N4dR07jFsN3Pi79DoC3Jnlwxj1XchFJgKmN8JMTcukJxA+n39VyZpJPpndrus+I2CesGvYfxh+Y5EUj5/+IJJfeaJ2ZiT9fepeAvzH8f9/0hvmHjvwdF7Yub9eQ6YmMqfXwBauGA2bqwX+P/A6T1udF/I7pz+Db7PZg0n5tmMYNklx/eH3V9IT97TKTrN/KZTCsS/dP8pvpCel7p99l9scjl8Gk/UJ6L1WTluHUIckrJsZP/Q1ekOT5U9alNab55tXbh3U+f/6cc5t6r/S7PsfWg+1ehpP2CUPMpIsczgtDJh5fLGKbPDusdAUBAAAA7GRVdcP0q9+/V1UXTHJYepdOn0y/ov+7I6dzgySt9WdOXTW9keDk1tpbR5bh5Nbad4cyPG4ow4ljylBVj0jy+tbaaWPKOqI8N0lvzP1Ea+2dI2PW+g7XyQaWY1VdOf0ZaB9Ovyr+8q21T1TVbVprb18ndtL8h2f13DPJV9Kf43ib9OfnnZjkua21uc/8WTX/C6VfuT66HlXVm9YY/evpdwaktXb7efEzZZityxtdBpPqUVWdP/3Ozq+01t5VVfdK8n/SG93WXYbDNK6Znpy8Yvqy/73W2qerav8k92yt/cuIaVw5/a7Xo9rwHPJh/Lr1aAfTe3Frbd3nQe4gdjPr0neT/CC9m7iXJXl1a+2bG5jnS9MfjXCh9AsNLpz+XLdbpidj7r9O/OR1ebtV1VOTvLO19q5V42+T5JmttSuuE7+IenjDJGdtZp+wg+ltuC4tOP6mQ/zHx8QvYL/2hCS3Ta/LR6Q/u/jI9ATfO1prTx5RhqnbtJV16YJJvptp69KG9wtrTG9Dv8EiLMl+5R5JvryZ/cqC9q2rt6l7JXldej1Ia+0BI6bxi+Obje6XFliPN7VPGKZx1/R696k13rtja+0Nmynbrmbq8cWcenDb1trbNlQWSUUAAADYHlV1YvrzXH5WVc9N8r9JXpPe2HKt1tqdR0xjUuPnGmX4QXoXXaPKsEYS4jWttdPXK/dM/EdaazcYXv9B+tX3r0/vdu2/WmuHj5jGpOU4NJr9cXpD4bWTPLK19sbhvWNba9fd4vlPbTyeOv9j0xtp/yNJS39e1MvTG1PTWnvvvPgFlWHRyawNN7yuM/0HttZesM5nptajSQ3Qq9alByV5WDa+Lh2X3jXcb6QnaW+f/lywlyd5XWvtzHXiT2itXbOq9kjy5fTu4n5eVZXeXeA114mfvE1cZmPq0dT4NfYJN0jynmwsITZpu7zg+AcN8W/YQPzU/drH09fh86c/f+6gmcTWh9erx8M0ZrdpL0/fpm1k37it69Iav+FDs4HfYBEWvF/ZzG8wab8ybE9PzLR969R68PD0fcFm90vbWo9HTH/SNnVXsYDji0n14FzaEty+aTAYDAaDwWAwGAwGwy/jkJln9GTVc2+y6rlcc6bx8fTn41woyfeS7D2Mv2BGPEdtahnSu6bbLb2h8XlJTk/y9vRu2y4yJn7m9dE5u8vGC6dfmb7ly3FYhnsNrw9JcszQ4HKO8m3h/E8Y/u6R5OtJdh/+r530G+6W5FHpCYhrD+NGP1NySerRpGU4Yvqn7oR6dGySl6R3+3iz4e9Xh9c3G7MMZ15vdl1a/dvtmZ5YfHmS00fEfyK9u7uLpnfferFh/AWy6plkW1GPln0YU4+mxmfiPmERdWkJ4idvj9Z6PTZ+JW7iNm1b16VFbE+mDov4DhN/g6n75kXsW6fWg6n7pW2txyOmP2mbuqsMC/gdJ8WvHvYIAAAAsF0+MXOV9ceq6tDW2jFVdaUk63bXOPhZa+3nSf63qj7XWvtekrTWflhVZ+2EMrTW2llJ3pnknVW1Z/pdMvdM8o/pz2+aZ7equmh6o1W14Qr41toPqupnI+a/iO+wWxu6gmqtnVJVN0/ymqq6THrj4ZbPv3oXqBdOTwTsk/68nPOnJ3W2dP7D7/f0qnr18PfryYbbjJahHk1ZhqmqE3b0VpIDRkxiaj06NMkjk/xlkse21o6vqh+2EXezrMx/AevSOcrZevd+b0rypupdKK7neenPfNp9+B6vrqrPJ7lRkleMiF/ENnFbTa1HC6iHU/cJyfS6tN3xU+vRT6rqQq21/02/czdJUlX7JBm7DKdu07Z7XVrE9mSqXXq/sqB969R6MHW/tN31eBHbxPOCqb/j1Phz0P0pAAAAbJOhgfIZSW6a5Jvpzzs6bRge0Vr72IhpfDjJLVpr/1tVuw2NPyvTPrKt3yXSpDJU1XGttevs4L2VRtl58aekN9JWevdgN26tfbWq9krygdbatefFL+g7vDvJo1trx8+M2yPJ85Pcu7W2+xbP/1FJHp7e6Pa0JHdIstLo9prW2hO3cv5rTO926b/DX2wgZrvr0aRlOEzj60luneSM1W8l+WBr7ZLrxE+qRzMxByV5evqdMbdvrR08Mu6UTF+XrtRa+/SY+c2ZxiWTpLX2laraN70r1VNbax8ZEbvQurwdFlCPpsZP2icMnz0lE+rSEsRP3R6dv7X24zXG75fkV1prH58XP3x20jZt+Ny2rUuL2J5MdV7Yr6ya3ob3rUPclHow9fhmW+vxED9pm3hesIDfcSHHJ7+IlVQEAACA7VVVeye5bPoV7F9qrX19A7GTGz+nlGERSYgdTPdCSQ5orX1hAzGb/Q4Hpd/d87U13rtxa+1/tnL+Q+ykRrep81+U7axHC2i4fF6SF7TWPrDGey9rrd1rnfiF1KOZmE01QK8xnQ2vS9ttGeryZi2gHk2NX8g+YQfTnlSXdnb8dtajrdo3bqIcC10G27E92ZX3K9tt6n5pGerx1G3iecECfsfFHp9IKgIAAAAAAADz7LbdBQAAAAAAAACWm6QiAAAAAAAAMJekIgAAAAAAADCXpCIAAAAAAAAwl6QiAAAAAAAAMNf/D+yNOjcndcyZAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 2304x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(32,6), sharey=True)\n",
        "item_means.nlargest(50).plot(kind=\"bar\", ax=ax1, title=\"Top 50 items in data set\")\n",
        "item_means.nsmallest(50).plot(kind=\"bar\", ax=ax2, title=\"Bottom 50 items in data set\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGLa04uYQRt"
      },
      "source": [
        "## Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0QEq-vnYohN",
        "outputId": "183d2ce2-65c2-49c9-ca8c-7f216083e4bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     151254\n",
              "unique    151199\n",
              "top             \n",
              "freq          22\n",
              "Name: reviewText, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['reviewText'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "OLw7n7EcbEKV",
        "outputId": "ffd1376f-19a1-42f2-a991-e490d04d84d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean        509.002142\n",
              "std         524.745639\n",
              "min           0.000000\n",
              "25%         191.000000\n",
              "50%         353.000000\n",
              "75%         644.000000\n",
              "max       29569.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# review length\n",
        "rv_le=df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTgNznNQ8aR1",
        "outputId": "3c1809ac-2fc3-4d67-ce83-7253c8687332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per user: 10.302704175464887\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per user: 5244.098494652953\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in user_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(user_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(user_df['reviewText']))\n",
        "print('mean of reviews per user:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per user:',r_mean * w_mean)\n",
        "# plot for reviews per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nje_ix7gAaf3",
        "outputId": "c3260e88-aa4f-46f3-aa38-85cbb25e0219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per item: 17.359577642603007\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per item: 8836.062205899232\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in item_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(item_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(item_df['reviewText']))\n",
        "print('mean of reviews per item:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per item:',r_mean * w_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMysaUvxxU3"
      },
      "source": [
        "# **Embedding Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WovD0fA5q-J6"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "embedding_dim=300\n",
        "min_frequent_word_num=50\n",
        "max_vocab_size=5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_word2vec_model():\n",
        "    if os.path.exists(\"word2vec.wordvectors\"):\n",
        "        print(\"loaded from word2vec.wordvectors\")\n",
        "        return KeyedVectors.load(\"word2vec.wordvectors\",mmap='r')\n",
        "    else:\n",
        "        # downloading google news word2vec model\n",
        "        if not os.path.exists(\"word2vec_google.bin\"):\n",
        "            downloaded_model = api.load('word2vec-google-news-300')\n",
        "            downloaded_model.save_word2vec_format('word2vec_google.bin',binary=True)\n",
        "            del downloaded_model\n",
        "        # loading google news word2vec model\n",
        "        google_word2vec = KeyedVectors.load_word2vec_format(\"word2vec_google.bin\", binary=True)\n",
        "\n",
        "       # tokenizing the whole reviews in text_corpus\n",
        "        text_corpus=[]\n",
        "        for k in range(len(df['reviewText'])):    # iterate through each sentence in the reviews\n",
        "            for i in sent_tokenize(df['reviewText'].loc[k]):\n",
        "                temp = []\n",
        "                # tokenize the sentence into words          \n",
        "                for j in word_tokenize(i):\n",
        "                    temp.append(j.lower())\n",
        "                text_corpus.append(temp)\n",
        "                del temp\n",
        "\n",
        "\n",
        "        # creating a new word2vec model and initializing it from pretrained google_word2vec\n",
        "        word2vec_model=Word2Vec( text_corpus,max_final_vocab=max_vocab_size,min_count=min_frequent_word_num ,vector_size= embedding_dim,window = 1,workers=16, sg=1,epochs=1)\n",
        "        word2vec_model.build_vocab(text_corpus)\n",
        "\n",
        "        word2vec_model.build_vocab([google_word2vec.index_to_key],update=True)\n",
        "        word2vec_model.wv.vectors_lockf = np.ones(len(word2vec_model.wv))\n",
        "        word2vec_model.wv.intersect_word2vec_format(\"word2vec_google.bin\",binary=True,lockf=1.0)\n",
        "        \n",
        "        # fine tuning the model and saving it\n",
        "        word2vec_model.train(text_corpus, epochs=5, total_examples=word2vec_model.corpus_count)\n",
        "        word2vec_model.wv.save(\"word2vec.wordvectors\")\n",
        "        \n",
        "        del google_word2vec\n",
        "        del text_corpus[:]\n",
        "        gc.collect()\n",
        "  \n",
        "        return word2vec_model.wv\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded from word2vec.wordvectors\n"
          ]
        }
      ],
      "source": [
        "# loading the embedding lookup matrix shape=( 5k ,300 )\n",
        "embedding_matrix = load_word2vec_model() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5004, 300)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "special_token_embedding = np.random.rand(4,embedding_matrix.vector_size)\n",
        "full_embedding_matrix = np.concatenate((special_token_embedding,embedding_matrix.vectors))\n",
        "full_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example\n",
        "# embedding_matrix['keep']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVT3Ur54LsIz"
      },
      "source": [
        "# **Text Vectorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4QVJNF8EGGe"
      },
      "source": [
        "- The conversion of tokens to ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Wgb-wnWWozZ3"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "sequence_length=20\n",
        "review_max_length=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_V0IYdnB2s"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PP90xBH8aZ2b"
      },
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "\n",
        "  #sos and eos are not used in docs but we need to add them manually in the decoder\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BeaTIprJ6Uz_"
      },
      "outputs": [],
      "source": [
        "# input text processor is in charge of maping tokens to ids and vice versa\n",
        "input_text_processor = tf.keras.layers.TextVectorization( max_tokens = max_vocab_size+4, standardize = tf_lower_and_split_punct, output_sequence_length = review_max_length )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text_processor.set_vocabulary(['','[UNK]','[START]','[END]'] +  embedding_matrix.index_to_key )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlGMIsZTV2oI"
      },
      "source": [
        "* some example about how to work with input text processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ZwtcZjLM6XCZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_text_processor vocab size : 5004\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', ',', 'the', 'i']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# included sos, eos, unk and space \n",
        "print(\"input_text_processor vocab size :\" ,len(input_text_processor.get_vocabulary()))\n",
        "# Here are the first 8 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Rbn35v_Unwr1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text_processor.get_vocabulary().index('just')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LSWPZQ_tH8np"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sent'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text_processor.get_vocabulary()[1240]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ouk6_52DSBaW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....\n",
            "tf.Tensor(\n",
            "[   2   42  288   41   12 1527    1   19    6   37   13 1136    9    8\n",
            "  116  206    4    6   92  246   17   13    1   13    6  118    4    7\n",
            "  248   10   29    8  116  387    4    4    4    4    3    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(100,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(item_df['reviewText'][0][0])\n",
        "print(input_text_processor(  item_df['reviewText'][0][0]  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3726"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt = np.dtype( [('userid', 'int32'), ('itemid', 'int32'),('rating', 'int32'),('review', 'int32',(sequence_length,) )])\n",
        "tt=np.empty([150, 1], dtype=dt)\n",
        "tt['rating'][50][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['A1U6M8VJHK2ECA', 'B009M516NE', 5.0],\n",
              "       ['A244CRJ2QSVLZ4', 'B009M516NE', 5.0],\n",
              "       ['A1SB9BNNGKNX2Z', 'B009M516NE', 3.0],\n",
              "       ...,\n",
              "       ['ASEBX8TBYWQWA', 'B00KCJRVO2', 5.0],\n",
              "       ['ANKQGTXHREOI5', 'B00KCJRVO2', 4.0],\n",
              "       ['A2CF66KIQ3RKX3', 'B00KCJRVO2', 4.0]], dtype=object)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data=np.empty([train_df.shape[0], ], dtype=dt)\n",
        "test_data=np.empty([test_df.shape[0], ], dtype=dt)\n",
        "\n",
        "user_to_row = {}\n",
        "item_to_column = {}\n",
        "\n",
        "\n",
        "for i, user_id in enumerate(np.unique(df['userID'])):\n",
        "    user_to_row[user_id] = i\n",
        "\n",
        "for j, item_id in enumerate(np.unique(df['itemID'].tolist())):\n",
        "    item_to_column[item_id] = j\n",
        "\n",
        "train_rw=input_text_processor(train_df['reviewText'])[:,:sequence_length]\n",
        "test_rw=input_text_processor(test_df['reviewText'])[:,:sequence_length]\n",
        "train_rw\n",
        "test_rw\n",
        "for index, row in enumerate( train_df[['userID','itemID','rating']].to_numpy()):\n",
        "   \n",
        "    train_data['userid'][index]= user_to_row[row[0]]\n",
        "    train_data['itemid'][index]= item_to_column[row[1]]\n",
        "    train_data['rating'][index]= row[2]\n",
        "    train_data['review'][index]=train_rw[index]\n",
        "\n",
        "for index, row in enumerate( test_df[['userID','itemID','rating']].to_numpy()):\n",
        "   \n",
        "    test_data['userid'][index]= user_to_row[row[0]]\n",
        "    test_data['itemid'][index]= item_to_column[row[1]]\n",
        "    test_data['rating'][index]= row[2]\n",
        "    test_data['review'][index]=train_rw[index]\n",
        "\n",
        "#for index,row in enumerate( train_data):\n",
        " # train_data['review'][row]=train_rw[i]\n",
        "#for i,row in enumerate( test_data):\n",
        "#  test_data['review'][row]=train_rw[i]\n",
        "train_data\n",
        "test_df[['userID','itemID','rating']].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
              "array([   2,    7, 1599,  170,   83,    6, 2656, 4357,   12,   14,   55,\n",
              "          5,   19,    6,   41,   13, 4950, 4028,    4,    7])>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_rw[50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       tf.cast(train_data['userid'],tf.int32),\n",
        "       tf.cast(train_data['itemid'],tf.int32),\n",
        "       tf.cast(train_data['rating'],tf.int32),  \n",
        "       tf.cast(train_data['review'],tf.int32)  \n",
        "    )\n",
        ").shuffle(1024).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       tf.cast(test_data['userid'],tf.int32),\n",
        "       tf.cast(test_data['itemid'],tf.int32),\n",
        "       tf.cast(test_data['rating'],tf.int32),  \n",
        "       tf.cast(test_data['review'],tf.int32)  \n",
        "\n",
        "    )\n",
        ").shuffle(1024).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2510, 0, 4, [  2,  36,   1,  23,  47,  34,   5,  19,  43,   1, 276,  16,   8, 189, 250,  55,  41,  18,  62,  40])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 4000   548 11970  2462   417  8897 14030  2447    93   534  4930 10795\n",
            "  7340 12084 13502 12692  5062  2736  9170  3618  3345  2149   177  3326\n",
            "  3250 12920 10123 12233  2977 11815  2879  9378], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3742 11935  8949 11970 13515  4275  2653  5545 10210  7041  5779  2411\n",
            " 13375  5250 12466   909  1039 11916 13273 11626  2977  3735  7558  7839\n",
            " 13859 13490  7609  8767   886  5718  6631  8198], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13487  8746  4817 12322 13914 11477 14635  8283  5729  6849  3218  2302\n",
            "    12  4462  3358  2755  9147  4729   713 13763  2904  1266   756   861\n",
            " 12771  6666  4813  8849  2202 10341  2363  8994], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13051   466  2968  5509  3840  5721  3384  7523 11924  1090  4242 13557\n",
            " 14437  1622  1045 14051  1030 11814  8982  8908  1205  9143  1842 10198\n",
            " 11883  9466  8430 11776  3163  3785  9116  3436], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8294 11458  8129 10987  2180 14534  1030  5650  5415 12301 11729  4511\n",
            "  3749 12284 11118 10597 10167  8544 13051  8086  5672  8275 13192 13940\n",
            " 11336  9344 11393  3971 13576   739  9390 13625], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14174  1376  4272  1697 14342  4626  1052  3963  3642  2778  7640  7287\n",
            " 12478 11043  2824   113 10199  1834 10148 14142 13601 11238  1867  2447\n",
            "  7993 10264  5300  1847 12352  7438  4726  2720], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12851  5468  7778 10370  3817    88  3738  6912  3179  3785  2485  2677\n",
            "  7197  6572  6408 11652  8556  5286 10606  9206  6377  9746  9850  3046\n",
            " 12694  1545 14307  8981   616   877  7313  7270], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13636  3687  1408  6249 12068  1543  3836  7122  3310 14589  1215   602\n",
            " 10849  9346  4802  4368 10191  3042  6975 11118  9093  6549  7380    43\n",
            " 11222 11009 12334  9548 11680  4857  7442  9777], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14452  1267  6982  2200  9067  5616  6341  2396  2381  4830 11384 12759\n",
            "  9577  8048  6047  9661 10933 11755  8762  8195 12071   131  1636  2674\n",
            " 13506 13999 11970  5185  6216 14220 13675  4219], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1823 13544   596  9347 10127  8327  6688 12466  6491  8172   943  8288\n",
            "   587 11313  3826 13182  8364 13321  8300  7408  3455  3168  5369  7915\n",
            " 11161 13192 13298 14005  3597  6976  7636 13249], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3624 10087  7835  2760  8257 11960  4280 11342  5509  9484  6437 11895\n",
            "  4488  9020  7236   385   941  4997  8276  9390  5821  7747  4719 14352\n",
            "  5983 10030  2854  1134  1808 11536  5286  5734], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13154  6295 14537 14491  4166  3738 13731  7408  4486  7116  3976  5638\n",
            " 11813  4368  8699  5112 13045  7077   739  8855 11882  3729   964  8246\n",
            "  8071  4161   608  5004  6873  3561  8925  7410], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6127  9316 10692  8993  8291   683  4105   626 12603  7227  3917  9407\n",
            "  3948  3455  8327  5044  8845  4917  6043 10507 10637 13900 12743 12101\n",
            "  9670   417 11010  9316  7746 12848 10260  6265], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6351  1099  8432 11651  3122  4744   612  4467 12693 10405 14369 13472\n",
            "  7548 12322 13789  4242  7187 10536   154 13084 13210  7469   518   417\n",
            "   875    43 12779 10138  1766  3788 12053  9152], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12369  9609  7317  7572 10502 13427  8901  3218 10054  9777  7392 13739\n",
            "  9401  5568 11109  6445 10581 13502  2988 12588 13582 12623 13326  6739\n",
            " 13379 12242  6874   417  9287  6172 11169  6382], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11599  4101   922  7776  7328  3681 13239  9459 11853  4820 10818   410\n",
            "  2703  8725 12941 12985  9666 11093 13845  6591  9396  3971  4304  7410\n",
            "  2399  2841  6005  4844  2372  7548 13293 11317], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3867  8126  3218  2428 11801 10463 11520 10719 13759  5142  1805 13630\n",
            "  6031 13865  5839  2595  9850   267  7197 10021  3218   338  3355 13544\n",
            " 13730  4242  5578  4865  8584  6460 12486  1268], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5532  1752  9732   417  3218   188   224  5938  9628  2582 11243 10807\n",
            "  6062   177  8572  1859 11431 11272  1949 12878  8514   195 11512  4242\n",
            "  4971   753  7292 11903  1527  9285   269  8901], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11856   739  2308  5054   626  9628   640 12795  7745 12082  4660  9389\n",
            " 12865  4170  9316  8804  7372 10835  4426  6218  3247  4509  5507   964\n",
            "  7820 11167  2953  4112  7464  2286  1140 12298], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10138 11200 14621 11970 13204  7689   434  1800 10147  7202  4054  6747\n",
            " 13627  6632  2387   626   459 10618  3483  6747  6463  6401  3226 14253\n",
            "  3153   746 11633    12  6729  1036  8366  7565], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14025  4062  8594 12599  5568 14537  9330   466  7090  4381  9389  3154\n",
            "  5915 13305 11970 11751  5207  1759 11167 13051  8170 12052  6930  4930\n",
            " 11709 13362  7880 12603  2031 13260  5095 13544], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6093 14543 10326  4860  4263 12190  8346  6938 12540  2506  2666  7189\n",
            "  9347 13683  4297  4213  1093   361  7772 12284 13675  9859 13051  2605\n",
            "  1008 14425  3366  7657  1421  3481 14352  1054], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8076   443   919  9067  4998  3393  7646  4405   951 12631  7746  7033\n",
            " 13437  9603 11507  6726  7411  2421  6238  5895 10719  4227  5116 10433\n",
            " 13185  6522 13387  9797  7876 12077 13833  2145], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2877 13124 10749  9232  7684 13159  9315 10369 10326  4200  5780  6276\n",
            " 11417  7793 13232 11320 11545  8007  8384 12404  4815  6544  8371  7588\n",
            "  8743  8346 11661 13759  3021 13158  7565  7323], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13345  4090 10429 14099  4231  2444  5466  4626  7823 13246  6048 12220\n",
            "  7410 11144 14279  4456   444  4904  1216  1542   177 12680 13922  1897\n",
            " 10272  4560  2582   363  4254 11970  1840 14297], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10719  1054  2308  5983  3163  7185  8186 14230  6318  8283    94  5247\n",
            "  1246  2994 10827  6463  3653  7503 13763  6971   989  7197  4105 11059\n",
            "  7706  7656  1149 10254   994 11939 13172 12150], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5132  4816  6892  6532  2422  2488  4160 13083  5891    85  9389 13675\n",
            " 14569 14503  4894 13981 12252  4086  6905  5267  1845  5740  8327  9770\n",
            "  4389  3063  3554  7941 14072 12554  2848  8050], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2131  5657  1975 10304  2662 10691   328   496  4306 14509 12895 12183\n",
            "  2755  2287 12194  5070 12392  1953 14352  6172  5375 14630  6922 13675\n",
            " 12508  5773  8642   188  2960 13645  7107 12538], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3611    65 10719  7713  6099  5657 11034 10556  6956  6265  1527 11305\n",
            "   847 10090  7565  9416  6310 13938  6749   218 13192  1438 13164  9076\n",
            "  3279  4541  6299  4805  8576   280 10592 12956], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2889   818  2007  3485 10719  5832  3640 12312   414 11118  9752    33\n",
            "  7666  2677  3218  2351  3245  6762  2803  7671  5122  9666 14287   942\n",
            "  5799  8577  1949  5095 10463  5170 11167  2004], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11222 13601 13695 14261  4043 10251  8249 14340   129  5354 10513 11243\n",
            "  3911  2327  5651  4086 11287  7125    65  6833 11642  9670  3975 11983\n",
            "  2820  8183  2938 13204 11222   268   790  2847], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9389  1611  3819 11222 11073  8151 13833  1837 13808  7039  7011  8137\n",
            "  7727  7697 10405   786  2582  3193  6012  1137  2392  8158  5539 14606\n",
            "  2507 13773  7310  9389 13945 11167   749  1694], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12775  9446 12195  4766 10319  2754 10449 10569  4640 10274  7438  3272\n",
            "  1527  8691 11003  8177  5275  1530  8944 13759    65  2874 13502  7850\n",
            "   889  3316 10195  6401  7112  7565  7273  7807], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13544  8327  1949 10256 13401  4327 12468 11263  9101 10576  1949  3742\n",
            " 14583  3773  8736  6114   608  9632  6547  3838 12233  1247  7970  7116\n",
            "  5095  7565 14228 10704  5375  3983  6047  6288], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2962  9113  1752   195 14503 12630   221  2853 12907  5487  8587  4960\n",
            "  4117  3438 11918  7139  2272  8982 10405 13512  1825  1907  6343 10307\n",
            " 13810  9772  2352  9205  9097  6104 10463 11117], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8506 13675  4542 14030 12779  2001 12301  9362  1140  4294 12178 12275\n",
            " 14530  1054 12911  9574 14474  4249 10704  1828  8712 11582  3436  4161\n",
            " 14310 12183  8283  8334 10143  7587 11283 14525], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4123  3122  4111  3722   830  8283  5420  1708  2115 14491  6714   739\n",
            " 12340  2230 11934  3836  5617  4865 11983  4960  7565    29 10247  6463\n",
            " 12862 13204  1879 14012  5527 11642 11317  7663], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2744   993  8283  8059  7069  7609 10509  6845 11111  8221  4984 11208\n",
            "  5097 11565 13477  1793  2874  4092  5642 10912  6882  4139  3642 14491\n",
            "  5537 11222  8485  1039  4458  5243  1367  6677], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9861 13632  7747   919 14419  8368 12895  8624  3640  4090   612 13003\n",
            " 10269  3247  9842 11507  1247 10162  4470  7326  6762  3310  1636   686\n",
            "  7185  4452 11509  3681 13544  5547  3887 13675], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9106  9066  6615   548 11294  3785 12907  7609 13051 12100  5197 14669\n",
            " 10293  4774  9199 12379  7572   674  8436  2403 12291 10143 14403  9837\n",
            "  7460  8710 14017  9568  8435  6158  6031  5298], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8749  7247  3403 13047 11167  8313  3136   484 12451 13646 14148  1527\n",
            "  6128  7131  6147  9406  7839  7697  5737 13038  7034  7197  7843  1777\n",
            " 13043  3138  7138  7666  3206  9526   203  9436], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5975  4464  9603  5171  9347  5642  3036   518  1586 10719 10818 13394\n",
            " 14571 10507 11944  8675 10979  2019  8198 11528 11726 10446 10094   850\n",
            "  8158  3785  6582 13503 12147  1752  5733   739], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1538  7609 10199  2467  1254  7341  1990 10372 13506  5964  8436 10304\n",
            "  3544  4816 11391  3669  7505  7389  5713  4000  6172 12997  7580  6573\n",
            "  9122  1813 11703  6654  2802 12895  9506  4447], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1977 14572  3523   669  7355 10700  7227  6912 14537  2507 13759  3706\n",
            "  8405 11600  6463 12692  4368  5834  8585  1036  1556 13558 12786  4326\n",
            "  8371  4147  1661  5893  8962  8436  7224  7392], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7533 11261 12148 11305  3975  8198  1237 12228  1755 13766    33  1823\n",
            " 14476  5509  9423   964 13487  9879   177  7317  6573 12862  9387 13706\n",
            "  6093 10304  9963 12113 10777  1974  3911  3911], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2053 13914 10553  6853  2650  9389  3815   136 10735 10463  6218 12362\n",
            "  7375  6460   752  5595 12024  3993 10320  7924  1133  1273  9994  1752\n",
            "   386  6898  6265 11055  3191   288 11629  8405], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8283  3692  4090 14537 13492  1081 10964 10071 10094 13334 13083 14161\n",
            "  8834 14579 10932  7226  9988  6256   578  4943 12084 14030 13132  7560\n",
            "  9830 10461  4278  5007  8318 14297  5363  3059], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8918 13351 10772  2977  2548 13051  4823 11167 12551  2673  7323 11327\n",
            "  4047 11611 13914  4587 13981  8898  7392  2007  5469   943  9749 11701\n",
            " 13926  6792  8171 10563  8504  1473 11849 11265], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4242 13496  7937 13909  4622  7666 13973 13714  1752  1491  4554  6239\n",
            "  5610  1947  2972  4514  9884 13908  6415  7090  1516 12220 13265  3653\n",
            "  4227  6290  9097 10806  7972  7446   686 12811], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9656  8906  4170 11848  8397   195  2745  2202 10445  7856 10008  2251\n",
            "  4197  7197  6422   288 13420 11727  6491  3420  6365  9338 12078  7060\n",
            " 10905  6579   417 13544  4178   643  8198  9662], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  219  9616  1205  1285  6688  3671  7044 11633 13981   602  9387  7587\n",
            "  9658  7666 11238  7682 11970  2832 11807 13157 10210   858  1456 14525\n",
            "   834 11231  1151 13928  5430   361  3479  2518], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8513  2539  1990  5302  6591   575  6356  3983  3771  9423 14528  8429\n",
            "  7718 12429  9249  7713  1563 13232 10341 14465   417 10322 14175  4127\n",
            " 13002 14314  8845  4752  9216  3218  8525  6630], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10920  1596  6999  8704 13981  5936  9076  1636  8010  7410  7713  6491\n",
            " 13506  8468 10917   520 10502  1439  4752  1967  1207  5017 10684 13386\n",
            "   506  3218  9316  3638 13527 10818  1561 11211], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12178  3317  1573 10804 11474 14437  9797 10719  5265  4724  2007  5052\n",
            "  3206  1949  5666  7323  9862  2044 12299 12429 13323 11239 13907  3455\n",
            "  9158  7566 11222 13879  9066   195  4093 13002], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6401  9055  1686    42 10059  4836 14562 12429  9466  1854 12627  3308\n",
            "  5610  8955 13784 10195 12965  8430  8202  9347  6688 12787 14635 11627\n",
            " 10272 10271  1324   109  2778 12793 13633 12067], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3222 10465  7125  1701  9616  7773  4304 11536  3785 13696 14554  5467\n",
            "  3651 14537  8110 12284  8436  2230  7921  7880  5733  1702 11871  3737\n",
            "  7916  3729 13352  3906  8966 10803  5009 14420], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14054   738  7745  9909  9054  7276  4590  5389 13882  9941  4066 10606\n",
            "  8485 13489  3056  9036  9122 12479 12862  4543 13506   170 11912 13801\n",
            "  6295  4047  1527   739  3534 11231  2129 12836], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9937 11412  7392 11385  6463 10326  3433  4665  1171  2256  7713  2977\n",
            " 12783 12683  3696  4585  6463 12852  3849  3696  2636  6999 11167  3345\n",
            "  3206  8158  2381 10027  1045  6522  7253  7587], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13727  1686 11729  6461  1039 13893  1879  7956  9697  1655  7125  7681\n",
            "  1149  7323 12539  6844  6228 13171  9941  4368  9406 11479  9658 14030\n",
            "  5761  6412 11102  8243   450  4626  6039  3455], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11445  6626  9520  1831  4814  8824 12204  6653 10468 11922 12584  3696\n",
            "  9658  6762  6573 10932  6936  8651  3896  1426  6238  9345 11898  8114\n",
            " 10128 10645  2582  6558  5837 11585 10806 13192], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10645  2904  6407 11482  8972  3201  8865  9930  3975  2582  2364 13071\n",
            "  5313 10188  9124  3366 10993  4732  8436  8500  5875  5052  4329  7197\n",
            "  6268  1641  5568  6762  8430  4136 12960  4326], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2234  1580  5676 12429  3911 14491 11544  5015  7238  6464 13483  7746\n",
            "  4572  5642  7317 10048  8418  1527   557 14013  4649  7585  3587  6513\n",
            "  1493  4047  2196  9421  4781  3218 13716 13564], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7616    70 10721 10604  8159 10317 11792 13012 14679 11590  8437  7921\n",
            " 13431  5017   641 14271 10410  9852  6699   688 14653  9315  7469  7746\n",
            "  9107 13477  3366 11970  6190  8463  9323  5888], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1262  3201  4535  5959  7609  7629  9603 11146 13506 10649  4626  9019\n",
            "  7019  8548 12404 13570  5015  2346  8030  5568  3592  8972  3372  7456\n",
            " 10295 13691 12732  1949  1867  4266  3445 12083], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14119 12623  2202  1174 11412  2783  1056  5620  9918  1199  3871 14012\n",
            " 11118 14460   148 11452  2750  1213   185  3649  2301 12301  9372  5231\n",
            "  8059 14030 14458  8571  5286  6258 11624 12343], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8108 12163  6044  2574  2575 12340 11970  6762    85 13214  9615  4575\n",
            "  9875   772  2278 12760 13745 10030  9697 12178  9755  9577  9956 10326\n",
            "  4019   512 14503 11776 11113  1197  4242  1995], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11970 10453 12152  1608  3122 13428 13776 14269  6039  9769  1619  1596\n",
            "   805 12651  4280  8664 11222 11052  5754 11231  8295 10247   556 12721\n",
            "  5811  3980  7413  6105  9692 12344  3968 11896], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6971  7161  2582 12627 11306  7202  1949  9326  1845  1556 11501 12279\n",
            "  9697 10060    53 12071  3861  1632  6101 10304  6265 12783  5016  3274\n",
            "   123 12484 10071  8368   650  2889  4749   294], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4018  3345 13192  5281 12209 12322  8719  4050  5837 10719 13386  4329\n",
            "  9423  1556  7943 10907  8068  9865 14132  9995 10247  6482  8159  7697\n",
            "  8954 11066  4762  2231 14447   620  1872  7706], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7125  6938  1527  8692 11623  3366  4860 12395  7609  7197  7149  8008\n",
            "  6299 10525 12367 13448  1877  7139  9315 14253    12 10592  6372 12359\n",
            "  7381  2001 13127 11103  2369  3274 11479  3197], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11066  5377  1886 14437  3655 10304  8512 14368 10326   582  2942 11915\n",
            "   195  3190   556  3838 11967 11225 13101 10351  4585  1835  5775  7410\n",
            "   738  8930  4778  9581  1840   186  3113 10958], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11227  9330  2479  2556  6859 12790 11225  6429   948  3423 13914  1619\n",
            "  3706  4039  5446  7385  8158 10340 13490 12774  3010  6833   738  1929\n",
            "  9405 12076 14501  8485  5171   385  9564  4372], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7666 14241 12860  8815  5254 11624  1240 13981  9662   254   885 11355\n",
            "  1799  1800  2894 12148  7392  5988 13878  5234  7227  9389  8772  4626\n",
            " 12232  1629    91 10195 10026  3206  2421  5544], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9205  5015 11811  4068 14137  5011 12424 12911  8283  2577 11002  1215\n",
            " 14415  3616  9572  4590  8283  3867  3335  7053  1644   186  6938 11851\n",
            "  4462 12162  2754 13739  6807 10818  7433  1262], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13154  5984  8556  3335  3335  5458   255  4749  6208  9067 12246  4304\n",
            "  6127  3274  5857  5095  4140 11231   325  9875 10581 13157  3437 10401\n",
            "  5670  9393  7976 13086  2540 11387 12561 13173], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13649  7090 13143   730  4304  8130  8767  6999  1114 10247 11422  2690\n",
            " 10550 13388 14041  8544 10463  7706  2775  6956  3179  3706  9423    38\n",
            "  5677  2127 10412  9797  7829  5074  7810  6287], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11370  3169  5245 13664  3622 11449 14352 12542  7776  7044 13557  6579\n",
            " 12596  5048  8827 10704   385  1910  7773 12869  2356  7579 14241  8851\n",
            " 11518  3214  4094  5499 13775   780  7094  5255], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13417 12913  6218 10107 10899 10494   950  5875 12801 13021  4306  8043\n",
            " 10403  7560  4506  9089 12683  7747  2428  9619  1823  9752  1949  9347\n",
            " 12010  9938  5445  5109  6774 14191  9158 10168], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2977   738 11002   484  5710 12768 11348  6594 12925 13634  7837 10448\n",
            "  8601  7937  4670   385  7197  6463 10746 10536  5641  2565 10856  8876\n",
            "  2194  2832 12485  8596 11654 13057  3218 10099], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10034  5968 14504  7197  8334  1271  5780  1036 10719  9338 10806  1900\n",
            "  3687 12065 11305  5727  8213  3601 13981 11388 11970 13833  8028  5309\n",
            "  2145  7713  9066  4721 10658  1439  8865 10849], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3477  7829  3653  5467  4421 14220  4462  2294  8059   444  8137 12820\n",
            " 14196   981  8429  1738  3218 11103  5106 13647 10459  4604  6534  8158\n",
            "   128  7473  9389  7090 11123  4123  6265   612], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1036   972  3640  6703  3640  3455  1054  9387 10465 12220  9636  3373\n",
            " 11290 12682  7428  2226 12597   417  4592 14012  3678  3911 13655  8147\n",
            "  3333 13185  4548  1300 11225 13633  3933  5707], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14537 10260   738 12532  2421  8068  8072  1649   601 11135  2382  1439\n",
            "  7937 13792  7453 11439 12289  7392  3908  1949 12146 10806  1464  1036\n",
            "   738 12743  6218   177 11634  7438  3289  7410], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9316 11952  7672 10560   380  1037  3326   812   474  3807 14635  8577\n",
            "  4278 14113  1575  6556 13516  9967 10440  5075 11586  9295  3120  7067\n",
            "  2068  5719  8114 14503  2813  7565  3427  2036], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12403  5812  6749 10595  5006  7816  6855  4275   843  6269 11833  4590\n",
            " 12024  1580  3534   453   711 10282 11507 10381  7921  4462  8945  6383\n",
            "  8436  4626 14503  6560  4170 12778  1362 13204], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4161  7921  6971  3693 12793  1228  6838 10263  2883 14267  3259 11848\n",
            " 12476 13492  1458  6131  2502 13671 12067 12811 10704    44  2850  6573\n",
            " 11410  6463  1949 12634 11904 13995  5721  9067], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7921  1967 13298  2563  5392 11776 13447 10502  5857 10780 12623   182\n",
            "  3582  9603  1176  4163  7049 12425  7408  5185 14030 10304 13591 11871\n",
            "  7395 11601  7334 14409 10251  9466  2167 10719], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12834  3976 11118  3055  9698 12209 11222  8473  4757  2357  6049  5371\n",
            "   490 13377 11827 10463 13277  6106  2765  9997  5055  6626 12822 13210\n",
            "   417 14537   534  9194  5541  9307 14075  8691], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8559 14341  6449  6324  6688 12304 13696  9666 11762 12783  1246 11961\n",
            " 13937  3148  3148  4186   847   127  8198  1775 12081  6241 13307 10210\n",
            "  9351  5585 13805  6959 13282   938   676  9852], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  188  7202 12221 10719 11586  9347 11769  4263 10463 10483  3738   183\n",
            " 13506  3011  1622  9692  2843  8436 12036 13281  3784 12367  5718  3228\n",
            "  2649 12736  5575  8664  9447   739   978 11102], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3279   158  4119  5265  2431  1005  9316 13451  6920  9158 10121  9956\n",
            "  2935  9746  8346 13164 12669  7034  2046  6573  7863  4593 13637  8198\n",
            " 11485  8170  1580  2853  7227  9861  1036  7713], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11652 10272   534  1240  4807 12544  3407 10185  9562 12061  4503  8371\n",
            " 11412  4626   325  1527  2503  7560 10486    12   186 13204 13192  1643\n",
            "  5650   972 13767   328 13810 12233  8357    12], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13094  4017  7983 10993  2933  2400  9700  3931  7227   739 14177  6532\n",
            "  4726  2146 12588  6104   922  5850  2324 10021  6600 13955  6491  7392\n",
            " 12282  5758 13130  4462  7191   434  4484 11883], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4086  1294  3218  3798  8045   892  8901 10777  7666 11261  7440  4377\n",
            " 13043  4486 10188  4498  4086 11491  1738  3696   703 13032   665  8966\n",
            "  9336 10530  7284 12331  9698  3681  3927  4335], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5501 10837 10463  3691 13554  8110  7313 11823  7747 13077 10027  8725\n",
            "  7935  9527 12554  3640  2145   595 13302  2146  4871   177  6698  2202\n",
            " 12779 13210   245 10333  1615   228 11319  4161], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1527  1036 14269  9147 10719 14182  3785 14121 10224 11725  3931 12686\n",
            "  8015  7778 12429  7607  6651  1830 13305  5334 10294  7560  5342  3970\n",
            " 12340  7044  5922   195   542 10704 14297 13210], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4864 14490  9616 12985  2726 12711  1125 13602 12429  6782  1561  3288\n",
            "  3817  9444  6532  8873 11898 14188 13094   779  8030 12500 11052  3235\n",
            " 11278  6295  5365 13732 14352  9067 11670  5042], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3436  1093 12233 11778  3084  8158  6043  8845  2611   295  2672 10878\n",
            "   195 12513  4065 11878  5058  3193  8944  1451  1037  5109  8593  4163\n",
            "  1012  8366  5658   739  4047 10918 13816  7357], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5004  3771  7747  2928  4092  7648  7583 12262  6190  7565 11598  2149\n",
            "  9916  3235  7287 11485  8901  1428 11057  7746   506 13835   682  9030\n",
            "  1840 10609 12811 13351  5136  9902  6265  7534], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8827    29 14155  8806  8283  9958 12596  7197  4823 13302    41 13763\n",
            "  2958  9129  2250 12466  9615 11452  9458  7190 13185  1903   991  2977\n",
            "  7146  4161  9732  8068  6265  1285 13051 11466], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2577 14086 14437 11824  5802  2012  4155  8918  7666 10556  8897  7586\n",
            "  5012 13351  9546  5303 12003 10530  5006 11883 14040 12532 10185  7185\n",
            " 10046   263  8367 10429  9666  2912  7875 12089], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6747  4197  8427  3245 13869 10274  4732 12991 11369  5307 11472  6042\n",
            "  3059  3193  1099  7635 12956  6531  1600  3785  7706  1042  1967 11912\n",
            "  3218  8126  4263  7746  6999  5747  7090 12811], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2563  1489 10295  7979 10071 11866  1840 12370  9391  4704  5910 12768\n",
            "  4177  8843  9193 10343  8918   222 14557  1714 12630 10326 10508  3593\n",
            "  2763   964  4115  7201  4121  6221  9278  3980], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11365  7292  3310 11970  9067 12529  1784  6951  5839  5658  9719 10016\n",
            "  3702  2346 11552   409 11434  7972  2627  6688  8345  7760 11970  8761\n",
            "  6858 13564 11322 13799  4412 12790  9042 14503], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10949  3574  4411 14236 10326  3022  8052  6591 10651  6762 10818   390\n",
            " 13024  3366  5472  4368  3491 11598  2626  9852  5962 10071 12792  9249\n",
            "  3738 13601 11922  4368  9268  8052  4647   725], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7609  3637  5563  1160 12398   730  3218   373  7764  2805  7227  3953\n",
            " 13452 11345  9937  1036  8776  9389 10721  6093 11225 11414  1845   910\n",
            "  7460 10333  8300  2103 11443  1689  9666  3417], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1556  3738  9902  4618 11321  8008 10993  1000  9885  7565  3692 13506\n",
            "  2323  3274  1494  5231 10293   509 11324 13204 11222  3671   692  4491\n",
            "  8706  9347 13726  3218  1439  5740  6116 10127], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8202 14477 11222  1000 10800  8171  1294 11776 10463  8587  9389  9263\n",
            " 11811 11434  6269  1099  8243  1280 13487  8918  8198  7666  7197   738\n",
            "  6573  7460  6938  1868 13633  3904 12367 14076], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4814  8381  1391 11452  7011   850 13204  9158  3799  5568  7446 12539\n",
            "  3125  3448  3648 12220  5912 10387  2977  6228 10485   909  1463  7996\n",
            "  2608  5721  7197 10326 10465 11727  8198 10301], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14395  4652 14302 11978  5254  7872  4819   964 14528  5654  4156  7061\n",
            "  6116 10326 14373  3753 13568  6531  4105  3671  6362 12749 10012  2078\n",
            " 11820  1459  4626   665  8113 11848 11231 12206], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7889  1861  7747  4737  2291 12793 11993  5206  1213  5467 12364  9797\n",
            " 13940 11821   829  4568  4569  2780  8977  4859 13805 14562  3178  2007\n",
            "  6234  7084  3642  6680  8288 10260  1491 12715], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8221 13204 11078   744  6809 13371 12917  9067 10964 10071 10287  3374\n",
            "   851  7138 11235  4486 11584  7587  6208   825  4396 10253 13949  9894\n",
            "  8701 12542  6463  3696 10329 13045   809  8438], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7392  9562  3345 10185  6813 14522 10519  7280 10326  6441  4047  9364\n",
            " 10196  8115  4368 13487 14501    69 12487   648  7459  1856 10511  3611\n",
            "  5472  1596 11616  7937  6597  4595  1054  9344], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5358  7254  4126  6547  8203  3827  1967   310  8302  3214  4859  3996\n",
            " 13319 12362  7565 13675   585   416 10427 11294  5628 13526  2928 13714\n",
            " 10785  5875   288  3281  5780  3410  7230 11626], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5381  9664  5841 13883  8663 13204  2423  1140  9231 10594  7517  1159\n",
            "  6158  7609   173  2542 13401 14271  6638   203  6971  6482  8372  7713\n",
            "  1390  2267  9316  7666  7747 10536  3582 10446], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2421  7392  6341 10202  7429  7460    12  4197 11449  3220  8914   603\n",
            " 12273  8669 13318  9904 10205  2874  4510  6212 12749   153 13387   189\n",
            " 12024 14503  1988 11176  6785 13737  9875  9725], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14253  3975 13205 13772 10304 11682  1093 13955  1389  8221  7609  3037\n",
            "  1538  3472   509 11978   358  1426 11479 14416 13210  8787  6241   459\n",
            "  7401  9808  7410 14486 10545  3272  7782  3105], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11473  8339  6984  4715  6316  6202  4792  7597  5675 11729 11222  3345\n",
            "  9352 11412 10681 11114  9227  8443  3696  3642  6401  7921  2627  2281\n",
            "  9315  8637   738  1619  1093  9423  9054 13739], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6851 13707 10654  4491  1913 10036  5543   749 12804  7536  2779 10343\n",
            "  5535  4837  9319 12631  6341  8012 10896  7541 14384 12334 13629  4368\n",
            "  2007 12724  3193    13 12862 10776 12042  7382], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11576  8660  9401  8346  4708 13232  4105  1039  5265  4178   877 14269\n",
            "  3498  5278  6031  6947  3059   546  2235  9158 12121 10083 10798  3436\n",
            "  7921  2998  2998  4094  7048  6067  5541  3272], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8028   850  6311 10498   625 12220 12565 13232 14054  2720 11200  5987\n",
            " 11782 12250  3384  7870  6615 11215  8872  9184  5458  7921   188  9246\n",
            " 11412  1321 12194  7121  4567  3817 13792  1294], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1194  4368  2548  7579  4638  7565 13192   919  7317  9483  8283  6830\n",
            "  5390 10508  6591  6137 13914   138 13352  7408 14601  4105  5710 10546\n",
            "   981 12276  7197  6573 14656  6023  1390   417], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11776  3738   622 11796  3703 12467  9333 13784  4086  8504  9006 10692\n",
            "  5174  7340  3706  3765   195 11144 12087 11444  3455 12607 13665 12053\n",
            "  5102  7083  6591  6343  7910  4614  9127 13665], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4278  4123 11276  1039  8642  8587  7213 10941  4065  5600  4136  1502\n",
            "  5024 11793  6265  5109  7038  3807 13210  9938  2905  5344 14562  4304\n",
            "   739  4792 10089 12362 12340 11167 11598    50], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3274  7392  3729  4373 10517  3611  4626   972 10340 10755  4026  9710\n",
            "  3011  2421  4292 14357   851  8243 12183  3366 10007  4687  9611  7276\n",
            "  8919  9232 11343  8719 12105 12429  5014  9415], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  994 10719 11233 10828  9136  2965  7044 14291  4368  4914  1473  8135\n",
            "  3935 10614 11263  4170   420  9275 12220  7312 11002 10060 10405 13879\n",
            "  5342   177  7197 11853  4216  4263  2134  1637], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12298 12650 12220  1738 12148 11118  3755 10260  4809  4825  9770  1847\n",
            "  5620 13854  2431  2149  6076  6405  4421  1560 11970  8874   730  3809\n",
            " 14572  8211  2977 14656 11624  7876  1426  9544], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5876  8012 12779  1529  6456  5247 11589  8365 11276  1390  9036  2707\n",
            "  8072 13067  4508  5611  3729  9246 13766  9581  2382  9852  9746   831\n",
            "  5780  8291 14537  5721  1409   175  9193  9902], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9310  2202 11472 12544 10097  8918  5109  2517 13192 13498  5307  5473\n",
            "  7921 12122  8583 10818 11339  2698  8873 10110  4814  9497  2711 10304\n",
            "  8817  9174  8557  1939  5671  5477  1960  9440], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7028  8918 11539  3823  1285  2416  3481  4626   130  9338 12320  4576\n",
            "  1967  8430  4329  9025  6494  8661 10247 14369  2469 10247  6894     0\n",
            "  6281 13490  2614 11794 12543 12233 13045  6463], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10086  4426 12106   870  8366 12429  2655 10300 10427 12752  5714 12532\n",
            "  2093    99  6562  7292  6935 13789 14572  6100 10316  8045  3642 13914\n",
            "   707  7292  3094  8576  3102  3021  3218  1504], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  518 12194 12503 12623 11567  1363  5488  6836  1823   587  8198 10704\n",
            " 14478  8291  8567  9326  8138 10150 12585  5774 10465  3345  1331  6999\n",
            "  9508   707  2848  5061  4637 10099   702  9692], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3274   194  4544  7642 13778 14220  5214   851 12749  7389   260  2241\n",
            " 11138  9431   484  1237 10616  3976 14240  1752  1004   195  1008  9109\n",
            "  9397 12489  9226 12429 12481 13799 13759  8436], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12301 11886  5052 10683  5115 14151  7385  1042 10207  4814  3607 13564\n",
            "  7921 13953 12220 11827  6039  8249  2031  3671  7148   959  1777 12257\n",
            " 11276  1527  9316   207  3528 11219 10027  4638], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9319  5700 13737 12793 13727  8574  9032   151 13462 13913  4932  8661\n",
            " 12742  4843  7796   252 12209  5115  7317 11826  7126  7460  8708  5392\n",
            "  3218 10581  4274  2492  1543  4368  4216 14549], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  361  2517  6738  5358  2928  8574  9928  8471  6158  1879  2604  8249\n",
            "  9312  6807  6953  9067  1392 13914 13043 11556  9406  3775   869  2127\n",
            "  2320  9657  8249  2986 11652 13506  3310 13914], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13557  7848  8650 11968 10340  2966 10210 14334  8500  3220 10491  1598\n",
            "  3310  9347 13229  7746 11589 13675 11113  1037   325 12962  9387 11539\n",
            " 13352  6158 11412  5852  9354  5082 10096  1974], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13045  7565  6401  6005 11798 14080 10318  7666 11485  4966  7560  8126\n",
            " 10883 12052  1823 10978  2626 10304  9942  8930  5250  6573  4136  8313\n",
            " 12534 11452 11507  9725  8252  7456  9226  4567], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7438  7810 11871  1247  3438   851 11472  3272 13668 12220  4207 10411\n",
            "   513  7455 11824  7935  9843 12328 10508 13184 13304  9671  6822 14675\n",
            "  2832  1339 11453  9544  1168  4016  9239  4174], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9095  5132  5983   993  5927 13737   809  1184   676  4508  1473  5272\n",
            "  4331  9389  3714  5509  2489  9387   195  4930    12  7411  1139  8982\n",
            "  6265 11055  4316 13691 14635 10772  1760  6936], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4154  2981   935 12608  9628  8760  6792 11134  2547 14603  1983  9931\n",
            " 11598 12445  4854  9566  7642 11211  1439 13633   385  2055  2537  1371\n",
            "   188  6428 12404  9423 13892  7923  4585 13981], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3780  5721 14417 13664  9657  7404  1926  8982  1234   725  3799  3218\n",
            "  9095  6426 14517  3274  8203  8279   177   479  7090   385  2307  2007\n",
            "  4304 10463   289  1054   738  6136  3274  7469], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9216  3178  7127   434  4304 10639 12084  4462  8436 11391  7232 13157\n",
            "  2653   417 11468  3218  3785  6608  7071  1451 13502  9316 10209  2210\n",
            "  4089 10616 10695  2403  9147 10993  5091 11523], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4782  1872  7757  6987  1268  8171  8944  6463  4604 10721  9494   470\n",
            "  8138  5353 11279  4975 11465  7565  1913   417 10508 14054  7334  7674\n",
            "    95 10588  8514 12939  7619  4507  5587  3785], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8485  8283  7935 12382 13192 10667 10162  5042   994  7897 10752  7854\n",
            "  6707  9139 10112   686  2200 13130  5544  5565   188  9394  7197 10198\n",
            "  7841  8090  5610  8872  5605   512 14508   870], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11939  7854 14092 10704 12284 10524  5888  6104  5675  3911  8618 11225\n",
            " 12583  8773 11883  2444  8504  4320 13064  4356 13402  3587 12220   760\n",
            " 12091  6127 14294  1774 12129 10682  4758  5231], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2577 10620  8198 14495 10704  3911 14424  6688  6591  9244  3788  2605\n",
            "   687 13387 10591  3566  8334  3234  3681 13759  7324 12336  3681  8875\n",
            "  8596  8291  9702  4163  2301  3815  3887   626], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  208  6726 13045   385 13506  9216 11548 12905  2945  4590  2275  1827\n",
            " 12854  2805   420  8922  3206   777  9405  3904 13915  3455  9876 14168\n",
            "  3218 14608  6265 12233 10588   850  3785  9146], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1305 12585  3544  7587 13083  8298 12194  4202  2662  6851  1974 13913\n",
            " 13737 12562  2820  8890  6463  2171  7197  8287 10041 10154 12623  5973\n",
            "  2489   118 13121 13828  7500  3452 12742  9638], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5507  8346 14495  1953  4533  8661  4155  3296  3455 11071 10463 11452\n",
            "  9603  8603  8678  9694 12274 12320 14030  7548 14443  6341  2388  4016\n",
            "  6544  2047  3880  3148 12811  3455  7236 10719], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12786 14650   973 10304  3521  6422 10818  5109 11576 13847  9415 10728\n",
            "  3908   850 13035  6462 14490 10889  3251  2012  7723 13387 14203  4242\n",
            "  7564  1425 12128  7227  5758 13882  2842 12352], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4801 13999 13151 11883  3788  5527   385  3186  6608 12927 11598 11865\n",
            "  3198 14491  2371  7513  9344  8984  4192  9962 14301  1045  8291  8171\n",
            "  9276  2823  1628   454  4170  9830  7565 10270], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  886  2924  4844 11978 14145  1439  5399  3165  2841   718  5293  4986\n",
            "  5758  8137 14363  1392  2531   640  7326  9423  3729  3201 12282  9025\n",
            " 13913 10682 13462 10094 10576  5125  8553 13668], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12261  4595  1879  1883  6987  3747   536 11453  6493  7793  9146  4190\n",
            "  5983 11761  6573  8295  9835 10741  7744 14479  2965  8436 11170  5392\n",
            "  7413  6203   964  6857  8138  6664  1506  9831], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14572 10304 11530 14249  4728  7582  7236  8346  9297  5062  9323  9055\n",
            "  1431  4304  2753  3755  3506  1036 12210  5439   289 13192  3682  7460\n",
            "  3785 12274  8504 11601  3708 10822  5725  6791], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12858  3218   522 14162  1485  3788  3607  8703  1439  4496  9165   590\n",
            "  4933 14595  8198  6586  3791 10147  1611  4201  6265  8719 11222  3611\n",
            "  7132 11389 10089  2673  2938  7545  8170 12204], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7040  7854  6135   170  5826  1819 12183  5207   877 10546  3816  3218\n",
            " 12429  6497  8064  1039 12761  3276    93  8583  1199  7223 14503  3178\n",
            "  4902 10160  1004 10138  4825  8198  3345 11876], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4329  4865 10138  3206  5231 11035  1478  4242  3399 10048 13348 14121\n",
            "   734  7121  8567 11867  5122 11991 13506 13094  7546 14517 10178   531\n",
            "  3345 10940  5795  3455  4227  6762 13288 10993], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12761 14640 14561  5062  9526 12247  3785 12039  9777  5509  3218 14151\n",
            "  1840  4590 14240  3888  1036   626 10089   467  9354  7090  2919   980\n",
            " 11834 14608 14537  6890  2031  8436 14292  6401], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1901 11980 10889 12194  7536  4604 12429    14  6539 13065  6836  2646\n",
            "  8771 11639 12988  6463  1605  8436  9866 12429  9662  9344  8930  8803\n",
            "  4511 10326   964  3218  6117  3198  2460 12542], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8113  1439  1378  7128  2646  2559  8918  7921  2582  8161  7131   472\n",
            " 12623  8045  1459  5775  1613  4845 11595   921 13402 10012  1027  7182\n",
            " 14272  3983  2502 10882  4086  8782   195  3991], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7227 13189  2911   951  8299 11487  5095 11821  7609  4105 11427   188\n",
            "  1437  1054  2542 12419  3245 12811  8897  9488  7138 13778  8231  4323\n",
            "  6556  8968  7156  1591 14680  2442  7572   513], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14332  9019  7666 13004  5784 11474   899 14030 11599  8866  1036  6041\n",
            "    39 13204  4421  5015 11284 14481  6728 14228 13424  5509  4156  8384\n",
            "  3345  7377  7039  4187 10460  4661  2836   563], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4860  2147  4242  7587 13532  5786  6993 11776 10304 12607  4604   104\n",
            "  9453  9389 14175 11118 10719  1332   300  2465  5278  2251 12725 13828\n",
            "  3206   676  1114  7148 13471   655  5014  6162], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1459 12090  6408  5167  8111 11902  2230  9347  2127   686  7392  3524\n",
            "  8472  6688 10818   985  9334 13836  6891  4905  5480 14472 10535   177\n",
            "  3697 10595 10752 12952  3788 13192 11052 14005], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7227  4396 11970  2269  5616  3738  7417  2809  1378  9835  8193  2702\n",
            " 11172 11167 13204 11222  3123  5805  6947   128 13175  6914   417  7713\n",
            "  1990 10860  5208  2977  7816    55 12365 10591], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3904  6252  6688 14316 10247  6099 12220  8898 10546  2473 11883 10856\n",
            "  8158  7723 14459  7041  4826  7306  4614  7896  8918  1998 13210   872\n",
            "  7138  8607 12326 10315  6851  9347 11565  1048], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  235 12599  8561 12000 12228  8065  8960  6938 13331  1752 13016  5095\n",
            " 11731 14538  7565  2498  4010 13428  7954 12107  3274   674  8222  9284\n",
            "  1990 11631  6925 10341  7197  6900  4646 13192], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7197  9628 11820  1439 10041  8557   877  5517  3671 10463  3455  6158\n",
            " 10700 11519 10205  1967  7565  5595  2582  8578  5838   361  2997  8020\n",
            "  6747 13237  6041  8150  4872 10190  1132  7175], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7221  1459  7836  9406  8973 12851 11548 11717  1596   117  3410  7329\n",
            "  7185  2051  8370  6791  5377  7623  8413 13469  5791 12988  4488 12537\n",
            " 10463 12760   995  5936  5342 10340  9562 10401], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7469  6951 10103  1550 13974  8098  7854  3801 13255 12778 11120  2321\n",
            "  5377  1793 11967  1798 12652  7520  1052  3388 13490  3274  7446  6941\n",
            " 13182  6721  9084  4217  1561  3545  4736  6781], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12337  9006 14474  9389 14503  7660 11552  2844  6688  8746  6257  7812\n",
            "  2356 10901  8916  8359  6124  6463  8789 11726  8556   569  2153  3775\n",
            "  6853 12672 13760 11714  6158   738 14269   777], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10335  9627  8227  6723  7846  5142 11654 13913  5459  1114  6747  3313\n",
            "  7720  2901 13759  7565  6249  5989  3148 14403  2240  8216 11970  6401\n",
            "  4592  8966 11263  3436  9423  5348 10107  1437], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7592  4065  4266  6601 11391  6253 10722  3642  9423 11643  8298  1527\n",
            " 10304  4231  3189  6039  5675  8101 14066  7870  6454  3455 10874  4170\n",
            "  1949 14478  2004   964  1522 12013 11052  7670], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2972   517  1103 11261  2444  9032     7  6415 10536  6463  2844  1536\n",
            "  4389 10304  7455   454 12265  8411 10504 11146  4242 13945 10089  7413\n",
            "  3259  1558  3942  1345 11052 10704 10085 12236], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6070  9097 13969 10818  9556  5509  6552  8138  1995 12597  3581  4018\n",
            "  6044 10825  7090  5215  8283  7266    39 13801 10835 14044  5795 10761\n",
            "  9567  6573  8327 14012 13473 13953  7884 14451], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14481  3681 10338 13737 11938  4865 13204 12529  4039  7872  6492 12623\n",
            "   656  6659  1984  5467  1062 13909 10446 13726  4368 11585  3751  8329\n",
            "   829  1948  4491 13490  9423  1566  5212 10742], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8205   993  2315  8897  2310  4397 11511  1039 11222  2570 11970 10741\n",
            "  5247  2044  9883  5286  8918 10393  3703 12542  2262 13383  8202 13897\n",
            "  9232 12003 13033  5017 12635  2325  9594  1527], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13204 12532  8914  3274   439 10304 13851  2832  5950  8395  6541  6463\n",
            "  7139 12616  9117  7551 13400    92   188 13998 10305  5828 13759   525\n",
            "  4242  7440  9694  5795  1895  6104 11225  9258], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6131 10264  7921  6699  1563  5203 13051  1448  1288  9586  8080  6359\n",
            "  7692  7392  3736  6463  1748 13595 14409  4511  2838  1967  7249 13204\n",
            "  7037  7664  1045 11286 10463  9754  9405  6941], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1486  1511  9538   468 11695  6030 10465  8597 13727 12431   177  8399\n",
            "   288  4814  3161  9956 11818 12136  6688 13043  1149 14083 11512  1030\n",
            "   335  4278 10931  8544 12542  9662  8667 13432], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3738   626  6172  7289 10509  2169 11444  6762  7863  5250  3596  8844\n",
            "  6249  9320  4553  3279 10694  2848  8694 13503  3671 13595  9574 10278\n",
            "   738  2548   730 11024 11692 12542  3189 10534], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4086 10719  3415 14495  9875  8500  5525 10550  6789 11216  7395  2879\n",
            "  5493  5062  4718  9798  5668  6440  6300   828  2088  8611 11565 11960\n",
            " 10283  8436 10121 10326   525 10395  9619  8381], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9948  7002  8854  2962  6990  6488  5654  3473  4396 11453 11450 13925\n",
            " 10465  8150  5415  6937 11525  3257  6605  1966  5171 14271  7803  7139\n",
            "  9085  1121  4402 10835  4817  1151 13038  3223], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4311  5047 11898 12806  7680  7510  6280   739  4059  4159  1531  9512\n",
            "  7460  3479  8158 10158  6104   762  9389  7121  3218 12879 14638 10536\n",
            "  8895 12083  2771  4161  6047  1752  9100  6262], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2188  6311  8415  3729  2650  8831  6904   645  8601 14495  6603   899\n",
            "  5555  7138  1408 13951  8126  7706 13912  7227  2630  5170  4803 11078\n",
            "  1426 10645  9157  2776 14158  7772 13682  4492], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1473   777  4242  6923  6366 11627  9663 10027  4845  9319 11507  6179\n",
            "  5891  2301 13193  5604 14488  3673  5359   964 12428  8603  5245 12694\n",
            " 12539  5523   123  4119  1543  4200 11290 11200], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8279 13693  8283 10396  9133  9953 10185 13473  8334  3142  8283  1067\n",
            "  3477  7392   956  9931 12404 13560 12749  9266   382 11572  7996  7228\n",
            "   902  7943 13716  9283 10375  7395  3206 12751], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10704 10818 11072 12220  1527 10704  3673  1580  6179  1736 14089  7713\n",
            "  5392  3005 13518 12960  3983   690  1879  6556   841 12219  9699  4648\n",
            " 10465  3785    44  6553 13713  5768  3193 12595], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11288  6591   223  2115  8366 10914  3369  5286   450  4170  5009  1529\n",
            "  6887  1378  8706  6573 11555  5742  3611  8596 12166 12933  6525  1711\n",
            "  5122  8731  5264  6020  2702  7669  9630  8327], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6078  4370  7562 13068  1698  4278  8985  7392  1192 10699  2848 13652\n",
            "  7033 12681  2627  7251  8056  7570  6265   382  7561  9717 13955  6903\n",
            "  8877  9548  4728  2860 10185  8029 12532 13426], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9534  8352  7870  7552  2343 12661   881  2901  1172 11129  9988 10605\n",
            "  1082  1110  1381  4238    27  1867  3037  3059 12433  3947  9347 13925\n",
            "  7392 12532  4871  3220  8159   328  5642  3642], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4233   790 10073  1191  8132  7854  3127  1284  3083 11565  4842  6724\n",
            "  2332  4208    44 13327 14012  7131   596  3741 10719 11939   739 13727\n",
            "   482 13720 12763  8143  3608  4592  7729  5986], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12943  3218 14423 10382  7746  2421  9295 11883  3152 11849 12841 10237\n",
            " 12200  3568 14269 12608 12771 11824 10127  3600  8272  5557  8804 14216\n",
            "   998  2650  3432 14233 10284 11423 13270 10977], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2977  4134  9522  2916  4745  2302  7557 12102  1831 13083  5097  7462\n",
            "   885  1949  8563  9902  8475 14085  9615  5579   973   919 14438  2200\n",
            "  4016  7921  9998  8802 11276   439  7384  8485], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[   60 13326  9897  2317  5826 10304 13154  6098 10252  8436  4488  9106\n",
            " 13477  1374   361 12327 10675  4103  1151 12301  3366 11970 13072  7847\n",
            "    93  3472 11052 12183 13452 12086  1287  1037], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12842 11589  9497   739   690 13165  8815  9347  9764   686  5768  9531\n",
            " 14194 13132  2613  6265 10148 11519  6127  6213  1075  5342 12468  4851\n",
            " 13818  6414 13772  1995  8959  4502 11066  9116], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8121  7292  2738  9649 10704 13424  8371 11667  1110 13550  8854  5517\n",
            " 12686 12148  7609  4813  4062 14623 11312  7440  4378  6810 13387  7565\n",
            " 11535  4638 13945  6459  6809 11528  6493  7729], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8245 12793  8464 14076  1459  1923 14650  7379  8950 14503 11218  5639\n",
            " 13766  1573  5721  4201  2120  1131  6381  7800  8137  6463  6270  3917\n",
            "  2096 14260  7884  9321 13629  7164 13228  7149], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2673 10083 14302  6975  2673  3563  6372  3230 10796  7139  9847  7943\n",
            "  8981 10083  2268  2139  8081 14626  5095  6111  7014  1550 13733  5784\n",
            " 12369  6810 11615  8474 11970 13239  9730  3218], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2502  9347 13537 11240  3345 10303  6670  2711 14089  2618 12950  3439\n",
            "  2809 10856   881  6532 11883 11536  4045  2812  9316 11597  9610  2209\n",
            " 10755 10704  7950 13640  1036  9146 11685  5071], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11053  5822 11290  2342 10405 10822  8556  8257 10333  6851  8693   195\n",
            "  1589  7090  7565 14564  4462  3218 10891 10809 10382  4242  2646 10116\n",
            "  6026  8464  4405  5274 12734  8257  3345  9308], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7227  2158  4658  2754  4274 11080  7940  3795 11337 14240  7766 10210\n",
            " 14041  8172  9174 10704 14142 11351  3778  9850  7950 12267  4745 13880\n",
            "  2924  4961 14441  9183  6639 11754  8555  9624], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14029  1381 10317  7156  8275  3736 12572  7545  6762    13 10581  9881\n",
            " 13981  8029  2697 14429 11161  6440   949  7854   788 11970 13491  1879\n",
            "  4920 13951  8994  1815  9215   612  3702   417], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14372  5233 12832  8850  3026 11970 14032  8743 10877 14245  4397  4069\n",
            "  3533  4627  1140  6127   177  3123  5620  8236  3837 11218 10164   361\n",
            "  1054 12522  8202  7609  1920  8121  5527  1955], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13832  7260  8143  1926  2666  7068 13305 10051 12093 11278  1856  5109\n",
            "  6251 12834  5426  9522 13707  5467  5122  3397  4023  9195  3801 12357\n",
            "  9316 12683  7197 13727  2241  4326   503  8043], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8384  9770  6573  2204  6626  3785 11358  1378 10205  7599 13930 11949\n",
            " 10820 11391  8179  6463  9993  6283  8403  1249  3719 14302  8995  6591\n",
            "  4592 12071  2647 10090  2193  3278  9176 13348], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2444  9415 14525  7446 11118 10691  9791 10645 11970  6789 14274 10154\n",
            " 12320 10762  7454  1854 12677  5668  9095  9914 10993 12584    17  8985\n",
            "  6389 10667  3911 14503  7323 13304  2848  3218], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5153  4128  9057  6699  7109  8198  3775  8918  5795  1714     3   598\n",
            "  9106  9773  9389 11276 10098 11118 13999   943 11036  2498  7460 13981\n",
            "  1054  4062  8624 10335  6463  7666  9626 11275], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11898  7820 13995  3455  4690 11903  6762  9203  8418  3063  7588  8966\n",
            "  7392   804  6463  9347 11827  4368 13198  2820 10519  3198 11512   998\n",
            " 13863  4352  8845  2883   881  3885 11845  4086], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14645  3677 14492  8464 12862 10293 13223  7185  7781  5992  7334  6525\n",
            "  1494  2655  8198 11507  5666  3021  5875  6791 14527 10073  2771  2455\n",
            "  5915 10639 11276  6070  1434  4704  7937 10425], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9316 14302  1663  5247  3272  7078 12256  5666 12352    44 12369  9626\n",
            " 13653 12651 10021 10094  7188 11845 12991  5936 10591 11063  6493  3757\n",
            "  1542  1199  3095 13629 13362 14113  1557 13264], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5905 14345 10561  4170 10236 14230    94  7157  7197 14372  2953  6573\n",
            "  2097  2421  6699  8554   235  4426  4267 11405 10719 12053 14039  9347\n",
            "  6807  8025 11078  7197  4136 10929  4745  2439], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11652 13204  5114  6518  2686  4477  5622  8743  5969  4749  4466 11792\n",
            " 11807  5795  4446  1054   391  2405 11950   557  7681  4135 11348  9338\n",
            "  9344 12245  7755 12677  6105  7996  3642  8901], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3887  3975 14369  4304 10449  6163  8960 11231  3755  6093  6972  5710\n",
            "  5997   177  1949  9389  9079  6956  7933  4628 10026  6778  6241  3455\n",
            " 13515  4904  2537  2421 11275  8330 10260 11275], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7438   139 10150 13629   730  5265  1879 14479 11801 11614  7270    12\n",
            " 11539  1527  5775  1743  7440  6888 13477   578  8406 12298  4593  4865\n",
            "  2779  4778  3911  7417  6430  8249  5588  3614], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2977  2954  8114  1444  1113  5784  4749  2444  3607  8464  2928  8418\n",
            "  8544   738 12429  9127  1093 11200  1697   188  3917 11276  8904  2315\n",
            " 11792 11337  1159 14132 10151  5473  3807  6265], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9490  8126   205  3347 10304  3742  6747 13045 11631  7895   153  6146\n",
            " 12793  6549  4368 10379 11970 14624  5568 13789  4749 13452  2493  8283\n",
            "  6218  9095 12952 10138    95  3976  6264 12609], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13624  7355 12336 12205   687 13204  9389  8346  1414 10626  6463 14089\n",
            "  2235  9677 10668  2771 11405  8173  8485 11776 13232 11276 11598  2013\n",
            "     1  7702 10143  7585  7190  1054   539   651], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9112  3634  6936  5442 10186  8786 11317   825 12181 14060 12445  8379\n",
            "  2009 10083 12879  7843 10818 10944 10536 10303  6623 13879  6011 14537\n",
            "  4462  7623 11225 10343 13738  5780  5784 10326], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7701 10794  3823  4018 13102  1266  7340 14503  4426  4195  6158 11648\n",
            " 11243 12220  5342  1949  4576  2024  4592   595  2834  1064 10138 13638\n",
            " 13968 12694  6813 14274   554  7042 11652  3570], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10317  4086  1874  8914  7127 13951  7478   322 11726 10617  5622 13167\n",
            " 11276 12233  2674  7440  4626  2174 10856  8143  7898   851  3976  3944\n",
            " 10587 12024 11507  4995  3151  6363  8126 10682], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4275  6306  7088 10581  3671   177 10251 10656 11552  5131  7980   525\n",
            " 11776  3738 14386  3324 10817   506  7122 10604 11661 11565  6249 11715\n",
            "  8982 13969  6375  7455  1532  3983  6299   138], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7352  4878 13863  6918  1091 13955   242 14018   739 13914 11670 10326\n",
            "  7579  1473 13595  9266  5666 10386  7012  7802   239 13792  3083    12\n",
            "  1127  8668  7623  1030 11472  1724  4159  2007], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10790  8966  7820 11064  2536  4626  5988  7138 11776 14220 12887   739\n",
            " 14271  7125  5541  2792  9586  3438 11624  7392  9316 14386  8783 11808\n",
            "  1045   459  5568  7489  1024  2321  7937  8843], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12429  9866 11472  3406  3671  6395  2175  7565  8007 13282  6497  1381\n",
            "  5721  8261  6190  2127  6813  2302  1573 13629 14113  7937 12607  9127\n",
            " 12431 11225  8272  4592  4590  8807  6164   789], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6109  9751  2137  5109  7674 10918  5779  6738  3203  9835 13372  5151\n",
            "  4761  6249  6623  3706  3068 13331  5509  4134  5755   385  8150 13675\n",
            " 13766 11898  7097  1062  7854 11080  4522  4326], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10932  6976 14089  3642 12411 12489 11444 12539 11452  3048  3420 10915\n",
            " 13157  1483   430  4634 12431  1980 10274 12650 13387  5061  2421 14325\n",
            "  7090  9316 13745 11717  9266  8288  8249  4170], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3702  8485  5247  4836  3242 10987  2847  6127  9020   594  7045  2792\n",
            "  8276  6463  8283 11222  2954  9611  8114 10849 14136  5675 10849  2882\n",
            "  5342  4626 10320  8555  2998  4594  4329  8261], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7933  2421  8062  7848   980   739 10150  4665 13945 13155  3755  9770\n",
            "  8825 10326  8845  1796  5009 12511  7587  9352 14653  4600  6343  6532\n",
            "  8364 14292 14025  1387  3218 11169  7934  9821], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4599  7139  8727  9954  8018  4583  4971 12411 14205 13756  8376  3130\n",
            " 11883  5655 13561  3339  8249  9246  1879 11235  8972 13318  3242  4396\n",
            "  4306 12819  4594  6433  6971 10304 11585  4933], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10138  4225  6290  5527  3168  2988  5872  9364  8371 13505  4567  7903\n",
            " 14409 14503 11002   644  3326 12429 12042  9338 10719 10846    39  8283\n",
            "  2498  5207 11717  8558 12302 14505 11290    12], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1045 11405 13381  8576  4593 11776  8525 11066  6972  1550  2689  3772\n",
            "  6975 14537  7666  7723 11412 11552 11850  5399 11231  7485 10272 13805\n",
            "  9338  9066  6591  6688 11758  6163 14302  7227], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8504   893  9609  1174  5527 13981  8834  4610  7282 10536   730  7983\n",
            "  4156   552  7747  6463 11035 14419   730  4105  1714  8739  7565 13331\n",
            "     3  6971 14269  8143 10691  8914  6573  8543], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13474 11792  3785 14503  1381  1574 12539  6847  9393 13381  7921  1247\n",
            " 13652  6990  6688  6847 10304 11583 10849  7687  9195 14537 12963 10993\n",
            "  9387  6256 14643 14653  6311 12551  2522  7034], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13707  1244   904 12256  7674  2209  3642  9902  9497  8283  3218  2928\n",
            "  5120  6762  9095 10932  3944  6463  3438  9009  4799  4626  1459  1331\n",
            "  3785 12619  2564  9609  1140  2938  4554 10654], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8472  9127  8073  4792  9657  4256  8298  9195  8291  7122 10209  5011\n",
            " 11306  7088   626  8380 14039  6497  5587  3749   690 11903 13502  3719\n",
            " 11373  3483 12332  1566 14458  3477  3083 14230], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14549  5622  5265 13103 10993  1817 14643  5145  9850  4368  3022  8587\n",
            "  1152  7548  3407 12735  9164  9595  8916 14503 11222 11916  3438  2623\n",
            " 11686  4648 10675 11476  3737  2843  5342  6857], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11929  4426  9616  1883  3335 12352  7438  5525  9111 13232  3122  3274\n",
            "  9956   738   417  5666  7227  7227  1518  6810  6208 12463  1140 11804\n",
            "  6532  2582  7545 11773  2951   525 12542 12683], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7733  1439  2820  7232  8428 13981 11837  5989 10896  3503 14495  6093\n",
            "  3251 13352  2421  4242  8283 10809  6747  4186 11550 10320 13477  4338\n",
            "  2449 10888 10027  9626  2416 13192  9097 13637], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13351  5215  5758 13953 11520 13154  4726 13424  6459 10274 10719 13069\n",
            " 10990   672 10932  7548   361  9990 13185 13083  1422  4304 13914  6482\n",
            "    93 10150  6609 12863  6703  3655 13635 11609], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4726 12609  6892   739 14556 11263  9526 12433  7442 11426  9009  1099\n",
            " 14537 11970  8821  1550  8025  4653  7623  9275  4139 13072 13151  8704\n",
            "  4242 11222  1019  4417  2127 11970  6762  5095], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8042 10704 11970  8941  3935  7151  7068 14310  9331  4367   919  9449\n",
            "  2502  4105  9934  6936  7185  8023  8650  2092  7741  5611  9616  8138\n",
            "  3127  5509 10722  4123  7410  9770  6829  5143], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5549  6591  2630  5915 12174 13502  8339   791 10138 13568  7565  3127\n",
            "  9699 11422 11479  3911  3409 10270  5620 12811  1494  3681  3911  1825\n",
            "  1247  3640  5015   881 13506 11598  8138 10704], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4160  3911  8028  2045  2605 11222  8107 10300  3736  9742 14197 14297\n",
            " 11036  7666  6513  7410 11509  8587 10562  2158 10704  8028   554  7292\n",
            " 10326  4187  5044 14269 11824   185  5070  6093], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5527   565 10274  7138 13204  3220  8214  4156   773  7121 13675  1949\n",
            "  9067  9616  8865 12451  2423  5569  9544  6127  2673  4072 13428  6618\n",
            " 14583  9626  9668  7565   872  9666  9338  2317], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13549  8132 14230  8283  2044  4614  4368  3634 10342   616  5857  2917\n",
            "  2965  5467 14252  2127 13154  7702  3385  2004 10247  7762  1140 12996\n",
            " 12646  6630  3193 11231  7121 13352 13640 11222], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  188  5878  2235 10929  9389  3647   738 12071  2673  3333  4667 12326\n",
            " 10529 13094  9316  9089  8715 10502  7042  3218  2632  4638  3587  8346\n",
            "  3719  4105 10205  4511   738 10787 10340 11707], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1014 12925  4329  5467  3193   136  7884 12743 13515 10688  6350   739\n",
            "  5377  5841 10440 10463 13159  9389 13633  4932  8283 10326  3094 11412\n",
            " 11231  5756  2297  8138 13526  3143  7746  8327], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6936 11865 10993  2630 14653  6836 12609  4187  7109  7287  1543  1460\n",
            "  8901 13068   188 13401  1161  6857  8279  7230  8334  1556  1752   739\n",
            "   861  6093  4792 10151  6093  4263  4567  7251], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4885  8339  5784   877 12284  8283  1569 10405  8327  6688  3887 13204\n",
            "  4372 11560 13955  2504  3148   738  7609  1987 10147  8361  7623 12228\n",
            "  2127 13000  4368    41  7993  5107   739   553], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9897  9271 13069  6703  1697  3640  4242  8526  8687 10502  9837   615\n",
            "  4278  8430  3130 10675  8583  6688  7236 11055  8138 13627  7439  1556\n",
            " 10993 14352 13627 10809  8346  4160  9508  9988], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12125 11307 14297  3647  8577  9019  7672 10063  3696   283  6833  7934\n",
            "  3438  8257 12609  2327 13696 10260  3203  7469  9066   188  7126 10536\n",
            " 11222  7227 10932 10304  1054 11002  9624  3671], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9282  4758  9152  6020  1149  1752  8114  9391  1132 14468 13204 11222\n",
            "  7185  3021  5872  1054  6127  9624  4304 12941  7125  3723 14503  3295\n",
            " 10719  7121  9972  6703 12779 13915 12554 14297], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12328  8028  8138 11222  3485 11878  5989  8982 10502  4627  8401 12220\n",
            " 11393 11507  1099  4975  3681  5666 10147  8898 14039  3493  2843  2630\n",
            "  9423  2745  6851  2024  6920 14503 12429  5868], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  739 10790 11412  8596  7236  1082  4304 13640 10610 10205  5236  9797\n",
            " 12284  2574  4275  7440  3274   956  8138  4690 14568  5458 13481  3426\n",
            "  4105  4590 10452  8587  5145  1949 12778  5742], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7561 14479 14509  6463  7993  9314  8371 10668  3127  8171 11222  7913\n",
            "  9407  6093  9297  1529 11970 12024 13051 13666 11898  5143  9777  9603\n",
            "  6158 10820 10205  9066  6158  1823 14650  6851], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1563  4274 10370  2945  2649 11144  1439 11222  6241  1036  9095  3835\n",
            "  1752  1037   690 13766   188 10896 14643 10405  9389  6591 13696 11072\n",
            "  2235  9397  9055  1010  8001 14562  9174  8850], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14060  9338  7776  1518  7609  6703 13047    41   739  9857  7317   602\n",
            " 12534 11021  3755 11021  4648   553 10787  5758  9406  9127  5301 12749\n",
            "  9220  3102  7565  6714   122 10227  1527  1014], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3642   218 14496 13477  8172 10089  6857  7804  4368 10436 13352  1511\n",
            "  1543  7937 11845 10570  8334 13232  9624 12862  3438  1473  4752  6093\n",
            " 12183  4845  5675 10590   391  5710  4593 10604], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8073  7898  8283 11718  1927  2297  1879    24 10210  8366  4368  1879\n",
            "  8213   850 10993  8447 11582  7438  9389  6573  1879 12429  5749  4368\n",
            "  3127  6249  1392  5527 11844 11827  6857  1106], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14562  2924 13204 11540  8138  8371  7227  8629  5109 11709 12429  8368\n",
            "  2315   739 13675  8334 13914  2188  5964  4590 11472  9394  5400  3022\n",
            "  6929  7410  6747 13759  2754  3729   912  3274], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12013  8746  8807 10720  5399  4105  3736  1247  6208 11169  1949  5231\n",
            "  7609  2638 11002  9183  8213 13881  6857  3755  6833  5071  3125 14503\n",
            "  5888  4170  7146  5622  6851  1879  5255  1014], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8327 12033  1409   850  4368  4290  4290  9559  3887 13265  7164  2698\n",
            "   506  1955  7197 13154  8339 11970  3438  3218   130  2319  2208 13809\n",
            "   975  4773   143  9116  4105  1232  9389   546], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2502  8824 14274  3911  1879  2009  9073 10519     1  7443  4485 13914\n",
            "   986 11002 10205  9352   185  1054  4165  5762  1949 10993  1573  2695\n",
            " 13675  4263  9215  2732 13379  9903 12359  6270], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6738  4745 11598  6265  4626  1149 11412 11970  9749  2012  8346  1294\n",
            "  6573 10326  9603  3206  4329  1140  4745 12429 11002  8715  1927  3455\n",
            "  4626  9581  7410  9102 12749 11847  4567 12941], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8339 13821  3438 11317 13352 10304 13160  5015 14012  1752   527  7747\n",
            "   555  9859  6490 11001  8851  8580  3366 10083  1054  8346   738 11694\n",
            "  1140 10519  8339 11217  7746 13691 14503  6597], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6688 10315 13051  1974 12677  2847  2421  1247 10205  8334  4329 13759\n",
            " 13232 10570  4274  9282  8149  3021  6851 12692  6093  3501 10227  9879\n",
            " 14517 10008 14369  6127  7746  1054  9603 13874], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4304  2308 12429  3785  5781 14235  6536 11545  7126  5956 12542  9423\n",
            "  9194  8138  8346   546  1390  7609  4105 13999 14089 11446 14297  3423\n",
            "   730 11312  8283  6591  6975  6913  8429  4018], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3755  7197  6591  4462  4023  1054 11261  7011  3438 10570 10304 10289\n",
            " 10690 13792  6792 13280  6591  5562  8823 14343 10366  5091  7230 14132\n",
            " 11598  4627 10704 11598  1294  7934 12082 14525], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3366 10719  4506 10027 13820  9158  6688  8982  2346    29 13981  9736\n",
            "  8966   841 13051  4420  7609  7230  8283  1718  8334  2130 10304 10211\n",
            "  7533  4470 11520  6690 14335  4150 10387 14652], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13283  1477 12429  2356  6762 12451 11884 11225  7011  8283  8574  8544\n",
            "  7810  1752  1527 14310  3565  3060 14537 11225  6938  8069  3681  4280\n",
            " 11200  2112  7125  6857  3154  9494 12220 13666], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9156  4648 11225  2662  9364  7934  4242  6781 10145  6573 13204  6851\n",
            " 11235  7393  1967 14537  5992 13204  7921  2673  4368  3068 11231    39\n",
            "  9297 13232  7105  8876  7609 14192 11865  4329], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1697  4801  6762  5616  2315  6295  5617 10808  6172 13352  4562 13981\n",
            "  4592  7609  4242  9777 10993 12629  4482 10343  9650  1054  7260  4263\n",
            " 10606  4389 11677 10205  3924 10446  9066 13914], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10205  8249  3976 13146   686  9764  9407  1543  7197  4411 13631  6851\n",
            "  6762   858 14228   195   555  3220   875  3234  3118  3681 12596 13051\n",
            "   209  9944  1966 10138  7410   690  8504  1738], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7818  1526  4329 14182  7732  3455 10370  9603  1392 13204 10227  3423\n",
            "  2673 12469  3035  5527 12121  7687   500 11261  6531  7565  1392 13051\n",
            " 14444 12024  6029  6463 13426  3528 13909  1448], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11452 10772  6810  1196  2145 14197  9116  2208  1752  1237  1054 10704\n",
            " 11807 10304  3703 11452 11871 10019 11217 13252  8823  6935  8171 11878\n",
            " 10403  9532  7469  9285 11412  8105  9073  8661], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12529 11807 14625 11200 14039 14274 14240  1949  9532 11055  9532 13192\n",
            "  8283  7287   738  1290  8259  4123  4136  8514 14562  7565   739 11627\n",
            " 12529  4161  3785  5197 10704 12232  1262   195], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1045   140  2356  6836  1054  3048  1640  3455 14253 11822 14509    44\n",
            "  3687  2167  4136  7609  3223  4626 14509  2965   738 10682  3692  6093\n",
            " 11606 10340  6749 10807 13999 12627  2194   676], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7317  1410 14039 10592  1990 13631 11878  5391  4935  4726  7548  2441\n",
            " 11996  4016  3485  9261    46  5167  4626    94 10570 11167  7747  5185\n",
            " 10412 13204   188  3245  4626 12749 13204  8495], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4453  5109  6374  9664  6573  3223 13192  4368  2421  6256   430  8734\n",
            " 13016 13675  8177  7090  7116  1905  9595  6463 12542  3844  1054  1967\n",
            " 11002 13722  9066  7011  3438  9067 11977  7045], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3706  1714  7674  7230 10440 10304  6999  7125 11917 13105 13726 11871\n",
            " 11970 10668 14269 14352 10343   450 13565 13696  8068 13593  7746    95\n",
            "  9401 13259  7392  8016  5936  2208 11002  6929], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6093  9852  4592 10260  8525  7729  5286 10205  2345  1140 11970  5822\n",
            "  3274  2308  5392  9861  4998 12111 11231  1392  2841  6247  9226 13568\n",
            "  6579 10604  5109  9331 10027 11070 14352  8346], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12862 11222 10704  4690 14076 11970 12075  1927 12862  4161  3536   738\n",
            " 10806 10907 14401  6065  9109  1054  5758 11945  7410  4964  9042  9389\n",
            "  8124  6762 10493  1910 11871  3218  9305  8715], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8171  5549  1392 11231 13219  7880  9909 14249  3640  8424  5224  9089\n",
            " 12445  6851 10704  4123 12532 13627   969  3971  5675  9266 10194  7109\n",
            " 11637  1036  4396 13016 11222  5663  6755   739], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2582  4626 12086 11804   205  5095  3245 14253  7609  2965  8202  3671\n",
            "  7026   512 12819 10317  5857  3274  9090 13535  6463  4068 13016  5215\n",
            "  2234 13101 13305  6093  2018  6365  7937 14444], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4280  7227  8236 12162  7460  2601 12735  4971 11885  4105 14297  8283\n",
            " 13675  1459 11418 13759  8918  8292  8937  8541   261  5006  3274 12641\n",
            "   890  8807  2754  2843  7609  7910  2673   850], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3984 10777   756  6440  8520 11970  6127  3611  5742  8857 11222 13659\n",
            "  9406   177  1926  4628  7666  1418 13737  3671 10304  2630  1949  3640\n",
            "  8257 10977  2623 11552 12790  6540  3696  1752], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13909 14023  4368 14132 12181  3125  4801  8650  3274 12429  9097 13424\n",
            " 13568 10171 12817  5109  7197  4590  3125 11222  1949  9338 12770 12382\n",
            "  7393   188  3278  2241   739  5915 14581  7746], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4123  4590  1885 11166 12551  8554  4061  6093 11167   439 12071  8154\n",
            " 14566  4396   777  8982  7185  9401  1935 10026  7440 10827  4971  7910\n",
            "  7392   177 10204  4227 14525 12304 13179   430], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10491  1949  6762  4546  5973 13280 10960  6436 10960 12819 12274  4267\n",
            "  5095  5966 10153 11006  6683 11222  8731  5758   188 10657  7884   557\n",
            " 13506  3518 12429  5758  9423  4344 10426  8587], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11063 13981 10581 14517  4170 13229  1748 13584 10704  8850 13981  3218\n",
            "  2458  2235  3884  4160 14504  9394 10205   186   972 13664  4590  5095\n",
            "  9780 12404 10326  7674 12298  5523 11598 13182], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3083  8025  9704  1097  4567  9389  2170  4197   821  3696   500 11222\n",
            "  3218  6257  4156 10223 13914  1221  1752 10340  1556   957 10155 10758\n",
            " 12429  4242  7474  1863  6721 14274  9104  2689], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4792  4402  2315 10027  6173  6463  6747   204 10326  5841   738  3785\n",
            "  7469  9972  3218   690  1473 13969  4372 11726  5639  4628  1407  2582\n",
            "  6559  4462 12404  9797 12928  2998  7747  1036], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6591  6127 12404  6256  9319 10986  3218  3251 10322 12274 14083  4638\n",
            " 12749 11412  9389   891  7790  8346 11883  5518 11510  7197  7609  6920\n",
            "  1055  7565 12870  4132  8149   391  5758 10618], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6336  3653   315  3642 12351  8126  7287  9116  3452   177  2400   294\n",
            "  9258  4368  8906 13909  4047  2011 12786  3887  7453   261 14272  8437\n",
            " 14537  9768  4202 11565  8334 12352  9972  2235], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3729 11446  7921  3729  4925  5082  3785  1099  3755  8821 11585  6762\n",
            " 11167  1488  4047  4590   739 10962 10396  1125  1390  1990 13390 12544\n",
            "  9934 12089  3976 14297 12298  5167  5857  8895], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8138  3656 12683  2310  5067   487  3218  6093 14658  6208  3125  9353\n",
            "  5762 12353  2309  6269  8823  1862  3446  6381  5964 11552 11807  8605\n",
            " 13580  2923  7626  7746  8027 14141  1665  3653], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  512  1502  8878 11948 11600  7996  6579 10211  8248 10900  7408  1439\n",
            " 11222 12058 11792  8138  2226  9310 10995  1687 14537  4845  2951  1556\n",
            "  2686  9996  7572  7094 11001 12755  9956   162], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10756   872  1237 14661  6619  3706  7317  9195 12532  2096  2820 14491\n",
            " 10672  6575  4080  5091 13086  6688  9780 13332  9356  8249 11639  8556\n",
            "  6915  4316  2282  4372  1331  7253  1054 10326], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8559  6044  7410  9580 14650    93  4062  5663 10993 10274 13139  5573\n",
            "  1527  6330  4062  8138  1371 11287  3528 12003  4444 13303 10405 12119\n",
            "  6836  6973   994  3345 10877  5490  5734  8198], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11231  1999  6463 14230  5286  7451  4396 10249  9875 10721  3272 11305\n",
            " 14274   862 12463  2492  8138  1015  4187  8918 13789  7182  1451  6459\n",
            "  3534 13121  2301  1575  8242 12742 10135  9053], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3541  7651 13094  7934 12167   386  8198  3111  7357  6256  8371  2444\n",
            "  7462  4170  7049  4329  5136 14253   804  6857  6228 13937  6104 13375\n",
            "  4626  5231  4507   573 10426  1640  1556  3563], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9598 10304  1217 11216  6868  9344  4397   739   226  6573 12162 10800\n",
            " 12216  8288 13376   195  2439 12605  3455  6703  4599  2998 10993 12323\n",
            "  4047  3218  6669 10326 13051 10563  5485   553], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12920 11598   756  8436 14108 14537 11876  5095 11222  3655 10777   263\n",
            "  1042  4028 14191  6028 14206  3274 13204  6609 13356  7227 14164  6851\n",
            "  7565 13981 11903  4671  7921  1882 11667 11222], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  730  8007  6498  8839 14492  8366  8885  5062 11528 10304 10274 11652\n",
            " 11745  9609  1489  9288  9657 13462  7875  4648  7422 12623  3203  9067\n",
            "    12   177 10772   267  5837   177 10993  7162], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  739  6041 14162 10086  7807  4223  5207 14181 10408 13462  1697 13387\n",
            " 11972  8526   814  7148   482  9423  9251  2754  7955  4597   121  8135\n",
            "  7536  7392  4368  6582  9616  6116  3218   417], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13766  1637  5061  3218  8124  7746  5992  1619  5117 11847 14503  4829\n",
            "  7875 11118  7415  2235 10747  1527   739  3218  2623 10704   361  8171\n",
            "  4292  8346 10723 12819  4965   459  7956  3673], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12352  4491  4047 14297  4593 11590  3729  1910  6836 12489  8498  1362\n",
            "  6573 14213  2754  2851 12404 10342  8480  1832  6100 12610  7585  4638\n",
            "  8138  1879 14521  9338  5372   477  8171  3713], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8436  1542  5250  2449  1910  2431   964  2745  4592  1949 13366  9751\n",
            "  4062 11883  3274  9642  7102  6762  3849  7156  2325 12429 10370  5654\n",
            " 10755  9995 14637   522  2968  9271 14562  6792], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3245  8708 10875 10623  4726 12542  7804  8657 13352  9777 11412  4865\n",
            "  8657  3785  5114  6509  7921  6048  3136  4638  4560  7903  3795  4486\n",
            "  6093  9494 13981  3541 14143 14501 10205   208], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1990 13495 13502  7747 13995  2188 13961   739  3305 10210 11002  8158\n",
            "  5617 10755 12429  3411  9364 12623   450  7090  3455 11222  6025  1114\n",
            " 11225  9713  7197  1949 11714  7202  7560  5832], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  899  1556  3875  2421  8865  9488 10993  7146 10326  2627 10797  3218\n",
            "  7807  6144 13863  1941 13051 14537  4170   871  4585  7773 11276  7392\n",
            "  9600 14008  9174  8807 14581  4799  5784  8504], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13352  8661  2736  3837 14462  1439  5091  5815  1426  4690  6515  6591\n",
            "  8745 10986  3642  4205   985   730   385  4304  7870 13945  9666  7867\n",
            "  2843   278  6976 12510  1036  8504 13234  5713], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1542 13683  9885  8276  1793  4177   734  3655  4217  6769 12529  7880\n",
            "  1949 10461  5059 10070 11305 13051  5007  6408 12521 10777  6688  7197\n",
            "  1701  6999   554 13921  6459   756  8485 10190], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5044 10247  1819 13185  2336  3843 12862  1099  4292  7398  9575  5734\n",
            "  5549 10326   361 13194 14562   459  2403  3449 13234  5795  7609   409\n",
            "  5362  5255 13394  8189  8135  2235  7818  8332], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3274  6112  5109 14175  1752  9128  7011 13192 14537  4368 12220  6688\n",
            "  6951  2213 10776  3452 14652 12461  8561 12300  4260  3272  1992  4156\n",
            "  9884  2960  4197  1724  4397  4696  9577 13241], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1045  1037 13549 14089 12585  1752   985  8171  2517  7746 10127 10304\n",
            "  7049  6065 11970  2582 13675  7642  7680  2405  7747  4492 12503 13192\n",
            " 12339  3218  7360  6127 10818 10818  5215 12539], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5333  7392  7361 13917  4570  3111 10326   553  7460  1172  3538  6073\n",
            "  6208  3400   991  3785  7109  9580 10185  8172  4188  8334  3704  4403\n",
            "  8339  2194  5253 13462  5541  2209 10138  2535], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10153 11650  1760 10375  4667  8966  6463  5721  1036  5002  4491  2230\n",
            "  5568 14549  3251 11792 13051  3477 11535  5140  6688 12619  2111  6179\n",
            "  3311  3218   158  7302 12597  7885  8753  1949], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11431  3565  6241 12623  7836 11357   411 13462 10604  6971  6591  7392\n",
            "  6762  3274  6579   881   420   553  7317 13675   434  2235 12036  9546\n",
            "  3299  5044  4304 13179  5587  2266  2991  4023], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12681  8138   916  6597 13737  3729    15  3455 14297  8577  9158 13351\n",
            " 11717  4389  7666 14132  3119 11384 12588  6716 13204  8346  1926  9554\n",
            "  7713  7565  8283  3218 14077  3738 12862 11222], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9921  5936  5942  1580  1949 11650  9078  8486 11257   686  3708 10086\n",
            "  1251 13595  3310  8110 13443  9494  6938   267 10772  7392  7681  1827\n",
            "  5535 11801  5549 11021  5185 12583  8895 13192], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4023  6925  4062    52  2623 13055  8346 13571  9423  6620 12220 12929\n",
            "  9595  6936  2574  7711  5549 13232  2235 11995  2356  1949 13874  6288\n",
            " 13241 11771  3755 10025  6256  1371  8593  5488], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9830 13740  6491  9562 12220  4368 12671 10205  8327  9389 10049   738\n",
            " 12939  3785  9864  6857  3345  2409  5681  2351  6020 14360  1770  4567\n",
            "  8834 11355  6163  6631 10592 10001  2787 13723], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13064  7674  8464  3022  3218  9546  8436  8556  3274 13051 11231 11138\n",
            "  4242 12181 12362 12404  7121 13981  8966 11387 13232 13234  4488 11469\n",
            "  1718  5265 13772  7185  4460  5671  9032  5231], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4648 11247 11071 14509 10849 12220   195 13912  9699  4227  4105  6463\n",
            "  2127  2282 13352  9626  1039 14119 10990 10696 10461  7197  8470  7745\n",
            " 10777   455 12608 13132  2832 12404  5784  6073], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13821  1854  8332  7146  6643   269  7334    20  2548  2422  3111  3755\n",
            "  2936  9562  3971  1527  8257  7227  7747 10371 13591 10739  1793  8346\n",
            " 13675  7843  8138  6099 14568   123  1055 11580], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1225  8327  2031 10195 11254  9861  9608   865  5274  8966  8198  3223\n",
            " 11825  9902    95  3375  5408  6020  5518  9792 13282  7232 13594  4062\n",
            "  4708   579  6086  6872 10138  4485 10993  9797], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11021 13820 14562  5768 13204  9389  2356 11970   409 14503  4462  2517\n",
            " 10846  5665  3143  2103   195  1835 13969 10568  5006  1225  4105   123\n",
            " 14122  9554  1339 14119    13  5838   877  9055], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7090  9903  2754  6762  8760  3125  7121  8901  4502  8126 11589  5915\n",
            "  1294  3790  7937 11970  3729  1556  1556  1925  8143  8914  3125  3706\n",
            "   674  9837 11393 11598  1114  4745 12052  6105], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4227  1923  8025 11776  2444  5015  8138  7599 11317  1692  3245  4592\n",
            "  8555  4865  3345  2673  8198  2726  1391 14478 11827 10529 12608 12529\n",
            " 13785  6573  3671   738  1990 14562  1036 13045], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9883 12559  8719 13401  9934  6857 12429  9691  8367  3345  8561   608\n",
            " 13400 11222  5808  5784  6591 12429 10719  3143  5666  7557 13064 11420\n",
            "   608  3772 12588  9127  1439 13772 11035  9658], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1036  6513 14581  6623 10304 10138  1110 11276  5795  1125  4203  9406\n",
            "  3222 11058 12985 14230 10395  1426   555  4554  8953 10647  6158 10536\n",
            "  7884 10076  6497 12783  8966 11222  5210  8073], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10403  3644 12232 14394  2725 13631 14463 14626 13157 13789  1649  3673\n",
            " 11970  4927  5185  8334 13523  6295 11590 10807 14115  6266  4275  3736\n",
            "  4953  2843  9066  2577  5015 12872  4231  6700], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4665  4389  8596 11200 13105 12404 13515  6863  9885  3021  1225  6609\n",
            " 10703  2149  1055  6778  3168  9095  7803  4187 14271  2421  3706  1697\n",
            " 11071 11598  5147  7186  5620 13265  3887  9466], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14420 14537 10446  5856  7270  7885  7030  6688 11970  4426 12439  5153\n",
            " 12579  2208  1556 10498  5610  5348 13261 12181 13051  4062 13981  3528\n",
            "   763  4129 10587 13059 10675 10519  5207   691], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1036 13043  8504 14637  4626  7666   842 12299 12848 10094  7439 10213\n",
            " 11066 10722  3059  3908  7565 11321  7791  7706 10993  7746  4275  8212\n",
            "  9018  7910 12399 12433  2085  6481 13204  7543], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4626  4482  2824  2092  1879 12429  3597  5109 10808 14648  5665  9885\n",
            " 11019 13462 12431  9316   789  3807  3976  1538 14383  3756 14369  9025\n",
            "  7891 11776 11544  6268  3611  9866  5377  2627], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1459  3259  3665  7107 10094  7910  9671  5597   676  6265  8743 10487\n",
            " 13341  5611  7897  3310 13050  8606 11631 10210  4626  1392  8969  6048\n",
            "  6288 11894 10877  2673  6158 14537  8074  1745], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7605   194  1949  3005 11318  7921  9364 12377  8478  6578 12091 13727\n",
            " 13726  3828  2968  4854    93 11043 12529  1752  8526 10846 11467  1271\n",
            "  2942 10656  4135 13157   177  6990  6065  9055], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5220  8189  8485  9754  6591  3033  1823 13477 11052 10205 14458 11965\n",
            "  3867  7659  8249  1820  3979   487  5795  5245  2211  9881 11727   750\n",
            "  7212  3778  8850 12390  9369 14568  4664  8966], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10878 10304  9963  4712  3472  7548  3686  1967  4798  8823  9588  3887\n",
            "  1697  1911 13805   298    42 10138  3345   328 13101 10790 13648  1967\n",
            "  5298 11945  7651 12204  3921   382   177 11231], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5549 10304  2409  9374  1708 13527 10581 13129  3242 14562 13870  5905\n",
            "    93  9406 10722  1014  2248  1426  7317  9757  1827   183 11254 11970\n",
            "   850  1473  7560 13549  8236 10842 12338  1294], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6158  8436  1885  8982  7165  9302  1149 12607   209 13266 11436  8249\n",
            "  1927  3983 11275  4086 14541 10849 14352  7817 14274  7623  5337  8173\n",
            "  1835 11842 13105  4293  8239  1246  3437  7592], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10877  7870  4865 10463 13524  3812  9747  2149  6747 11583  6179  3218\n",
            "  1471  1036 13914  6711 10704  3347 12414  5802 13352   706  1916  1430\n",
            "  2421  3450  9067  3245  9276 13318  9538   993], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11307  3778 10868  4491 11618 12854  3125  9266 12204  3438  4568  4392\n",
            " 11261 12913  1448  1331  6041 13092  9712  9484  8433 12798 12779 13215\n",
            "  8339  6810  1425  7921   738  2375 12532  8114], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12996 10759  1905 14503  5392 12895 10205  5784 10504 11961 10118   739\n",
            "  4849  6295  4728  7469 11736  4550 11814  5102  8898  3541  3125  7037\n",
            "   453 10568  8916  3218  4590 13231 14297  1064], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6265 10818  7439 12463 11894 10719 12429  6990  2423   391 10993 13021\n",
            "  6738  8966  7161  6573 14364  6836   288  8555  4331  2011 10021  2444\n",
            " 12257   691  4105  1511 14008  5120  7393  2139], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5342  9616  9466  7950   825  3826 10205  2627  7976  1448 10595 10631\n",
            "  7592  2705  7565  7711  5663 13083  4396   730 10818  5201  6527  6551\n",
            " 10071  7584 13016  1036 10274 11816  4279  8473], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5642  9179  9423  5221  5430  9387  2301 11513 12935 13810  5611  9101\n",
            "  2928  4275  7565  1159 10205  9128 13897  7164 11369  4498  1543   338\n",
            " 14227  6990  4086  5015  9451  7588  1955  8334], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10153  9850  2335 14139  7127  6822  4469  4139  2339  9837 13462  5247\n",
            "  5069 13955  1110 10590 11620   964  3274  5062  6954  4624 14650  9174\n",
            "  8446 11222  2436 13079 13086 12204 11652 11557], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8918 11503  7746 10837  5232  7469 12748   434 10370  6683  8283  5503\n",
            " 12280  9780  9992  6573  3218   472 11055  7408 12429  3696  5826  2713\n",
            "  8227  9564 13926  4123   635  4767  1636 14544], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3702 12793  7671  8349  5143  8845  7863 14031  8500  5919 13242 12190\n",
            "  9907  1172  7580  8334  7460 11898 10536 11449  1152 12991 10877  4814\n",
            " 14637  6732  6106  5012  4105  6256 12952 11914], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9962  6127  7197  1910  7197  6531 10677  7666   459 11052 10161    44\n",
            "  2838  8895 10704 11584   921 11898 11606  8687    58   650  3703  5231\n",
            "  7139   382 11307  7960  8236  7937  4626  2502], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13134 13845  1671  7995  7566  1740 13999    44  7392  2754  2812 11759\n",
            "  2809  2319  5399  4813  5637  3498 10489  6498  8687  1697 10581  2843\n",
            "  9978  9327  4045  1093 12688 13192 13386  7345], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9335  8592 11052  9554 12382  9577 14012  7226 11276  3541 12542 10827\n",
            "  2586  3935  1823  1589  1331  1793  8216   676  7950  3671   717 14216\n",
            " 12445  2383 14639 10761  3595  9883 11970    33], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7994  5734 11261  5467   919  9903 10489  9466  9407  2465 10570  6579\n",
            "  4506  7937 13955 12429  6526  4023 12585  8838  7727 12463 12542  5597\n",
            " 10795 10078  3037   622  3454 12291  9428  5756], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1260  6581  2007  2655  2483   307 12429  7897 14198 10931 10405 11150\n",
            "  1926  7383  1556  3272 12836  8504  7687  3924  2073  2634  9897  4462\n",
            "  4638 11453 10185  1039  5269  9870 11914  6038], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13182  9784  8065  3960  7757  9628  9594  4061  9677  6124  8404  2080\n",
            "  8663  4638  8406  7062  7733  9777 10351 13044  1613 12106 11652  1879\n",
            " 10368  2241  1439 10519  6851 11856  1636  2077], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7816 13690 11871  6127  5351  2411  9744 10993 10027 12257 14274  7078\n",
            " 13731   608  4604  4453  4745  5581  2860   595  9423 12408   928 12404\n",
            "  5256 10543  4546  2140  6265 11782 12755 13627], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7884 10343  1815  7224  6031 13690  1099 14012  1990  9757  8430  3729\n",
            "  9174 11305 12194  6489  4308  3736  8171 12252 12448  5250  6234  7869\n",
            "  1232  3250 14039 13979 11052  1862  4023  4592], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12220   832   328  5392 11337  8140  3944  8418 10803  8519 13465 12416\n",
            "  3485  2274  7899  4772 10772 12429  3452  6591  8622  7965 13242 13627\n",
            "  3004 14404 12748 13847  7950  6688   525 12262], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14158  7746  7609 14400 10749 11590 10818 10986  1990  2707  7109  6078\n",
            " 13506  5624  1949  7151  3452  5545 12991  7121  8158   385  8482  7651\n",
            "  9170  1700  4514  6098  6711  5316  9923  3679], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7139  6809  6888  7428  5587  2994 12404  3813 13394   409  6762  4570\n",
            " 13210 11488  9679  8300  6732 10385 11305  3333  2517 11651  5231  3541\n",
            " 14083  6119 12027  9389  9710  3048  8827 14479], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11945  5742  2041  7950  2820 11306  7674 13502  5008  7565  2832 14297\n",
            " 13631  6463  3742  4912  6032  7241  8371 11883  4402  6348  9751  9850\n",
            "  7408   739  7870 10436  3807  3169  7671  9727], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12926   434  8948 11822 10827   541 11507  4595 12479 11970  1990  6053\n",
            " 14123  4783 12695  7384   738  9297 13210  1563 11052  4396  2618  5228\n",
            "  3706 11073  9389 14334  3807   263  1028 10618], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13875  7937 12053   539  3921  4491  9850  3385 13743  4773  1823  1823\n",
            "  8065  7277  1697  9484  7934  3144 12681 10888  5028  8556  3030  2497\n",
            "  6119  3587  2127 12864  2889 11668   830  2779], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12511  4304  2207   761  6167 12151 12246  7870  7460  9671 13241 14567\n",
            " 10078  6321  5622  1115  2577  7156 10382 12428 13894 13914  6851  6463\n",
            "  1247  4323  1742 14194  6810  4003  2742  6172], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10972  7934  7126  5625  4595  8179  9797 13505  2994  5097  1527  1225\n",
            "  6357  8474  4602 11965  3587  1149  5532  7934  3394  9338 14221 11290\n",
            " 11883 14537 13343  2230  2409  2147  5734  5253], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2655   382   913 13352  5351  1407  6179  3598 11624 13204 10502  6093\n",
            " 10295 14562 12623  9624  7803  2169  7998  9710   973  5445  3671  2356\n",
            "  8532 10463 10803 13776  9609  1473   195  1107], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5510    33  3421  2158 13759  8583  4217  6065  9888  2423  5245  4912\n",
            "  8243  7517 11391  6688  2834 12194 13551  3742 12597  3775  5351 10882\n",
            " 11078  1055  2033  3438  9577   448  5597 14352], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5272  5784  7205   500 11701 11078   492 14423  4920  5253  1827  1050\n",
            " 10581 13175  4001  1062  4590  6954 12793 11465  9172 10637 10883  5342\n",
            "  9101 11552 12249 12641  9261  1448  5450  9438], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7565  4139 10570  7460  4814  8786  7127  4396  7599 10227  2554 11939\n",
            "  2404 11307  2301  4170 13502  3595 13544  4242  8171   267 14403    58\n",
            " 14029  4592 10692  5764  8593  5392  2092 10675], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3048 13529  1378 12024  1200  7227 11848 11807  3052  2771  1944 12220\n",
            "  2158  5707 12988 10536  7205  7417  1619   417 10820  4261 10993 12429\n",
            "  7121  3976   188 11206  7599  6167  8544  7579], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8436  3811  3645  3345  1178  8981  6265 10951  4396  6295  6573  7039\n",
            "  7090  9020 13024 13805 14302  7545   985 10856 12006  6690  7732  3321\n",
            "  6630  4626  5792  7213  7848  9768 10366 12616], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7756   382  3125  7469 13094  2582  5634  4304 10366  8177  7455  1471\n",
            "   608  1784 11598  2745  2697  2517  7737  5377  3272 13973  8715  1935\n",
            "  7776 12584  1391  2977  3143  3976  9230 14087], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3345  6920  9546  1426 14151   194 11980  2423 11807 13204  2327  9744\n",
            "  3366 13792    94  3516 11247 12641 13535 13805  5102 11980 13999  4658\n",
            " 13981 14083 11995  6990  9394    41  9954  7500], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3271  8264  9384 13627 13938   690   168  1250  4371  6663  9990  5729\n",
            " 12155 10326   643  7463  8815  3218 10686  3746 13591  9679  1752 13657\n",
            "  2744  4912  8198 12423  1287 14635 13544  4306], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10755   195 14470 14294 12186  2301  8437 10772  8731  3119  5322  1967\n",
            "  6766 10440  9654 13179  8069  2325  4491 11824  2230  6002  8982  3807\n",
            "   417 14569  9365  7190 13185  7609 11333 11152], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9316 12071  1091  8016  3904  2139  3163 14479  3223 12369  9544  4123\n",
            "  4280 10153  4477  1900  4659  5679  2779  9295 12793  3692  3345  9101\n",
            "  4590   522 11073 11146  2576  8504  4142 11824], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2736  3904  1574 12257 10304 11412 11846  1273 11012  8028 12220  1796\n",
            "  8436   990 11807 14132  2961  3225  7148  9780  2848 12274  6278 14025\n",
            "  9616  9389  8905  6265  5644  3333 14507 13914], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5061  9837 13584  1114   527  7469  1091 11073  3843  3021  2092 11436\n",
            "    70  8663  7746  6532  1082  7121  4217  9616  3809 13624  5146  1413\n",
            " 13305    39  8138  8746  6769 11356  6971  1990], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6109 10846 11914  2444  2351  1738  9406  2785  7885 12862  2291  8179\n",
            "  2502  7998  8198 13540  8222  4920  2213 12328  4323 11052  1563   459\n",
            "  7660 12688 10625 10772   195  9066 12950  8300], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13157  5567 13265  7185  7609 11002 11824  2623 10260  5758  4105  2920\n",
            " 10803 13179 12072 13086  4344  7817  4396  6067  5561 12300 13204  8171\n",
            "  6034  3647  9595  8901 13784 12220  4996  6011], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6295   730 10845 10809  4850  3742   750  5905 11168  4814  2623  1984\n",
            " 11487 13737  2139  3582 10162 11970 12148  1453  4025   707  4746  6851\n",
            " 13763  1140  8996  6663  9389  8256 12681  4595], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10868  2993  6491  9932   826  7671  2537  9307 13969 14248  3345  5078\n",
            "  6571  9702  1036  1555  6238  3068    12  5555  3800  8184  5115 11717\n",
            "  5666  4388  3633  7453 11146 11589   850  8449], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1823  2479  2327  8931  8513  1246  6623 10446 11222 14479  1511  9387\n",
            "  6029 12404  3450  6782 14593  4650  6382  3190   847    84  5044  1463\n",
            " 11073 12819 14151 11960   568 13981  6029  8121], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7834  2287 12121  3345 14310  7885  1107  8073  1619  7175  4845 13021\n",
            " 12482  9423 11446  1538   142 11630 12996  6290  1636 12150 10458 13863\n",
            "  1439  8543  5666  8982 13897 11276  6093  7446], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1002  2127  4814  1095  9609  5181 11624 14503  6822  7440 13953 12688\n",
            " 12338 12111  6810 13374  7544  3655   434  5245 10667  4993 10618  9019\n",
            "  6851  9415  8797  8642  4029  1039  5120  1114], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12257  4094 10382   894  2479  1682 13210 14458  7125  6824  4585  4466\n",
            "   382 12150  1574  9101  5875  9108  7965  3976  6030  2319  7609  3835\n",
            "  9839  8593  1532 11970 11590  4460  5231  5545], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8527  5255  5748  1039  4280  5780  2325 14587  9183 14136 10568 10610\n",
            " 10605  7267  4018 13981  7227 13179  4590  7287  6938  5202  9101 12769\n",
            "  7068  6228  9206   267 10247  4667  7747  9994], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9261  3142  6969 10138  7517 12044  8853  4132 13664  4925 10034  8966\n",
            "  6071  5102  2972 12683  1132  4412  8855  3951  6463  9443  9156  2230\n",
            "  1748 13953  3409  4329   569  4697  5742 10463], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11200 11807 11019  3218  4830  8544  6630 10704 14648 13805  4691  2605\n",
            "  8966 12579  6498  2292  7385  2111  6683  4638 14481 10452  3068  7031\n",
            "  7121  6436  8418  3823 12352  3778 10342  8792], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2655   676  6971  1200  2421 11261  1990  4625  1132 11871 14538  2575\n",
            " 10223 11970  4062   964  8897  8500  8249  5467  2634  7462  3289 14184\n",
            " 10252   263  2638 12911 12560 10536  7454  1353], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5555  3119 12443  2849 11899  6076  4242 14322 10973  8346 12560  5903\n",
            " 11139  9029   117  6762 11631  3755 13982  3655  4726 10138  2327  2230\n",
            "  8371  2843  1619  3206  6491 13777  6011 14089], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14261 10251  6630 12083  3871 13624 13242  9054  7164  9095  4132 13726\n",
            "  7408 11590 12612  7292  9231  1200 11305  8734  4603 13969 12688  6158\n",
            "  6202  4134 10700  4161 14635  3411 11848  2582], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1439  4930   130  6249  6920 11146 13210  4813   522  1831  1566  4071\n",
            "  5009  1159 14132  7817  1198  9885  7932  9006 12641  2325  6048 11844\n",
            " 11686  1300  1140 12463   512  4628  9206  4080], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11491  9415  5342 12204   288 13981  9420 11146 14322  5826 13105  3218\n",
            " 12024  6938  1543 11624  1300  6463  2118  5442  5140  9975 11544   602\n",
            "  2389  7876  7405  8198  3397  6179   684  1949], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2013  9055 11052 11305  7167 13544  9054 10381  7935  5964   772  8532\n",
            " 14269  8532  6034 11384  3206  2812  1949 10028  4658 13874  8069 10700\n",
            "  6573 10912  4857 13056   885 11624  5286  4807], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8473  6688 12286  6747  8900 10405 11846  5115  3696  8446 12404  8198\n",
            "  5745   263  2208  8504  9852  4161 10027 13601  9089 14091  7933 12809\n",
            "  4478  5545  7828  3039 13954  1247  2812  7336], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10227 10722 13204  9055  1300  1353  5264 10094 13614  6547 11736  4638\n",
            " 10645  3719 12641   434  9745 10151  5663  9981  9546  9768  2739 10807\n",
            " 12125 11402  1738 12652 14401  5247  3681  6076], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1390 10993  3458  4396 12431 11750  4326  2389  8283  6920  8198  2668\n",
            "  3421  8418  3951  3250 14479  7870 14648   690  8715  7609   512  3580\n",
            " 11766  1522  5642  3719 11146 10960 10536 10818], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9595 13642  8436  5758 12596 12941  3785 11146 11222  7733 14562 13073\n",
            "  6928  6039  1198  3335  6049  7796  5449 13911  1152   567  3481  6732\n",
            "  8450  5784  4158  7251 12114  1889 12532  2820], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11052  5888  8283   458  7674   195  4953  6249  1090  2668    41  7385\n",
            "  6547   750 14562  8544  6573 10722  5784  8718  4595  8450  5247  5015\n",
            " 11231 10304  1851  1695  2586 10993 11423  1200], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11827  5700  7875 10338  2325 12256  8851 13696  9287  8544  7146  2779\n",
            "  8346  8918  8198  7937  8028  1232  7994  9376  9295  9595 10138 13043\n",
            " 10700 10668   269  7965  8907  5587  7536  6228], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5012  4384  4462  2421  7469  2582  3345   656   602  2575  2320  6172\n",
            "  2977  1625  7572  4329  6782 11980  9067  2455 12125  8098 12024  3130\n",
            " 11200 12560  1949 10382 14083 13280  3335  7149], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11185  2536  6073  1039  8259 12220  4223  3048 11052  9628  4590  7875\n",
            "  5587   739 13763  5215  6288  2404  5535 14668  1831  7512  8532  9601\n",
            "  9407  3119  3371  3310 14538 10396 12195  8931], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10818  2301  4123  9006  5231 11247  1752 11965  4460  8177  4160  5946\n",
            "  1677  9443  6463  4800  8404  9133  2127  5587   205 11146   201  8436\n",
            " 14680  1039  9850 14401  6934 11565  4080  9389], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4932 10088  4726  7440 13995  9389  9133  3927  2998 14119  8897 14566\n",
            "  7139 10186  6459  4511  8307  1400  1630  5311  6208  7817  6925  5700\n",
            "  1217 10090 13914  7125   703  9362  3203  2041], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2112  8543  3723 11343 11384  1284  2582 12926  1949  6810 12707  3222\n",
            " 10322  4829   738 12220 10104  8283  4071  8605  8700 10592  9576  7395\n",
            "  7565 12220  3310 13232   512 13813  1049  7746], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11825   851  5666  2037  2575 10463 14648 12479  5247 14443 11801  8257\n",
            "  5453  2301  1251  2262  1448  3218  8522  5616 11261 14587 12811  3100\n",
            "  4003 10704 14119  2548  9432 14206 11804  4627], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13544  5654  6532  7379  3111  5700   850 13629  5745  7884  6104  3843\n",
            "  8901  5597 14461 10094  4697  7609 10034  8901 13944  6208  8334  8349\n",
            " 12529 12382  9117  7609  7872  1288 10932 12749], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7965  6747 12166  6249  7031  9526  9656  3887  8318 12560 13298 10405\n",
            "    58  9666  2327  8520  6119   738  2618 10987 14501  7884  7453   195\n",
            "  7609  4280 12641  4161  7413 10426  3242 13387], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6714 11807 12220  1543  7525  6158   123  5015  3825  3102 13642  9305\n",
            "  1777  1752 10704 13726  3706 10987  9603  7205 10150  9295  3472  3935\n",
            "  4242  3250  1152  1039  2375  1426   594 12529], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 2924  3706  2575  5989  9777 11951  3218  4086 12145 12811 10426   602\n",
            " 10507 13045  9020  7492  7323  4293  3355 12404  5555  9658  5131 14567\n",
            "  3904  8527 10527 12926 10251 10704   890 13737], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12609  6844  3021  6509 11231 11758  2789  6810 12148  5102 11524 14274\n",
            "  7139  4638  5399 10946  5450  5245   763 12848  2013  5617 14503  4358\n",
            "  7109  2582  5821  1262 13375 14118  1140  4648], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 9865  4606   763 12181  1728  1172  4892  5391  6491  4814  3691  9231\n",
            "  7410  7125  2695  7993  6127  1823    84  4626 13845  2630  6071 12033\n",
            "  1777  4477  2356  6295 10094  5207  9554  1439], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12359  8950   122 10089 12429 12529  2491  4272  7031  4023 14106  5700\n",
            "    44  7937  1752 10252  9658  9384   439 11457  1288 11807  5351   363\n",
            " 10190  6190  9619  7469  7994 12681 10153  4227], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1799  7610 10930  7126 13666  9287  4018  3544  6208   420  9522 10818\n",
            "  5439  9338  2158 12585 12560  3123  7572 11782  9992  4329  7395  5555\n",
            " 13955   833  3563  1448 10162  3409  9956 10076], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5389  2241   755 14538  4603  4593  3061  8069 13155  6116  1463 12808\n",
            "  2853  6334   826  2055  4491  9751  9603 11452 14525 10818 14029  4105\n",
            "  1439 11146  2308  7723  8364 12339  1391  8300], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  989 14419  3345  2491  8371  2977 12960 10083  3448  3590  3587  5015\n",
            "  8259  1381  8918  4535 12346  1831 10375  5265 14419  8256  9331 12585\n",
            "   569 11009 10405  1831  7872 14151  6218 11970], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12641  1390 11384  5581  5351   177  1755 10366  9174 13760  1039 13351\n",
            "  9770 13727  3702 13036  6382  9338  7460  6493    44  5342  7190 11337\n",
            "  4606  5784 12352  6959  7588 10304 11844 11222], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5848  8198  2479   123  8500  2114  4086  4047  7453  4511  3666 13273\n",
            "  2007   506 14031 14322   132  2112  1697  3250 13298 13549  6377   193\n",
            " 10519  1390 12283  6381  7609   771 13158 13897], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  177  9451  4466 12024  1820  1463  8966   493  7625  8817   472  1339\n",
            "  8288  4544 11539  8069  2668 12339  5981 11790   417 11027  9774  6699\n",
            " 14297  7674  3350 11146  2127  5302  2826  3976], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6559 11782   834 12875 14163  8121   427 10304  8576  4170  3978  2668\n",
            "  8223  1247   567   186 11210  7185  7189  1820 12681 12135  2325   957\n",
            "  5255  1451 14337 11618 12220  3506  6158  8827], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3218 13874  7872  8457 13723  4726 11512    38 11654 13973 10645  6971\n",
            " 14206 13961 14163  8966 14579  6527  6920  1697  6925  1752 13108  8914\n",
            " 13759  8648 13045  9682  4690  1778  2919 12848], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7323 12811  1926 13056  9646  8914  5265  5509  7565  4326  8972 14083\n",
            " 12641  5775  3649 11387 10691   205  1297  4105 14337  5617 10679  2673\n",
            " 11006 13192  1152  7453 12392  9344  1065  8527], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  290  5705  7818  7818  2673  5071  7104 10185 11009  5742  3251  2720\n",
            " 11034  6925    84 14192  4829  5700 11330  9668  3983  6914  5265  5700\n",
            "   439  7334  9287  4086    44 13791  3251 13665], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  771  4392 11899  1724  1760  5102  7108  8371  8406  6920 13515 13462\n",
            "  8257  1991  6904  7921  4771 14562 11970 13535  1448 13784  8158 11113\n",
            "  9095  9861  6559  4971  2247  1262 14670  1418], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4227   850 11776 12352  2241 13981  2317  4062  2161  7993  9768 13351\n",
            "  5467 14177  9619  3305  3218  9595  9389  7884  1752  7450 13913  1439\n",
            " 10885 14419  8406  3218  6044  3115  6762  6116], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6793 11844 11970  9603  2217 14614  7818  9054  8249  6317  8366  5639\n",
            " 11970   619  4491 14508 14367  9727 11146  6579  7474  9364  7287 12338\n",
            " 13192  7692 12382 11623  4186 11970  5992  5061], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7572 10986  9861  3647  8436  4132   235  9881 11185  9101  6249 10104\n",
            "  4912  5231 12793  8827  1419  9861  9692 13935  1697  6073  3144  9407\n",
            "  2953  2244 13159  7389 13462  5617 11114 14029], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1748  7536  8216  1905  3319  3172 14562 11066  3251  8130 11387 13462\n",
            "  1553  8950 12404  2158   730  3251  3206   595  1582 10190  7937  7921\n",
            "  6956    58 13192  6265  6454  8725  9389  3197], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3565  7746  7776  3335  6179  6127   373  6039 11970  4788  2582  8845\n",
            "  8787  6738   989  5392  6032 14581  7292  7520  7818 12620  4293  5265\n",
            "  8878  2819 13071 14503  3117  4792  3083 11661], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[  899  5095  7438  1596 10753  9266 10928  8154  2325 14107  8648  8158\n",
            "  7612  2312  1823   755 11267  9378 13683 13045 11276 12688  2291 13146\n",
            "  2705  2750  7934  5194  3778 11387  3409 14503], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5969 13914  4170 13879  1069  5565  8138  3310  9095   998  6713 13424\n",
            "  6608 11801  2210  9642  6208 10304 10386  4638  5705 13874  3048  3778\n",
            " 13298  6071  4017 12135  5342  3755  1271  8366], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5109 11848  7164 11709  5399 13776  9616  3203  5245  1042  7492 12369\n",
            " 10603  6775 10199  4726 11369  2994 12148 12125  5095 10076  9464  3218\n",
            " 12003 14341  7334 10326  5336 10536  6270  3755], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14581  9415  7747 12443 11127  3119  5545  3345  7292  5255 11631  9397\n",
            "  3272 11276  8520  5942 10827 10530  6732    44  9754  8517  7334  6269\n",
            "  5145  3598   218   209 14581 13766  6990  3647], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[12220 12862  9216  5215  1030  4628  9338 14076 13791  6630    41 13045\n",
            "  2301  9443 13462 13159  4749  2905 10685  2500 11263  8198 14479 10272\n",
            "  8442  9658 10396  8436  6422  6347  7104  6747], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5247 13424  5666 10145  1640  4003  2024  5185  4800 10275 11391 12362\n",
            "  7126   385  3345 12178  4186 11231  9883  4003 11590 12952    70 12911\n",
            "   615   439  2479  6493  1162  3784   861  2230], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8865 12641  9682 10818 11845 13192 14302  1114  4329 11729  6249 11452\n",
            "  9394  6041  7880  8628  1473  6792 12544 11804 12246  9995  1927  3229\n",
            " 13351 13158  6071  7701  6630 12352 10296 14522], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1701  8230 13505 11257  1418 10059  8979  6208  1215  8593  8349 13917\n",
            "  3655  6382  5351  7553  8845  9928  6377 10326 10995 10295  1409  7945\n",
            "  6688  9095 10489 11970  5177  6422  8906  6347], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4275  6208  4593  9067 10340  2646   409  4478  8914  9261  7068 11618\n",
            "  7255  2477 12233  7733  1682 11970  7278  9389  8198  2119  1885 14528\n",
            "  7090  6269  7031  2616 14501 10749  9684  4775], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14581  2725  1808  8969 13955  2548 11146 12217  7937  5887  7884  3222\n",
            "  7440 10463 11261  1082  3693  6778  5989 11276   177 10738 12414  8906\n",
            "  7553 13568  6256  4697 13241 12688  7552  5707], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11970 13453  1271  7474   877  9926 11412  4921   957 13427  8366  6630\n",
            "  5095  3210 14259 11231  8972  7503 14458  9176  8731 12895 12811  2905\n",
            "  3251 12811  4331  9266 10185  6228  4892  1939], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4638  8544 11146  8866  9445 12084 12779 10055  5467  4870   376   738\n",
            "  2805 12726  9141 12404 10878  7162 12220 12540   427  6732 14269  2646\n",
            " 12790  4813 11903  3388  9603    12  5801  8806], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1960  4498 11035 13408 11717 11387 14503  4590  2127  7083  1107  2736\n",
            " 13051 13613  2779  7011  4326 12119  7469 10749 10087  9389  1820  1724\n",
            "  9397  9289  4462  8898 11231 12503    95  5232], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10807 11326  8406  7512  6100 11792  3565  8969 10986 10366 11432 10889\n",
            "  9089 13772 10386 12220  7517 11825  4813 13192 11267  8897   385  6108\n",
            " 10536  8130 10613   569  9997  9338  9843  6020], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13387  6522  3692  2127  8520  9866  7898  7469 10076  2421  7674 10465\n",
            " 13892  6981  7706 10195  6031  2686  6813  1039  1200  3048 11716  9347\n",
            " 10965 12979    77 10944 13094  5632 12204  7666], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7440 13784  2290 12681  5666  4813  9295  4306  2194  8371   434  5654\n",
            "  3835  9745 11276  8138  3778  2301  9394  2477 13995 11507 12150  8895\n",
            "  1093 13737    41  4592  4156 12352  8346  1835], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13913 11898  4160  8789  7440  5815  3719  1091    70  2649  7512  1473\n",
            " 12353   439  6762  9284  1823  4135  4606  2981  9176  1294  5541 11707\n",
            "  1824  1262 10268 13925  7994 14119  7776  7701], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 6738  8249  5336  8544  7405  7991  1532 10605 11432  8025  3206 14269\n",
            "  7227  7565  8648  4585   170  6716  3102 11995 12925  7994  8283  1217\n",
            "  6990 10603 12109  9800  1478  8901 13266  9346], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7385  8211 11925   730  5666  9305  2655 11247 10993 12463  9751 14579\n",
            " 11970  2994 12339  3656  5109  2805 10260  2241  8827 10326  2981  2548\n",
            " 10317 14005  2276 13995  9314 10411   850   730], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1271 14501 10932  8950  7474 10338 12542  4329  5875  7125   500  5245\n",
            "  3218  6532  7993 14240  9609  4704  1069  1439  4086 12245  6099 14181\n",
            "  8966 14118 14083  3411  9054  8172 14645  2444], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4538  9423   825  4638  9101  6463 12071  2754  6256 11848 13713  8064\n",
            " 11766  4638  3514 13080  9533  1905  4160 12833  9634  7011  9067  2496\n",
            "  8821  7945  2351  3310  7780  9101 12326 14515], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1390  9466  8177  3479  1854  5342  5527  5222  7037   886  3218  6605\n",
            " 14568  7596 12089 10818  7733  9844 12125  7643  6116  1055   686 14118\n",
            " 13179  5032 13167  6295  2158  1695 10568 11970], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[13942  3755  6532  2244 13633  4365  1992 10658  8138  7085  1376  7561\n",
            "  4003  7460  5351 11758 12119  3753  7803  7270  6539  6164  5342 12052\n",
            " 10729  5981 12121  4154  6699 13040  6938 11717], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1974 11412  3422  7139 12339 11337 12607  7553  5987 12267  3048  1132\n",
            " 11057 11524  2031 10987  4971 14255 11261  3727  9020 12150  6061 11856\n",
            " 13614 11848   382  9864  6463 10710  5143  7609], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3005  2013  1408 11715  6104 14012  7910  4072  2491  7733  8154  6238\n",
            " 10089 11012  3755  9897 10411  5220  7588  2832 10322  7572  6973  8504\n",
            "  7869 13945 10166  2290  7469  4132 13045  5795], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4047  9848 13192  9657  7642  6747  4116 13801  4293  7623  2789  1099\n",
            " 13925  1724    39  2652  6761 10536  6116  3536  1390  6269  2963  6836\n",
            "  7139  7455 13839  1580  2455 10822   139  9657], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[14060 13094  1934 11565 11251  4781  5377 13723 13351 14012  7492 10393\n",
            "  2496  9532  4656 12960  7708 14310  2325  1145 11507  3220  3696  7880\n",
            " 14495 13801  9362  1036  9938 14181  6295  1949], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3649  5617 13357 14345  1418  6573  8950  4626 12382  9953  9903  7674\n",
            "  8028   500 11072  9052  8544  9754 12819  2843 10645 11813 10142  9287\n",
            "  4156  6749 12923  9438  7175 12779  4773  5286], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4567  7733 10247  6341  7828 10814  1237 11231  6971 13204  5185 10719\n",
            "  5634  3713 12486  6158 12811 13024 12109  5705 11361 11231  7090 11195\n",
            " 11624  5816  5756  7937  5058   181  2998 13969], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4293 10592 12220  7440 12893  3206  4971  8667 12542  4595  7572 11175\n",
            "  8706 10513 10412 14037  6293  3218  9445  6936  3783 10274  8249   328\n",
            " 10260  2726  7356 12834  2455 12431  2145 14543], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 5775  7202  5758  8950  7561 11537  4217  4003  8371  6956  7987 14567\n",
            "   826 13776  6341  7672  8648  4355  4326  3561  3335  5449  1251  7189\n",
            " 11453  2444  9295  4819  9266  5272 13404  4814], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[11970  4638  9389  1900  4263   338 10618  7523  2421  8324 13925  1820\n",
            " 12832  9428  4938  4638 13192  9770  8527  7561  6732  7733 12960  4569\n",
            "  7139 11299  7126  8069  9658   734 13850  8327], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 3649  8914  9347 13083  8827 10432 11766  5721 10685 12923 12895 11848\n",
            "    84  6956 10803  6288  9055 12612  8622  1246  8827  7440   267  5055\n",
            "  3232  5775   209  8578  3042 12445 10322  7408], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 8288 11446  2832  8198  4843 12748 13999  5784 10199  3218 13913  3681\n",
            "    41  6732  1527  1882  9883  5311  3927  1913 10238  6164  9576  5213\n",
            "  5775 12681  1237  9226  8349  8371  6295 11361], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 7125  1139  1589 10618 13784  2239 14228  8609  2650 14272  4981  5177\n",
            "  9295 13759  8298 11066  8944  5611  8177  8307  6034  8259  4062  8767\n",
            "  2498  5231  9885  5568 12671  8240  4114  1237], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 4161  7884  7671  1160  4086  4001  5453   361  7950  7642  7776  5372\n",
            "  3458 12121  1910  5535 14163  3696  9389 14481  4749 14091  7175  9484\n",
            "  6084 10962  8184 14345 13303  8544  9522  2627], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 1082  1473  6699  3021  8327  4871  4947  9067  3738 13154  2325  9066\n",
            " 10785  2919 11925  5055 14479 10185  8249  9369 12782  8371   159  1061\n",
            "  6747 12024  9264 11263  2241  3458 14012  8556], shape=(32,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[10536  5011  7453 12429 11352  9508  1905  8845 10618  5568 13666 13883\n",
            "  3048  1339  9352  7610 10856 10326  4773  7185  9302], shape=(21,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate( test_ds ):\n",
        "    print(batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4PGxjttli6"
      },
      "source": [
        "## Creating User and Item Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BwcnBKDxVMk"
      },
      "source": [
        "**User Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SKZcU2qGwiGG"
      },
      "outputs": [],
      "source": [
        "user_doc=[]\n",
        "for mydoc in user_df['reviewText']:\n",
        "   user_doc.append( input_text_processor(  mydoc ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "FU_cW-H2ji3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 100), dtype=int64, numpy=\n",
              "array([[   2,   27,   65,  966,   25,  329,    5,   14,  450,  100,   16,\n",
              "        1377,  318,    5,   19,   21,  513,    4,    7,  119,   15,    1,\n",
              "           9,   63,  203,    5,  200,  348,    5,   19,   43,   71,    1,\n",
              "           8,  153,   12,   65,  161,  273,   32,   15,  819,   18,   23,\n",
              "         488,    5,   18,   23,  273,   11,   37,    6,  763,  373,    4,\n",
              "           7,  585,   18,   25,   11,  272,   49,   10,  209,    8,  116,\n",
              "           4,    6,  897,  353,  485,   32,    6,  283,   12,    6,  129,\n",
              "          13,   47,   34,    5,  187,    7,  120, 4058, 4526,  350,   12,\n",
              "         156,    7,  180,   17,    4,   27,  257,   27,   18,    1,  803,\n",
              "          14],\n",
              "       [   2,   14,  368,   13,   16,    6,   61,    5,   19,   21,    6,\n",
              "         118,    4,   18,   50,  124,   10,   49,  112,  345,  148,  224,\n",
              "          16,   83,  331,    6,  118,    4,  378,   18,  108,   10,  187,\n",
              "           5,  858,   11,   40,    1,    4,   14,   13,  643,  110,  559,\n",
              "           5,   19,  284,  173,   11,   76,   10,   15,  203,   27,    8,\n",
              "        1138,   16,   63,   12,    6, 4526,    4,   71,   13,   69,  101,\n",
              "         201,   41,   70,   71,    4,  332,   16,  849,  382,    4,    3,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0],\n",
              "       [   2,    7,   64,  531,   11,   66,   14,  154,    4,  202, 1659,\n",
              "          59,  807,  805,  279,  173,    9, 2103,   68,  102,  328,  828,\n",
              "        1105, 1259,    9,    1,   32,    8,  208, 1359,    4,   98,   10,\n",
              "          64,    1,  290,   11,   16,   56,   13,   37,    4,   14,  243,\n",
              "          25,   75, 1975,  197,    5,   19,    6,   37,   13, 1228,    4,\n",
              "           7,   25,  111,   10,   20,    8,  709, 1062,  169,    9,  251,\n",
              "           5,    9,   97,    7,   25,  402,  784,  626,    4,    4,    4,\n",
              "           7,  585, 3553,  108,  145,  523,    4,  371,    8, 2065,  169,\n",
              "        1105,   54,    1,    6,   37,   12,    6, 1259,    4,    7, 1599,\n",
              "         143],\n",
              "       [   2,    7,  668,  292,    1,  235,   83,  622,  672,    9,   25,\n",
              "         111,  402,   12,    6,  798,    4,   14,   13,   22, 1120,  186,\n",
              "           4,  200,   42,  103,  167,    5,   20,    8,   80, 2243,    4,\n",
              "          62,  808,    6, 1649,   16,  172,  489,   17,   18, 1599,  284,\n",
              "          28,   18,   50,  209, 1004,   70, 2425,  701,   38,  506,    4,\n",
              "           3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0],\n",
              "       [   2,    7,   66,    6, 4159, 3650, 4271,   30,   14,   13,    8,\n",
              "          52,  283,   81,   60,   18, 3343,  239,  506,    9, 1335,   47,\n",
              "         100,   15,    6,  535,    4,   14,   13,   22,  186,    1,   61,\n",
              "           4, 2470,    1,    5,   18, 2901,   28,   14,    4,   51,   16,\n",
              "          56,   30,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0]])>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_doc[7000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWDCul-D_N99"
      },
      "source": [
        "**Item Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "phoN10nsXZGc"
      },
      "outputs": [],
      "source": [
        "item_doc=[]\n",
        "for mydoc in item_df['reviewText']:\n",
        "   item_doc.append( input_text_processor(  mydoc ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I've been looking forward to trying these after hearing about how popular they were in Japan, and among Kit Kat fans as well. I do not recommend ordering these during warm weather, because they can melt and become smushy. I ordered mine right when summer began, and they were a bit mushy so I let them solidify under room temp. Afterwards, I tried some and they tasted fine. I was expecting a stronger green tea or matcha flavor, but it is actually quite subtle. The outer coating was creamy and not overly sugary, which I liked. Overall, I wouldn't say it's insanely good, but definitely a yummy treat.\""
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_df['reviewText'][0][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0kTL6A4FmuZY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(12, 100), dtype=int64, numpy=\n",
              "array([[   2,    6, 1381, ...,   69, 1769,    1],\n",
              "       [   2,    6,   55, ...,  182,   12,   55],\n",
              "       [   2,   14,  168, ...,    7, 1599,   66],\n",
              "       ...,\n",
              "       [   2,    7,   64, ...,   97,   12,   63],\n",
              "       [   2,   14,   13, ...,    0,    0,    0],\n",
              "       [   2,  151,  250, ...,    0,    0,    0]])>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_doc[5004]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1G79SrZySBqJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(item_doc[0])\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(item_doc[0] != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbR2h5ML5h70"
      },
      "source": [
        "### Converting ID to Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kSxQNOCYKAzF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[START] just another flavor of kit [UNK] but the taste is unique and a bit different . the only thing that is [UNK] is the price . i thought it was a bit expensive . . . . [END]                                                             '"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[user_doc[3282][0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Context-aware Matrix Factorization for Rating Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "num_users=user_df.shape[0]\n",
        "num_items=item_df.shape[0]\n",
        "feature_num=16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_specific_vector = tf.Variable(np.zeros(shape=(num_users, feature_num),dtype=np.float32)) \n",
        "item_specific_vector = tf.Variable(np.zeros(shape=(num_items, feature_num),dtype=np.float32)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uKWBtzhmMA5"
      },
      "source": [
        "## **PMF (Probabilistic Matrix Factorization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5JAoyyjOnJis"
      },
      "outputs": [],
      "source": [
        "class PMF():\n",
        "    def __init__(self, num_feat=16, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=152, batch_size=1000,num_item=9000,num_user=15000,mean_inv=3):\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.num_item=num_item\n",
        "        self.num_user=num_user\n",
        "        self.V =  0.1 * np.random.randn(self.num_item, self.num_feat).astype(np.float64)  # Item feature vectors\n",
        "        self.U =  0.1 * np.random.randn(self.num_user, self.num_feat).astype(np.float64)  # User feature vectors\n",
        "        self.V_inc = np.zeros((self.num_item, self.num_feat),dtype=np.float64)\n",
        "        self.U_inc = np.zeros((self.num_user, self.num_feat),dtype=np.float64)\n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.mean_inv= mean_inv  \n",
        "        \n",
        "    # ***Fit the model with train_tuple and evaluate RMSE on both train and test data.  ***********#\n",
        "    # ***************** train_vec=TrainData, test_vec=TestData*************#\n",
        "    def train(self):\n",
        "          \n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_data.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  \n",
        "            # Batch update\n",
        "            \n",
        "            for batch in range(self.num_batches):  \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "              \n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  \n",
        "            \n",
        "                batch_UserID = np.array(train_data['userid'][shuffled_order[batch_idx]], dtype='int32')\n",
        "                batch_ItemID = np.array(train_data['itemid'][shuffled_order[batch_idx]], dtype='int32')\n",
        "                # Compute Objective Function\n",
        "               \n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                              self.V[batch_ItemID, :]),\n",
        "                                  axis=1)  # mean_inv subtracted # np.multiply\n",
        "                \n",
        "                rawErr = pred_out - train_data['rating'][shuffled_order[batch_idx]] + self.mean_inv\n",
        "                \n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.V[batch_ItemID, :]) \\\n",
        "                       + self._lambda * (self.U[batch_UserID, :] - tf.gather(user_specific_vector,batch_UserID).numpy())\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.U[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.V[batch_ItemID, :] -  tf.gather(item_specific_vector,batch_ItemID).numpy()) \n",
        "                       # np.newaxis :increase the dimension\n",
        "               \n",
        "                dw_Item = np.zeros((self.num_item, self.num_feat))\n",
        "                dw_User = np.zeros((self.num_user, self.num_feat))\n",
        "                \n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "              \n",
        "                self.V_inc = self.momentum * self.V_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.U_inc = self.momentum * self.U_inc + self.epsilon * dw_User / self.batch_size\n",
        "                \n",
        "                self.V = self.V - self.V_inc\n",
        "                self.U = self.U - self.U_inc\n",
        "            \n",
        "                # Compute Objective Function after\n",
        "                if batch == self.num_batches - 1:\n",
        "                    pred_out = np.sum(np.multiply(self.U[np.array(train_data['userid'], dtype='int32'), :],\n",
        "                                                  self.V[np.array(train_data['itemid'], dtype='int32'), :]),\n",
        "                                      axis=1)  # mean_inv subtracted\n",
        "                    rawErr = pred_out - train_data['rating'] + self.mean_inv\n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.U - user_specific_vector) ** 2 + np.linalg.norm(self.V - item_specific_vector) ** 2)\n",
        "                   # print(\"1***************\\n\",self.U.shape)\n",
        "                   # print(\"2***************\\n\",user_specific_vector.shape)\n",
        "                    self.rmse_train.append(np.sqrt(obj / train_data.shape[0]))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1:\n",
        "                    pred_out = np.sum(np.multiply(self.U[np.array(test_data['userid'], dtype='int32'), :],\n",
        "                                                  self.V[np.array(test_data['itemid'], dtype='int32'), :]),\n",
        "                                      axis=1)  # mean_inv subtracted\n",
        "                    rawErr = pred_out - test_data['rating'] + self.mean_inv\n",
        "                   \n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(test_data.shape[0]))\n",
        "\n",
        "                    # Print info\n",
        "                    if batch == self.num_batches - 1:\n",
        "                        print('\\nTraining RMSE: %f, Test RMSE %f' % (self.rmse_train[-1], self.rmse_test[-1]))\n",
        "\n",
        "    def predict(self, invID):\n",
        "        return np.dot(self.V, self.U[int(invID), :]) + self.mean_inv  # numpy.dot 点乘\n",
        "\n",
        "    # ****************Set parameters by providing a parameter dictionary.  ***********#\n",
        "\n",
        "    def topK(self, test_data, k=10):\n",
        "        inv_lst = np.unique(test_data[:, 0])\n",
        "        pred = {}\n",
        "        for inv in inv_lst:\n",
        "            if pred.get(inv, None) is None:\n",
        "                pred[inv] = np.argsort(self.predict(inv))[-k:]  # numpy.argsort\n",
        "\n",
        "        intersection_cnt = {}\n",
        "        for i in range(test_data.shape[0]):\n",
        "            if test_data[i, 1] in pred[test_data[i, 0]]:\n",
        "                intersection_cnt[test_data[i, 0]] = intersection_cnt.get(test_data[i, 0], 0) + 1\n",
        "        invPairs_cnt = np.bincount(np.array(test_data[:, 0], dtype='int32'))\n",
        "\n",
        "        precision_acc = 0.0\n",
        "        recall_acc = 0.0\n",
        "        for inv in inv_lst:\n",
        "            precision_acc += intersection_cnt.get(inv, 0) / float(k)\n",
        "            recall_acc += intersection_cnt.get(inv, 0) / float(invPairs_cnt[int(inv)])\n",
        "\n",
        "        return precision_acc / len(inv_lst), recall_acc / len(inv_lst)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0y4xKXSRYU-"
      },
      "source": [
        "# **Adversarial Seq2Seq Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log files for training and test\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "graph_log_dir = 'logs/graph/' + current_time \n",
        "graph_summary_writer = tf.summary.create_file_writer(graph_log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PerplexityMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='perplexity',**kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.perplexity=self.add_weight(name='pl',initializer='zeros')\n",
        "\n",
        "    def update_state(self, nll_loss):\n",
        "        self.perplexity= 2 ** nll_loss\n",
        "\n",
        "    def result(self):\n",
        "        return self.perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_plx_gen_tch = PerplexityMetric(name='generator perplexity')  # teacher forcing mode\n",
        "train_plx_gen_plc = PerplexityMetric(name='generator perplexity')  # policy gradient mode\n",
        "train_loss_gen_policy = tf.keras.metrics.Mean('train loss gen policy', dtype=tf.float32)\n",
        "\n",
        "train_acc_dis = tf.keras.metrics.BinaryAccuracy(threshold=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Recurrent Review Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- it consists of two encoders and one decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UVYfYjX9YW"
      },
      "source": [
        "### **Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TwRd0VNHkMf0"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_dim, enc_units):\n",
        "    super().__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = max_vocab_size\n",
        "    self.embedding = tf.keras.layers.Embedding(max_vocab_size+4, embedding_dim, embeddings_initializer=keras.initializers.Constant(full_embedding_matrix),trainable=False)\n",
        "    self.gru= tf.keras.layers.Bidirectional(tf.keras.layers.GRU(enc_units,return_state=True,  recurrent_initializer='glorot_uniform' ))\n",
        "\n",
        "\n",
        "  def call(self, reviews, state=None):\n",
        "   \n",
        "    vectors = self.embedding(reviews)\n",
        "    _,encoder_forward_state,encoder_backward_state  = self.gru(vectors, initial_state=state)\n",
        " \n",
        "    return  tf.concat([ encoder_forward_state, encoder_backward_state],-1)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Decoder (Generator)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "skIgKP4iCABs"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_dim, dec_units):\n",
        "    super().__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = max_vocab_size\n",
        "    self.embedding = tf.keras.layers.Embedding(max_vocab_size+4, embedding_dim,embeddings_initializer=keras.initializers.Constant(full_embedding_matrix), trainable=False)\n",
        "    self.gru=tf.keras.layers.GRU(dec_units , return_state=True,return_sequences=True)\n",
        "    self.fc = tf.keras.layers.Dense(max_vocab_size, use_bias=False)\n",
        "    self.sf=tf.keras.layers.Activation('softmax')\n",
        "\n",
        "  def call(self, decoder_input, context_vector,state=None):\n",
        "\n",
        "     embedded_input= self.embedding(decoder_input)\n",
        "     joint_input_context =tf.concat([embedded_input, tf.tile(tf.expand_dims(context_vector,1),[1,embedded_input.shape[1],1])],2 )\n",
        "     outputs,dec_state =self.gru(joint_input_context, initial_state=state)\n",
        "     logits = self.fc( outputs)\n",
        "     prob_dist=self.sf(logits)\n",
        "\n",
        "     return prob_dist,dec_state\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DyhJk5pGKW_N"
      },
      "outputs": [],
      "source": [
        "class GeneratorLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "   # self.loss = tf.keras.losses.SparseCategoricalCrossentropy( reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # Calculating the loss for a batch of reviews.\n",
        "\n",
        "    mask = tf.cast(y_true != 0, tf.int32)\n",
        "    maskoff_ind=tf.reduce_sum(mask)\n",
        "    a=tf.one_hot(y_true[:maskoff_ind], max_vocab_size, 1.0, 0.0)\n",
        "    b=tf.math.log( tf.clip_by_value(y_pred[:maskoff_ind], 1e-20, 1.0))\n",
        "    #print(y_true)\n",
        "    #print(\"\\n\\n\\n\",a)\n",
        "    #print(\"\\n\\n\\n\",b)\n",
        "    c=a * b\n",
        "   # print(\"\\n\\n\\n\",c)\n",
        "    loss=-tf.reduce_sum(c) /tf.cast(maskoff_ind,dtype=tf.float32)\n",
        "   # print(loss)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v_zte_RHR5a"
      },
      "source": [
        "## **Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "84ZgGwB9HXi5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__( self, sequence_length, vocab_size, embedding_dim, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
        "      super().__init__()\n",
        "      self.sequence_length=sequence_length\n",
        "      self.vocab_size=max_vocab_size\n",
        "      self.embedding_dim=embedding_dim\n",
        "      self.filter_sizes=filter_sizes\n",
        "      self.num_filters= num_filters\n",
        "\n",
        "      self.embedding = tf.keras.layers.Embedding(max_vocab_size+4, embedding_dim,weights=[full_embedding_matrix],name=\"discriminator_embedding\",trainable=False)\n",
        "     \n",
        "      self.conv_unigram= tf.keras.layers.Conv1D(num_filters, filter_sizes[0], activation=\"tanh\",name=\"conv_unigram\")\n",
        "      self.conv_bigram= tf.keras.layers.Conv1D(num_filters, filter_sizes[1],activation=\"tanh\",name=\"conv_bigram\")\n",
        "      self.conv_trigram= tf.keras.layers.Conv1D(num_filters, filter_sizes[2],activation=\"tanh\",name=\"conv_trigram\")\n",
        "      self.conv_fourgram= tf.keras.layers.Conv1D(num_filters, filter_sizes[3],activation=\"tanh\",name=\"conv_fourgram\")\n",
        "      self.conv_fivegram= tf.keras.layers.Conv1D(num_filters, filter_sizes[4],activation=\"tanh\",name=\"conv_fivegram\")\n",
        "\n",
        "      self.gmp_unigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_unigram\")\n",
        "      self.gmp_bigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_bigram\")\n",
        "      self.gmp_trigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_trigram\")\n",
        "      self.gmp_fourgram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_fourgram\")\n",
        "      self.gmp_fivegram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_fivegram\")\n",
        "\n",
        "      self.dropout=tf.keras.layers.Dropout(.5,name=\"dropout\")\n",
        "      self.fc=tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "\n",
        "    def get_reward(self, discriminator_inputs , context_vector ):\n",
        "      \n",
        "      embedded_input= self.embedding(discriminator_inputs)\n",
        "      # print(\"\\n\\n embeded\",embeded_input.shape)\n",
        "      joint_input_context =tf.concat([embedded_input, tf.tile(tf.expand_dims(context_vector,1),[1,embedded_input.shape[1],1])],2 )\n",
        "\n",
        "      #  print(\"\\n\\n joint:\",joint_input_context.shape)\n",
        "      # print(new_vector.shape)\n",
        "      #new_vector=tf.reshape(new_vector,[new_vector.shape[1],new_vector.shape[2],1])\n",
        "      #print(new_vector[0])\n",
        "      # joint_input_context_reshaped=tf.transpose( joint_input_context,perm=[0,2,1])\n",
        "      #print(\"\\n\\n joint reshaped:\",joint_input_context_reshaped.shape)\n",
        "\n",
        "      cv_unigram=self.conv_unigram(joint_input_context)\n",
        "      cv_bigram=self.conv_bigram(joint_input_context)\n",
        "      cv_trigram=self.conv_trigram(joint_input_context)\n",
        "      cv_fourgram=self.conv_fourgram(joint_input_context)\n",
        "      cv_fivegram=self.conv_fivegram(joint_input_context)\n",
        "\n",
        "      #print(\" cv uni: \",cv_unigram.shape)\n",
        "      #print(\" cv bi: \",cv_bigram.shape)\n",
        "      #print(\" cv tri: \",cv_trigram.shape)\n",
        "      #print(\" cv four: \",cv_fourgram.shape)\n",
        "      #print(\" cv five: \",cv_fivegram.shape)\n",
        "\n",
        "      #cv_unigram = tf.reshape(cv_unigram,(cv_unigram.shape[1] , cv_unigram.shape[2], 1))\n",
        "     \n",
        "      gmp_unigram = self.gmp_unigram(cv_unigram)\n",
        "     # cv_bigram = tf.reshape(cv_bigram,(cv_bigram.shape[1] , cv_bigram.shape[2], 1))\n",
        "      gmp_bigram = self.gmp_bigram(cv_bigram)\n",
        "     # cv_trigram = tf.reshape(cv_trigram,(cv_trigram.shape[1] , cv_trigram.shape[2], 1))\n",
        "      gmp_trigram =  self.gmp_trigram(cv_trigram)\n",
        "     # cv_fourgram = tf.reshape(cv_fourgram,(cv_fourgram.shape[1] , cv_fourgram.shape[2], 1))\n",
        "      gmp_fourgram = self.gmp_fourgram(cv_fourgram)\n",
        "     # cv_fivegram = tf.reshape(cv_fivegram,(cv_fivegram.shape[1] , cv_fivegram.shape[2], 1))\n",
        "      gmp_fivegram = self.gmp_fivegram(cv_fivegram)\n",
        "\n",
        "     # print(gmp_unigram)\n",
        "      #print(gmp_bigram)\n",
        "      #print(gmp_trigram)\n",
        "     # print(gmp_fourgram)\n",
        "     # print(gmp_fivegram)\n",
        "      gmp_overal= tf.concat([gmp_unigram,gmp_bigram,gmp_trigram,gmp_fourgram,gmp_fivegram],1)\n",
        "      #print(\"gmp :\",gmp_overal)\n",
        "      #training=true must be studied more but i know dropout during test must not be working\n",
        "      dropout = self.dropout(gmp_overal,training=True)\n",
        "     # print(dropout)\n",
        "      ath= self.fc(dropout)\n",
        "      gc.collect()\n",
        "     # print(ath)\n",
        "      return ath[:,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "FCRHY3LgfD2_"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'cross-entropy_loss'\n",
        "    self.binary_cross_entropy_loss = tf.keras.losses.BinaryCrossentropy( reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    loss = self.binary_cross_entropy_loss(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "GnKB7mW5evTE"
      },
      "outputs": [],
      "source": [
        "#hyperparameter\n",
        "t_step=1 # teacher forcing training number\n",
        "g_step=1 # generator training number\n",
        "d_step=3 # discriminator training number\n",
        "rollout_num=1\n",
        "units=int(feature_num/2 )# gru units\n",
        "batch_size=32\n",
        "num_batches=int(train_data.shape[0]/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "MB7HymOiTfdl"
      },
      "outputs": [],
      "source": [
        "class MaskedLossReward(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss_reward'\n",
        "\n",
        "  def __call__(self, y_true, y_pred,reward):\n",
        "    # Calculate the loss for each step.\n",
        "\n",
        "    mask = tf.cast(y_true != 0, tf.int32)\n",
        "    maskoff_ind=tf.reduce_sum(mask)\n",
        "    a=tf.one_hot(y_true[:maskoff_ind], max_vocab_size, 1.0, 0.0)\n",
        "    b=tf.math.log( tf.clip_by_value(y_pred[:maskoff_ind], 1e-20, 1.0))\n",
        "    aa=tf.reduce_sum( a * b,2)\n",
        "\n",
        "    aaa=aa*reward[:maskoff_ind]\n",
        "    loss=- tf.reduce_sum(aaa)  /tf.cast(maskoff_ind,dtype=tf.float32)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Z3NlswFZRbub"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(tf.keras.Model): \n",
        "    def __init__(self, latent_dim, num_batches, batch_size, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.use_tf_function = use_tf_function\n",
        "        self.num_batches=num_batches\n",
        "        self.batch_size=batch_size\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.user_encoder = Encoder(embedding_dim, units)\n",
        "        self.item_encoder = Encoder(embedding_dim, units)\n",
        "        self.decoder = Decoder(embedding_dim, units) #generator\n",
        "        self.discriminator = Discriminator(sequence_length, max_vocab_size, embedding_dim,[1, 2, 3 ,4, 5] ,100)\n",
        "      \n",
        "        self.loss_gn=GeneratorLoss()\n",
        "        self.loss_ds=DiscriminatorLoss()\n",
        "        self.loss_fn = MaskedLossReward() # generator loss with reward\n",
        "\n",
        "        self.optimizer_gn=tf.optimizers.Adam()\n",
        "        self.optimizer_ds=tf.optimizers.Adam()\n",
        "\n",
        "\n",
        "    def _train_step_gn_teacher(self,  batch_Userdoc_flattened, batch_Itemdoc_flattened,batch_Userdoc,batch_Itemdoc,batch_review,user_review_num,item_review_num):\n",
        "            with tf.GradientTape() as tape:\n",
        "  \n",
        "              user_enc_state = self.user_encoder(tf.reshape( tf.convert_to_tensor(batch_Userdoc_flattened,dtype=tf.int32) ,[user_review_num,review_max_length])) # user vector representations      \n",
        "              item_enc_state = self.item_encoder(tf.reshape( tf.convert_to_tensor(batch_Itemdoc_flattened,dtype=tf.int32) ,[item_review_num,review_max_length])) # item vector representations\n",
        "                  \n",
        "              pointer=0\n",
        "              user_context_vector=tf.zeros([0,feature_num])\n",
        "            \n",
        "              for i,doc in enumerate(batch_Userdoc): \n",
        "                user_context_vector=tf.concat([ user_context_vector, tf.reduce_mean(user_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "                pointer +=doc.shape[0]\n",
        "        \n",
        "              pointer=0\n",
        "              item_context_vector=tf.zeros([0,feature_num])\n",
        "              \n",
        "              for i,doc in enumerate(batch_Itemdoc): \n",
        "                item_context_vector=tf.concat([ item_context_vector, tf.reduce_mean(item_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "                pointer +=doc.shape[0]\n",
        "\n",
        "              context_vector= tf.concat( [user_context_vector,item_context_vector],1)\n",
        "        \n",
        "              loss = tf.constant(0.0)\n",
        "              dec_pred, dec_state=self.decoder(tf.concat([tf.cast( np.transpose([[2] * batch_size]),dtype=tf.int32 ), batch_review],1) , context_vector)\n",
        "              \n",
        "              loss=self.loss_gn(tf.concat([batch_review ,tf.cast( np.transpose([[3] * batch_size]),dtype=tf.int32) ],1),  dec_pred)\n",
        "            variables =self.user_encoder.trainable_variables + self.item_encoder.trainable_variables + self.decoder.trainable_variables\n",
        "            gradients = tape.gradient(loss,variables)\n",
        "            self.optimizer_gn.apply_gradients(zip(gradients, variables))          \n",
        "            print(\"gen batch loss in supervised training\", loss)\n",
        "            \n",
        "            train_plx_gen_tch.update_state(loss)\n",
        "      \n",
        "          # returning the probablity distribution over words for a batch of reviews\n",
        "\n",
        "    def _train_step_gn_policy(self, batch_Userdoc_flattened, batch_Itemdoc_flattened,batch_Userdoc,batch_Itemdoc,user_review_num,item_review_num):\n",
        "            with tf.GradientTape() as tape:\n",
        "              user_enc_state = self.user_encoder(tf.reshape( tf.convert_to_tensor(batch_Userdoc_flattened,dtype=tf.int32) ,[user_review_num,review_max_length])) # user vector representations      \n",
        "              item_enc_state = self.item_encoder(tf.reshape( tf.convert_to_tensor(batch_Itemdoc_flattened,dtype=tf.int32) ,[item_review_num,review_max_length])) # item vector representations                   \n",
        "              pointer=0\n",
        "              user_context_vector=tf.zeros([0,feature_num])                \n",
        "              for i,doc in enumerate(batch_Userdoc): \n",
        "                user_context_vector=tf.concat([ user_context_vector, tf.reduce_mean(user_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "                pointer +=doc.shape[0]            \n",
        "              pointer=0\n",
        "              item_context_vector=tf.zeros([0,feature_num])                  \n",
        "              for i,doc in enumerate(batch_Itemdoc): \n",
        "                item_context_vector=tf.concat([ item_context_vector, tf.reduce_mean(item_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "                pointer +=doc.shape[0]\n",
        "              context_vector= tf.concat( [user_context_vector,item_context_vector],1)\n",
        "              \n",
        "              dec_state=None\n",
        "              dec_prob=[]\n",
        "              generated_samples=tf.cast(tf.constant(np.full((len(batch_Itemdoc),1),2)),dtype=tf.int32)\n",
        "                  \n",
        "              for j in range(sequence_length):                      \n",
        "                  d_prob,dec_state=self.decoder( generated_samples[:,j:j+1], context_vector ,dec_state)\n",
        "                  dec_prob.append(d_prob[:,-1])\n",
        "                  #probability distribution of words  \n",
        "                  # Sample a token from the last distribution\n",
        "                  new_tokens =tf.random.categorical(d_prob[:,-1],1,dtype=tf.int32)    \n",
        "                  generated_samples= tf.concat([generated_samples, new_tokens],-1)   \n",
        "                  del d_prob          \n",
        "                              \n",
        "              #generated_samples,context_vector= self.generate_sample(batch_UserID,batch_ItemID)\n",
        "              #generated_samples=tf.cast(tf.concat([generated_samples,np.transpose([[3] * batch_size])],1),dtype=tf.int32)\n",
        "        # generating samples\n",
        "              g_loss = tf.constant(0.0)           \n",
        "\n",
        "              reward=[]\n",
        "              with tape.stop_recording():\n",
        "                for k in range(rollout_num):\n",
        "                  \n",
        "                    for given_num in range(1,sequence_length+1):\n",
        "                      # the generation of first part of seq\n",
        "                      _, dec_state=self.decoder(generated_samples[:,:given_num], context_vector)\n",
        "\n",
        "                      # generated probability distribution given the samples\n",
        "                      dec_rollout_prob=tf.zeros([batch_size,1,max_vocab_size],dtype= tf.float32)                     \n",
        "                      rollout_samples=tf.zeros([sequence_length-given_num+1, batch_size] ,dtype= tf.int32)                 \n",
        "                      rd=None\n",
        "\n",
        "                      if given_num!=sequence_length+2:\n",
        "                          # sampling seq length - i tokens with the roll out policy \n",
        "                        \n",
        "                          current_input_token=generated_samples[:,given_num-1:given_num]\n",
        "                          rollout_samples_list =tf.unstack(rollout_samples)                   \n",
        "                          for j in range(sequence_length-given_num+2):\n",
        "                              dec_rollout_prob,dec_state=self.decoder( current_input_token, context_vector ,dec_state)\n",
        "                          \n",
        "                              # Sample a token\n",
        "                              current_input_token = tf.random.categorical(dec_rollout_prob[:,0,:],1,dtype=tf.int32) \n",
        "\n",
        "                              rollout_samples_list.append(current_input_token[:,0])\n",
        "                      \n",
        "                          rollout_samples=tf.stack(tf.transpose(rollout_samples_list))   \n",
        "                          full_samples= tf.concat([ generated_samples[:,1:given_num], rollout_samples] ,1)\n",
        "                          dec_rollout_prob=None\n",
        "                          rollout_samples=None                        \n",
        "                          gc.collect()\n",
        "                          gc.collect(0)   \n",
        "                          gc.collect(1)   \n",
        "                          gc.collect(2)   \n",
        "\n",
        "                          #full sample\n",
        "                          rd=self.discriminator.get_reward(full_samples,context_vector)\n",
        "\n",
        "                      else:\n",
        "                          rd=self.discriminator.get_reward(generated_samples[:,1:],context_vector)\n",
        "                          #  print(\"size of dis\",asizeof.asized(self.discriminator, detail=1).format() )\n",
        "\n",
        "                    \n",
        "                      if k==0: \n",
        "                          reward.append(rd)\n",
        "                      else:\n",
        "                        reward[given_num-1] +=rd  \n",
        "\n",
        "              reward= tf.stack(reward,1)/ rollout_num # batchsize * seq_length\n",
        "              g_loss= self.loss_fn(generated_samples[:,1:] , tf.transpose( tf.stack(dec_prob) ,[1,0,2]) , reward)\n",
        "            variables = self.user_encoder.trainable_variables + self.item_encoder.trainable_variables + self.decoder.trainable_variables \n",
        "            gradients = tape.gradient(g_loss, variables)                  \n",
        "            self.optimizer_gn.apply_gradients(zip(gradients, variables))\n",
        "            print(\"gen batch loss in policy gradient training: \",g_loss)\n",
        "            train_plx_gen_plc.update_state(g_loss)\n",
        "          \n",
        "    def _train_step_disc(self):\n",
        "\n",
        "          with tf.GradientTape() as tape:\n",
        "\n",
        "            positive_data,positive_user_indices,positive_item_indices = self.sample_real_data() # ground-truth data\n",
        "            negative_data,negative_user_indices,negative_item_indices = self.sample_fake_data() # machine-generated data\n",
        "            #data shape (batch_size * seq length)\n",
        "            whole_user_indices=tf.concat([positive_user_indices,negative_user_indices],0)\n",
        "            whole_item_indices= tf.concat([positive_item_indices,negative_item_indices],0)\n",
        "\n",
        "            positive_labels = tf.ones(batch_size, dtype=tf.int32) \n",
        "            negative_labels = tf.zeros(batch_size, dtype=tf.int32) \n",
        "            labels = tf.concat([positive_labels, negative_labels], 0)\n",
        "\n",
        "            shuffle_indices = tf.random.shuffle( tf.range(0, len(labels),dtype=tf.int32))\n",
        "            whole_data = tf.gather(tf.concat([positive_data,negative_data],0),shuffle_indices)    \n",
        "            labels = tf.gather(labels,shuffle_indices)\n",
        "            whole_user_indices = tf.gather(whole_user_indices,shuffle_indices)\n",
        "            whole_item_indices = tf.gather(whole_item_indices,shuffle_indices)\n",
        "            query_embedding = tf.concat([tf.gather(user_specific_vector , whole_user_indices) ,tf.gather( item_specific_vector , whole_item_indices)], 1)\n",
        "            # query shape (batch_size ,2.feature_num)\n",
        "            dis_reward = self.discriminator.get_reward( whole_data,query_embedding)\n",
        "\n",
        "            #for i in range(real_data_num+fake_data_num):\n",
        "              #print(tf.convert_to_tensor( whole_data[i]))\n",
        "              #print(whole_user_indices[i])\n",
        "              # print(user_specific_vector[whole_user_indices[i] ])\n",
        "              #reward.append([0][0].numpy() )\n",
        "            #print(reward)\n",
        "            disc_loss=self.loss_ds(labels,dis_reward)\n",
        "          variables = self.discriminator.trainable_variables \n",
        "          # print(variables)\n",
        "          gradients = tape.gradient(disc_loss, variables)\n",
        "          # print(\"************************* gradient :\",gradients)\n",
        "          self.optimizer_ds.apply_gradients(zip(gradients, variables))\n",
        "          #calculate loss and gradient\n",
        "          print(\"disc loss: \",disc_loss)\n",
        "\n",
        "          train_acc_dis.update_state(labels,dis_reward)\n",
        "\n",
        "    def sample_real_data(self):\n",
        "\n",
        "      sample = train_data[np.random.choice(range(0,train_data.shape[0]),batch_size)][['userid','itemid','review']]\n",
        "\n",
        "      return   tf.stack(sample['review']) ,sample['userid'], sample['itemid']\n",
        " \n",
        "    def sample_fake_data(self):\n",
        "                \n",
        "\n",
        "      drawn_userid = np.random.choice(range(0,num_users),batch_size).astype('int32')\n",
        "      drawn_itemid = np.random.choice(range(0,num_items),batch_size).astype('int32')    \n",
        "      sample,_= self.generate_sample(drawn_userid,drawn_itemid)\n",
        "\n",
        "      return sample,drawn_userid,drawn_itemid\n",
        "\n",
        "    def generate_sample(self,batch_UserID, batch_ItemID):\n",
        "        \n",
        "        batch_Userdoc=[user_doc[i] for i in batch_UserID]\n",
        "        batch_Itemdoc=[item_doc[i] for i in batch_ItemID]\n",
        "        user_review_num=np.sum([it.shape[0] for it in batch_Userdoc])\n",
        "        item_review_num=np.sum([it.shape[0] for it in batch_Itemdoc])\n",
        "        batch_Userdoc_flattened= []\n",
        "        for i, doc in enumerate(batch_Userdoc):\n",
        "            batch_Userdoc_flattened=np.append(batch_Userdoc_flattened, doc)\n",
        "        batch_Itemdoc_flattened= []\n",
        "        for i, doc in enumerate(batch_Itemdoc):\n",
        "            batch_Itemdoc_flattened=np.append(batch_Itemdoc_flattened, doc)\n",
        "        user_enc_state = self.user_encoder(tf.reshape(batch_Userdoc_flattened.astype(int),[user_review_num,review_max_length])) # user vector representations      \n",
        "        item_enc_state = self.item_encoder(tf.reshape(batch_Itemdoc_flattened.astype(int),[item_review_num,review_max_length])) # item vector representations\n",
        "      \n",
        "        pointer=0\n",
        "        user_context_vector=tf.zeros([0,feature_num])\n",
        "\n",
        "        for i,doc in enumerate(batch_Userdoc): \n",
        "          user_context_vector=tf.concat([ user_context_vector, tf.reduce_mean(user_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "          pointer +=doc.shape[0]\n",
        "    \n",
        "        pointer=0\n",
        "        item_context_vector=tf.zeros([0,feature_num])\n",
        "\n",
        "        for i,doc in enumerate(batch_Itemdoc): \n",
        "          item_context_vector=tf.concat([ item_context_vector, tf.reduce_mean(item_enc_state[pointer:pointer + doc.shape[0]],0,keepdims=True)   ],0)\n",
        "          pointer +=doc.shape[0]\n",
        "\n",
        "        context_vector= tf.concat( [user_context_vector,item_context_vector],1)\n",
        "        \n",
        "        dec_state=None\n",
        "        dec_prob=[]\n",
        "        dec_out=tf.constant(np.full((len(batch_Itemdoc),1),2),dtype=tf.int32)\n",
        "            \n",
        "        for j in range(sequence_length):           \n",
        "            dec_prob,dec_state=self.decoder( dec_out[:,j:j+1], context_vector ,dec_state)\n",
        "            #probability distribution of words  \n",
        "            # Sample a token from the last distribution\n",
        "            new_tokens =tf.random.categorical(dec_prob[:,-1],1,dtype=tf.int32)    \n",
        "            dec_out= tf.concat([dec_out, new_tokens],-1)   \n",
        "        \n",
        "            del dec_prob          \n",
        "            del new_tokens \n",
        "\n",
        "        gc.collect()  \n",
        "        return dec_out[:,1:],context_vector\n",
        "\n",
        "    # def generate_incompleted_sample(self, context_vector,partial_sample):\n",
        "    #   #given a partial sequence as an input for decoder, this function generate a seq with particular length as an output\n",
        "      \n",
        "    #     joint_dec_inputs_context=self.decoder.concat_input_context(partial_sample, context_vector) \n",
        "      \n",
        "    #     dec_result, dec_state=self.decoder(joint_dec_inputs_context)\n",
        "    #     gc.collect()\n",
        "    #     #print(\"incomplete\",tracemalloc.get_traced_memory())\n",
        "\n",
        "    #     return dec_result,dec_state\n",
        "\n",
        "    # def rollout(self,dec_st,context_vector, initial_token,initial_index):\n",
        "    #     dec_state=dec_st\n",
        "    #     dec_pr=np.zeros([sequence_length-initial_index,self.batch_size,1,max_vocab_size],dtype= np.float32)\n",
        "    #     dec_out=initial_token\n",
        "    #     joint_dec_inputs_context=None\n",
        "    #     new_tokens=None\n",
        "    #     for j in range(sequence_length-initial_index):\n",
        "\n",
        "\n",
        "    #         joint_dec_inputs_context=self.decoder.concat_input_context(dec_out[:,-1:], context_vector )\n",
        "\n",
        "\n",
        "    #         dec_pr[j],dec_state=self.decoder( joint_dec_inputs_context ,dec_state)\n",
        "            \n",
        "    #         #probability distribution of words  \n",
        "    #         # Sample a token\n",
        "    #         new_tokens =tf.random.categorical(dec_pr[j,:,0],1,dtype=tf.int32)  \n",
        "    #         #print('120', psutil.virtual_memory()[2])\n",
        "    #         dec_out= tf.concat([dec_out, new_tokens],-1)  \n",
        "    #         #print('123', psutil.virtual_memory()[2])\n",
        "          \n",
        "    #         joint_dec_inputs_context=None\n",
        "            \n",
        "    #         gc.collect()\n",
        "\n",
        "\n",
        "    #     self.dec_prob=tf.transpose(dec_pr,[2,1,0,3])[0]\n",
        "    #     dec_pr=None \n",
        "    #     gc.collect()\n",
        "      \n",
        "    #     print('roll out end', psutil.virtual_memory()[2])\n",
        "\n",
        "    #     #print(dec_out)\n",
        "    #     # print(\"\\n\\n\\n\",dec_prob)\n",
        "    #     return dec_out[:,1:]\n",
        "    def train(self):\n",
        "        tf.profiler.experimental.start('logs')\n",
        "\n",
        "        for batch_step in range(4):\n",
        "          with tf.profiler.experimental.Trace(\"train\",step_num=batch_step, _r=1):\n",
        "            print(\"\\nstep number : \",batch_step)\n",
        "            (batch_UserID,batch_ItemID,batch_rating,batch_review) = next(iter(train_ds))\n",
        "            \n",
        "            batch_Userdoc=[user_doc[i] for i in batch_UserID]\n",
        "            batch_Itemdoc=[item_doc[i] for i in batch_ItemID]\n",
        "            user_review_num=np.sum([it.shape[0] for it in batch_Userdoc],dtype=int)\n",
        "            item_review_num=np.sum([it.shape[0] for it in batch_Itemdoc],dtype=int)\n",
        "\n",
        "            batch_Userdoc_flattened= []\n",
        "            for i, doc in enumerate(batch_Userdoc):\n",
        "                batch_Userdoc_flattened=np.append(batch_Userdoc_flattened, doc)\n",
        "\n",
        "            batch_Itemdoc_flattened= []\n",
        "            for i, doc in enumerate(batch_Itemdoc):\n",
        "                batch_Itemdoc_flattened=np.append(batch_Itemdoc_flattened, doc)\n",
        "\n",
        "\n",
        "\n",
        "            # t step generator training teacher forcing\n",
        "            for _ in range(t_step): \n",
        "              self._train_step_gn_teacher(batch_Userdoc_flattened,batch_Itemdoc_flattened,batch_Userdoc,batch_Itemdoc,batch_review,user_review_num,item_review_num)\n",
        "              \n",
        "            # g step generator training policy gradient    \n",
        "            for _ in range(g_step):             \n",
        "              self._train_step_gn_policy(batch_Userdoc_flattened,batch_Itemdoc_flattened,batch_Userdoc,batch_Itemdoc,user_review_num,item_review_num)  \n",
        "             \n",
        "            # d step discriminator training\n",
        "            for _ in range(d_step):\n",
        "                self._train_step_disc()\n",
        "\n",
        "\n",
        "            with train_summary_writer.as_default():\n",
        "                  tf.summary.scalar('Training perplexity for generator in Teacher Forcing mode', train_plx_gen_tch.result(), step=int(ckpt.step))\n",
        "                  tf.summary.scalar('Training perplexity for generator in Policy Gradient mode', train_plx_gen_plc.result(), step=int(ckpt.step))\n",
        "                  tf.summary.scalar('Training accuracy for discriminator', train_acc_dis.result(), step=int(ckpt.step))\n",
        "        \n",
        "        tf.profiler.experimental.stop()\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3YKdf1-uW8Q"
      },
      "source": [
        "# **Multi-Task Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "khZxlR9oRxVe"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(tf.keras.Model):\n",
        "      def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pmf_model=PMF(num_feat=feature_num,maxepoch=100,num_item=len(item_to_column) ,num_user=len(user_to_row), mean_inv=np.mean(train_data['rating']))\n",
        "        self.seq2seq_model=Seq2Seq(embedding_dim,num_batches,batch_size)      \n",
        "\n",
        "      def train(self,n_epochs):    \n",
        "          ckpt.restore(manager.latest_checkpoint)\n",
        "          if manager.latest_checkpoint:\n",
        "            print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "          else:\n",
        "            print(\"Initializing from scratch.\")\n",
        "\n",
        "          for epoch in range(n_epochs):\n",
        "              print(\"\\n\\nepoch : \", int(ckpt.step))\n",
        "            \n",
        "              print(\"********************************************* \\nPMF Model Training Turn =>\")\n",
        "              self.pmf_model.train()\n",
        "              print(\"********************************************* \\nSeq2Seq Model Training Turn =>\")                                         \n",
        "              self.seq2seq_model.train( )\n",
        "            \n",
        "              ckpt.step.assign_add(1)\n",
        "              save_path = manager.save()\n",
        "              print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.step), save_path))\n",
        "            # with graph_summary_writer.as_default():\n",
        "            #     tf.summary.trace_export('seq2seq train step',profiler_outdir=graph_log_dir,step=epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzxSK6IUr6O",
        "outputId": "212b1776-5de7-4896-f09a-4ea54c2405df"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "gc.collect(0)\n",
        "gc.collect(1)\n",
        "gc.collect(2)\n",
        "\n",
        "# creating an instance of Multi_Task Model\n",
        "mt_model = MultiTaskModel()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(0), optimizer=tf.keras.optimizers.Adam(), net=mt_model)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from ./tf_ckpts/ckpt-6\n",
            "\n",
            "\n",
            "epoch :  6\n",
            "********************************************* \n",
            "PMF Model Training Turn =>\n",
            "\n",
            "Training RMSE: 1.088599, Test RMSE 1.081316\n",
            "********************************************* \n",
            "Seq2Seq Model Training Turn =>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 12:05:55.947725: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
            "2022-11-16 12:05:55.947801: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
            "2022-11-16 12:05:55.948012: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
            "2022-11-16 12:05:55.948223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "step number :  0\n",
            "gen batch loss in supervised training tf.Tensor(8.199638, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(5.3772206, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0039768843, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0060112732, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.003760762, shape=(), dtype=float32)\n",
            "\n",
            "step number :  1\n",
            "gen batch loss in supervised training tf.Tensor(8.189674, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(5.2174034, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.018634222, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0031075657, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.013056725, shape=(), dtype=float32)\n",
            "\n",
            "step number :  2\n",
            "gen batch loss in supervised training tf.Tensor(8.178998, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(5.234179, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.010677272, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.022168674, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.013886287, shape=(), dtype=float32)\n",
            "\n",
            "step number :  3\n",
            "gen batch loss in supervised training tf.Tensor(8.168007, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(4.966794, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0019984683, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.005749539, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0025532097, shape=(), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 12:06:52.556968: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
            "2022-11-16 12:06:52.567937: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
            "2022-11-16 12:06:53.171230: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 98817 callback api events and 97817 activity events. \n",
            "2022-11-16 12:06:55.055135: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
            "2022-11-16 12:06:57.477218: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2022_11_16_12_06_55\n",
            "\n",
            "2022-11-16 12:06:59.316027: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.trace.json.gz\n",
            "2022-11-16 12:07:00.966967: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2022_11_16_12_06_55\n",
            "\n",
            "2022-11-16 12:07:00.982021: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.memory_profile.json.gz\n",
            "2022-11-16 12:07:01.009998: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/plugins/profile/2022_11_16_12_06_55\n",
            "Dumped tool data for xplane.pb to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.xplane.pb\n",
            "Dumped tool data for overview_page.pb to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to logs/plugins/profile/2022_11_16_12_06_55/mobin-vivobook.kernel_stats.pb\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved checkpoint for epoch 7: ./tf_ckpts/ckpt-7\n",
            "\n",
            "\n",
            "epoch :  7\n",
            "********************************************* \n",
            "PMF Model Training Turn =>\n",
            "\n",
            "Training RMSE: 1.085093, Test RMSE 1.081303\n",
            "********************************************* \n",
            "Seq2Seq Model Training Turn =>\n",
            "\n",
            "step number :  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 12:07:02.585432: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
            "2022-11-16 12:07:02.585485: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gen batch loss in supervised training tf.Tensor(8.139611, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(4.995831, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0075292327, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.03690392, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0030809348, shape=(), dtype=float32)\n",
            "\n",
            "step number :  1\n",
            "gen batch loss in supervised training tf.Tensor(8.124789, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(4.8410587, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.014208645, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0050380765, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0065654553, shape=(), dtype=float32)\n",
            "\n",
            "step number :  2\n",
            "gen batch loss in supervised training tf.Tensor(8.10791, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(4.6994424, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.013080272, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0046119336, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.004771966, shape=(), dtype=float32)\n",
            "\n",
            "step number :  3\n",
            "gen batch loss in supervised training tf.Tensor(8.302163, shape=(), dtype=float32)\n",
            "gen batch loss in policy gradient training:  tf.Tensor(4.2645955, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.00614631, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.002789698, shape=(), dtype=float32)\n",
            "disc loss:  tf.Tensor(0.0039372714, shape=(), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-16 12:07:58.624631: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
            "2022-11-16 12:07:58.635725: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
            "2022-11-16 12:07:59.234342: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 98725 callback api events and 97724 activity events. \n",
            "2022-11-16 12:08:01.112179: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
            "2022-11-16 12:08:03.433129: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2022_11_16_12_08_01\n",
            "\n",
            "2022-11-16 12:08:05.279853: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.trace.json.gz\n",
            "2022-11-16 12:08:06.863499: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2022_11_16_12_08_01\n",
            "\n",
            "2022-11-16 12:08:06.876406: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.memory_profile.json.gz\n",
            "2022-11-16 12:08:06.903411: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/plugins/profile/2022_11_16_12_08_01\n",
            "Dumped tool data for xplane.pb to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.xplane.pb\n",
            "Dumped tool data for overview_page.pb to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to logs/plugins/profile/2022_11_16_12_08_01/mobin-vivobook.kernel_stats.pb\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved checkpoint for epoch 8: ./tf_ckpts/ckpt-8\n"
          ]
        }
      ],
      "source": [
        "mt_model.train(n_epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ploting Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 20875), started 0:24:28 ago. (Use '!kill 20875' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-97fda4e8c883d923\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-97fda4e8c883d923\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xniWi24qcZsb"
      },
      "source": [
        "# test code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "85ryd-vJrTix"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_20452/2514589496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pm' is not defined"
          ]
        }
      ],
      "source": [
        "log_ps, mse_train, mse_test= pm.train(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4meEBmwsqMYC"
      },
      "outputs": [],
      "source": [
        "\n",
        "dec_result,dec_state=decoder(dec_output_tokens,dec_output_tokens,context_vector= user_context_vector,state=dec_state)\n",
        "sampled_token = tf.random.categorical(dec_result[:,-1, :], num_samples=1)\n",
        "print( sampled_token.numpy())\n",
        "dec_output_tokens=np.append( dec_output_tokens , sampled_token.numpy()[0])\n",
        "print(dec_output_tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-58-IpbsBSy"
      },
      "outputs": [],
      "source": [
        "dec_output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfemPqnVZPwk"
      },
      "outputs": [],
      "source": [
        "sampled_token = tf.random.categorical(dec_result[:, -1, :], num_samples=1)\n",
        "sampled_token.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_sYJN4wTBma"
      },
      "outputs": [],
      "source": [
        "vocab = np.array(input_text_processor.get_vocabulary())\n",
        "first_word = vocab[dec_output_tokens]\n",
        "first_word"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Explainable Recommender System.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('colabenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5859fc1fd51a29bc96a6c335b5cef2533de774a99a73e1484108bae0d11f06ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
