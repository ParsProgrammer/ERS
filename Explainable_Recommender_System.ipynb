{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uncomment the last two cell to clone the data and enable the GPU\n",
        "#! git clone https://github.com/ParsProgrammer/ERS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cd ERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrzVYQNxJm_W",
        "outputId": "8f98d417-6c2d-47ff-a041-84238103eba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.0)\n",
            "Requirement already satisfied: packaging in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (4.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.7.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (61.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (0.26.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-gpu==2.9) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.9) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.9.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from packaging->tensorflow-gpu==2.9) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.26.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow-text in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-text) (2.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: packaging in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (61.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.7.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.19.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow-gpu==2.9\n",
        "%pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BTOV54y-ckzq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (4.34.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1u4wpNQOEUc9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import gc\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "import datetime \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTkARkSuo9PR",
        "outputId": "8548446d-69cd-4727-8b8f-851569dd33d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==4.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (4.2.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==4.2) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==4.2) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from gensim==4.2) (6.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: nltk in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (3.7)\n",
            "Requirement already satisfied: click in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (2022.7.25)\n",
            "Requirement already satisfied: tqdm in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from click->nltk) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim==4.2\n",
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnDuJU4fpMLE",
        "outputId": "ecfd7d10-b929-43ce-cd99-0e2213f4e376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mobin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-08 11:31:45.594539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:45.633168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:45.633398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:45.634327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-08 11:31:45.635659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zer"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "o\n",
            "2022-12-08 11:31:45.635850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:45.636006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:46.129013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:46.129185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:46.129321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-08 11:31:46.129584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2132 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "else :\n",
        "  print(\"No GPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (61.2.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (4.12.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorboard_plugin_profile in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (2.11.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (61.2.0)\n",
            "Requirement already satisfied: gviz-api>=1.9.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (1.10.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (3.19.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from tensorboard_plugin_profile) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (2.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorboard\n",
        "%pip install -U tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.optimizer.set_jit(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyypFCrlw2SV"
      },
      "source": [
        "# **Data Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p7IbgFIxRQb-"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    name=b'\"verified\": \\\"true\\\",'\n",
        "    l=l.replace(b'\"verified\": true,',bytes(name))\n",
        "    name1=b'\"verified\": \\\"false\\\",'\n",
        "    l=l.replace(b'\"verified\": false,',bytes(name))\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('reviews_Grocery_and_Gourmet_Food_5.json.gz')\n",
        "\n",
        "# dataset link\n",
        "# Grocery and Gourmet Food\n",
        "# https://jmcauley.ucsd.edu/data/amazon/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_auxwvSRYsvu"
      },
      "source": [
        "Dataset Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E9FGFZINRQOn",
        "outputId": "0dad1216-9ec6-4528-fa44-32ab26a94602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151249</th>\n",
              "      <td>A2L6QS8SVHT9RG</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>Delicious gluten-free oatmeal: we tried both t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151250</th>\n",
              "      <td>AFJFXN42RZ3G2</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>With the many selections of instant oatmeal ce...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151251</th>\n",
              "      <td>ASEBX8TBYWQWA</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>While I usually review CDs and DVDs, as well a...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151252</th>\n",
              "      <td>ANKQGTXHREOI5</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>My son and I enjoyed these oatmeal packets.  H...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151253</th>\n",
              "      <td>A2CF66KIQ3RKX3</td>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>I like to eat oatmeal i the mornings. I usuall...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151254 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userID      itemID  \\\n",
              "0       A1VEELTKS8NLZB  616719923X   \n",
              "1       A14R9XMZVJ6INB  616719923X   \n",
              "2       A27IQHDZFQFNGG  616719923X   \n",
              "3       A31QY5TASILE89  616719923X   \n",
              "4       A2LWK003FFMCI5  616719923X   \n",
              "...                ...         ...   \n",
              "151249  A2L6QS8SVHT9RG  B00KCJRVO2   \n",
              "151250   AFJFXN42RZ3G2  B00KCJRVO2   \n",
              "151251   ASEBX8TBYWQWA  B00KCJRVO2   \n",
              "151252   ANKQGTXHREOI5  B00KCJRVO2   \n",
              "151253  A2CF66KIQ3RKX3  B00KCJRVO2   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "151249  Delicious gluten-free oatmeal: we tried both t...     4.0  \n",
              "151250  With the many selections of instant oatmeal ce...     4.0  \n",
              "151251  While I usually review CDs and DVDs, as well a...     5.0  \n",
              "151252  My son and I enjoyed these oatmeal packets.  H...     4.0  \n",
              "151253  I like to eat oatmeal i the mornings. I usuall...     4.0  \n",
              "\n",
              "[151254 rows x 4 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\",\"overall\":\"rating\"},inplace=True)\n",
        "df=df[['userID','itemID','reviewText','rating']]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 15126  15127  15128 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136128\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 151251 151252 151253] 136129\n",
            "[     0      1      2 ... 136126 136127 136128] 136129\n"
          ]
        }
      ],
      "source": [
        "current_fold=10\n",
        "kfold = KFold(10)\n",
        "random_iterator=kfold.split(df)\n",
        "for i in range(current_fold):\n",
        "  train_index, test_index = next(random_iterator, None)\n",
        "  print(train_index,len(train_index))\n",
        "  train_df, test_df =df.iloc[train_index], df.iloc[test_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VEELTKS8NLZB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Just another flavor of Kit Kat but the taste i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A14R9XMZVJ6INB</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I bought this on impulse and it comes from Jap...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A27IQHDZFQFNGG</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>Really good. Great gift for any fan of green t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A31QY5TASILE89</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I had never had it before, was curious to see ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2LWK003FFMCI5</td>\n",
              "      <td>616719923X</td>\n",
              "      <td>I've been looking forward to trying these afte...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136124</th>\n",
              "      <td>A74CGCGJ11Y23</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I've made rice pilaf from scratch. I've also t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136125</th>\n",
              "      <td>A36MP37DITBU6F</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This is a slightly mild flavored rice pilaf. t...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136126</th>\n",
              "      <td>A1JBBR4MNGQ70G</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I added a package of Albacore tuna to this mix...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136127</th>\n",
              "      <td>A2P739KOM4U5JB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>I am happy to report that Side Mates were grea...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136128</th>\n",
              "      <td>AT53ZTTO707MB</td>\n",
              "      <td>B009M516NE</td>\n",
              "      <td>This was a nice combo of rice, pasta and herbs...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136129 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userID      itemID  \\\n",
              "0       A1VEELTKS8NLZB  616719923X   \n",
              "1       A14R9XMZVJ6INB  616719923X   \n",
              "2       A27IQHDZFQFNGG  616719923X   \n",
              "3       A31QY5TASILE89  616719923X   \n",
              "4       A2LWK003FFMCI5  616719923X   \n",
              "...                ...         ...   \n",
              "136124   A74CGCGJ11Y23  B009M516NE   \n",
              "136125  A36MP37DITBU6F  B009M516NE   \n",
              "136126  A1JBBR4MNGQ70G  B009M516NE   \n",
              "136127  A2P739KOM4U5JB  B009M516NE   \n",
              "136128   AT53ZTTO707MB  B009M516NE   \n",
              "\n",
              "                                               reviewText  rating  \n",
              "0       Just another flavor of Kit Kat but the taste i...     4.0  \n",
              "1       I bought this on impulse and it comes from Jap...     3.0  \n",
              "2       Really good. Great gift for any fan of green t...     4.0  \n",
              "3       I had never had it before, was curious to see ...     5.0  \n",
              "4       I've been looking forward to trying these afte...     4.0  \n",
              "...                                                   ...     ...  \n",
              "136124  I've made rice pilaf from scratch. I've also t...     4.0  \n",
              "136125  This is a slightly mild flavored rice pilaf. t...     4.0  \n",
              "136126  I added a package of Albacore tuna to this mix...     3.0  \n",
              "136127  I am happy to report that Side Mates were grea...     4.0  \n",
              "136128  This was a nice combo of rice, pasta and herbs...     3.0  \n",
              "\n",
              "[136129 rows x 4 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYb9dMRLXjZT"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yY4NJsolgtl"
      },
      "source": [
        "**User Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9kPFQ1GJr_I"
      },
      "source": [
        "determining all unique users with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "l_eSbOjWRQD3",
        "outputId": "63fd7abe-5957-46a2-aa85-8ca3721bdec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00177463W0XWB16A9O05</td>\n",
              "      <td>[It is a good stand by coffee you can count on...</td>\n",
              "      <td>[5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A022899328A0QROR32DCT</td>\n",
              "      <td>[awesome texture for even the gluten eating ea...</td>\n",
              "      <td>[5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 1.0, 2.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A04309042SDSL8YX2HRR7</td>\n",
              "      <td>[I love roasted garlic &amp; sweet bell peppers. Y...</td>\n",
              "      <td>[5.0, 2.0, 4.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A068255029AHTHDXZURNU</td>\n",
              "      <td>[These bars are especially delicious for cocon...</td>\n",
              "      <td>[5.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A06944662TFWOKKV4GJKX</td>\n",
              "      <td>[UGH!  My stomach has been really killing me l...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14676</th>\n",
              "      <td>AZWRZZAMX90VT</td>\n",
              "      <td>[Very nice. Not spicy, not too salty, lots of ...</td>\n",
              "      <td>[5.0, 5.0, 2.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14677</th>\n",
              "      <td>AZXKAH2DE6C8A</td>\n",
              "      <td>[Could not imagine having such a rich tasting ...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14678</th>\n",
              "      <td>AZXON596A1VXC</td>\n",
              "      <td>[I was a bit skeptical when I bought this prod...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14679</th>\n",
              "      <td>AZYXC63SS008M</td>\n",
              "      <td>[This is just about the healthiest you can get...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14680</th>\n",
              "      <td>AZZ5ASC403N74</td>\n",
              "      <td>[Everybody loves homemade spaghetti sauce, but...</td>\n",
              "      <td>[5.0, 2.0, 3.0, 3.0, 4.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14681 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      userID  \\\n",
              "0      A00177463W0XWB16A9O05   \n",
              "1      A022899328A0QROR32DCT   \n",
              "2      A04309042SDSL8YX2HRR7   \n",
              "3      A068255029AHTHDXZURNU   \n",
              "4      A06944662TFWOKKV4GJKX   \n",
              "...                      ...   \n",
              "14676          AZWRZZAMX90VT   \n",
              "14677          AZXKAH2DE6C8A   \n",
              "14678          AZXON596A1VXC   \n",
              "14679          AZYXC63SS008M   \n",
              "14680          AZZ5ASC403N74   \n",
              "\n",
              "                                              reviewText  \\\n",
              "0      [It is a good stand by coffee you can count on...   \n",
              "1      [awesome texture for even the gluten eating ea...   \n",
              "2      [I love roasted garlic & sweet bell peppers. Y...   \n",
              "3      [These bars are especially delicious for cocon...   \n",
              "4      [UGH!  My stomach has been really killing me l...   \n",
              "...                                                  ...   \n",
              "14676  [Very nice. Not spicy, not too salty, lots of ...   \n",
              "14677  [Could not imagine having such a rich tasting ...   \n",
              "14678  [I was a bit skeptical when I bought this prod...   \n",
              "14679  [This is just about the healthiest you can get...   \n",
              "14680  [Everybody loves homemade spaghetti sauce, but...   \n",
              "\n",
              "                                                  rating  \n",
              "0      [5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, ...  \n",
              "1      [5.0, 1.0, 4.0, 5.0, 5.0, 5.0, 1.0, 2.0, 3.0, ...  \n",
              "2                              [5.0, 2.0, 4.0, 4.0, 4.0]  \n",
              "3          [5.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 5.0]  \n",
              "4          [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0]  \n",
              "...                                                  ...  \n",
              "14676  [5.0, 5.0, 2.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, ...  \n",
              "14677  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, ...  \n",
              "14678                [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "14679                     [5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "14680                          [5.0, 2.0, 3.0, 3.0, 4.0]  \n",
              "\n",
              "[14681 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_df=df[['userID','reviewText','rating']].groupby('userID')['rating','reviewText'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['rating'])],index=['reviewText', 'rating'])).reset_index()\n",
        "user_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReAbgOc7q3Tp"
      },
      "source": [
        "**Item Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arvKphT7KCTg"
      },
      "source": [
        "determining all unique items with their reviews and ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "qAjW8mmJq9Cj",
        "outputId": "e03f94a0-8923-417b-c9c0-fd8cd33ea676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mobin/anaconda3/envs/colabenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemID</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>616719923X</td>\n",
              "      <td>[Just another flavor of Kit Kat but the taste ...</td>\n",
              "      <td>[4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9742356831</td>\n",
              "      <td>[This curry paste makes a delicious curry.  I ...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B00004S1C5</td>\n",
              "      <td>[These dyes create awesome colors for kids cra...</td>\n",
              "      <td>[5.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0000531B7</td>\n",
              "      <td>[I really enjoy these bars as a quick breakfas...</td>\n",
              "      <td>[5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00005344V</td>\n",
              "      <td>[Traditional Medicinals' \"Breathe Easy\" is an ...</td>\n",
              "      <td>[5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8708</th>\n",
              "      <td>B00JGPG60I</td>\n",
              "      <td>[We switched to this formula 5 days ago and fo...</td>\n",
              "      <td>[4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 2.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8709</th>\n",
              "      <td>B00JL6LTMW</td>\n",
              "      <td>[We have enjoyed Larabar's variety of bars for...</td>\n",
              "      <td>[4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8710</th>\n",
              "      <td>B00K00H9I6</td>\n",
              "      <td>[This 100% pure Canadian maple syrup is a Grad...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8711</th>\n",
              "      <td>B00KC0LGI8</td>\n",
              "      <td>[I followed the directions on the box exactly ...</td>\n",
              "      <td>[2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8712</th>\n",
              "      <td>B00KCJRVO2</td>\n",
              "      <td>[Usually the label &amp;#34;gluten free&amp;#34; is a ...</td>\n",
              "      <td>[5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8713 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          itemID                                         reviewText  \\\n",
              "0     616719923X  [Just another flavor of Kit Kat but the taste ...   \n",
              "1     9742356831  [This curry paste makes a delicious curry.  I ...   \n",
              "2     B00004S1C5  [These dyes create awesome colors for kids cra...   \n",
              "3     B0000531B7  [I really enjoy these bars as a quick breakfas...   \n",
              "4     B00005344V  [Traditional Medicinals' \"Breathe Easy\" is an ...   \n",
              "...          ...                                                ...   \n",
              "8708  B00JGPG60I  [We switched to this formula 5 days ago and fo...   \n",
              "8709  B00JL6LTMW  [We have enjoyed Larabar's variety of bars for...   \n",
              "8710  B00K00H9I6  [This 100% pure Canadian maple syrup is a Grad...   \n",
              "8711  B00KC0LGI8  [I followed the directions on the box exactly ...   \n",
              "8712  B00KCJRVO2  [Usually the label &#34;gluten free&#34; is a ...   \n",
              "\n",
              "                                                 rating  \n",
              "0     [4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, ...  \n",
              "1     [5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...  \n",
              "2                   [5.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0]  \n",
              "3         [5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0]  \n",
              "4                   [5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 5.0]  \n",
              "...                                                 ...  \n",
              "8708  [4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 2.0, ...  \n",
              "8709  [4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, ...  \n",
              "8710           [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]  \n",
              "8711  [2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, ...  \n",
              "8712  [5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, ...  \n",
              "\n",
              "[8713 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_df=df[['itemID','reviewText','rating']].groupby('itemID')['reviewText','rating'].apply(lambda x: pd.Series([list(x['reviewText']),list(x['rating'])],index=['reviewText', 'rating'])).reset_index()\n",
        "item_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCekVFHgXtom"
      },
      "source": [
        "##   Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "cZb_XiBoGHSa",
        "outputId": "f1cb72ea-8d50-467a-d412-92d75a9d167e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean          4.243042\n",
              "std           1.090003\n",
              "min           1.000000\n",
              "25%           4.000000\n",
              "50%           5.000000\n",
              "75%           5.000000\n",
              "max           5.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.groupby('rating').size().plot(kind=\"bar\");\n",
        "df['rating'].describe()\n",
        "#histogram of ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "hPn4ftb2vqn-",
        "outputId": "91fde917-2de7-4a70-ea94-2e4ae376ea5a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_means=user_df.rating.apply(lambda x: np.mean(x))\n",
        "user_means[:50].plot(kind=\"bar\", grid=False, figsize=(16, 6), title=\"Mean ratings for 50 users\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZuVzD2bTv4iE",
        "outputId": "8533423d-08da-4eeb-c78b-51397de9ecff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2304x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(32,6), sharey=True)\n",
        "user_means.nlargest(50).plot(kind=\"bar\", ax=ax1, title=\"Top 50 users in data set\")\n",
        "user_means.nsmallest(50).plot(kind=\"bar\", ax=ax2, title=\"Bottom 50 users in data set\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FChjMJ0MvtiU",
        "outputId": "81b5374f-986d-4079-8cb6-a99614f56d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ca462e690>]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "user_means = df.groupby(\"userID\").rating.mean().sort_values()\n",
        "_, ax = plt.subplots(figsize=(20, 6))\n",
        "ax.plot(np.arange(len(user_means)), user_means.values, \"k-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "VQfmX7OwGaRN",
        "outputId": "65757a6a-d630-49fc-a97c-0742c3a1b7a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "item_means=item_df.rating.apply(lambda x: np.mean(x))\n",
        "item_means[:50].plot(kind=\"bar\", grid=False, figsize=(16, 6), title=\"Mean ratings for 50 items\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "6Dyp-7KeGyoK",
        "outputId": "6d657471-73d2-4291-aa92-49de438f0a59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2304x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(32,6), sharey=True)\n",
        "item_means.nlargest(50).plot(kind=\"bar\", ax=ax1, title=\"Top 50 items in data set\")\n",
        "item_means.nsmallest(50).plot(kind=\"bar\", ax=ax2, title=\"Bottom 50 items in data set\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGLa04uYQRt"
      },
      "source": [
        "## Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0QEq-vnYohN",
        "outputId": "183d2ce2-65c2-49c9-ca8c-7f216083e4bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     151254\n",
              "unique    151199\n",
              "top             \n",
              "freq          22\n",
              "Name: reviewText, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['reviewText'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "OLw7n7EcbEKV",
        "outputId": "ffd1376f-19a1-42f2-a991-e490d04d84d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    151254.000000\n",
              "mean        509.002142\n",
              "std         524.745639\n",
              "min           0.000000\n",
              "25%         191.000000\n",
              "50%         353.000000\n",
              "75%         644.000000\n",
              "max       29569.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# review length\n",
        "rv_le=df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTgNznNQ8aR1",
        "outputId": "3c1809ac-2fc3-4d67-ce83-7253c8687332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per user: 10.302704175464887\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per user: 5244.098494652953\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in user_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(user_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(user_df['reviewText']))\n",
        "print('mean of reviews per user:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per user:',r_mean * w_mean)\n",
        "# plot for reviews per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58      77\n",
              "65      92\n",
              "117     45\n",
              "125     82\n",
              "143     43\n",
              "        ..\n",
              "8695    87\n",
              "8696    69\n",
              "8701    57\n",
              "8706    47\n",
              "8709    52\n",
              "Name: reviewText, Length: 691, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=item_df['reviewText'].apply(len)\n",
        "a[a>40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "513"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=user_df['reviewText'].apply(len)\n",
        "len(a[a>32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    8713.000000\n",
              "mean       17.359578\n",
              "std        33.915980\n",
              "min         5.000000\n",
              "25%         6.000000\n",
              "50%         8.000000\n",
              "75%        14.000000\n",
              "max       742.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rv_le=item_df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    14681.000000\n",
              "mean        10.302704\n",
              "std         10.581392\n",
              "min          5.000000\n",
              "25%          5.000000\n",
              "50%          7.000000\n",
              "75%         11.000000\n",
              "max        204.000000\n",
              "Name: reviewText, dtype: float64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXcAAAHSCAYAAACnyPghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlmUlEQVR4nO3df7Bmd10f8PeHXQj4oyaUNU2T6EaM2tjWkK4JHdRSKCFBJdhRmoyVSGmj09CRaacloU6h2MygLaTSEWowqcEKIaKUrcRiBNTxD0g2EEN+kGaF0GSNyUoQpNhgwqd/3LP4JN67e7O55z73u/t6zTxzz/mc7znP5+6cOc+97z33e6q7AwAAAADAWJ607AYAAAAAAHj8hLsAAAAAAAMS7gIAAAAADEi4CwAAAAAwIOEuAAAAAMCAhLsAAAAAAAPavuwG5vCMZzyjd+7cuew2AAAAAACesJtuuumPu3vHY+tHZLi7c+fO7NmzZ9ltAAAAAAA8YVX16dXqpmUAAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3jxA7L3nfslsAAAAAADaRcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAc0e7lbVtqr6WFX9+rR+SlV9pKr2VtW7quopU/2YaX3vtH3nwjEunep3VtUL5+4ZAAAAAGCr24w7d38iyR0L6z+d5PLu/uYkn03yiqn+iiSfneqXT+NSVaclOT/Jtyc5J8lbqmrbJvQNAAAAALBlzRruVtVJSb43yS9M65XkeUnePQ25OslLpuXzpvVM258/jT8vyTXd/VB3fyrJ3iRnztk3AAAAAMBWN/edu/85yb9J8uVp/a8m+ZPufnhavzfJidPyiUnuSZJp++em8V+pr7IPAAAAAMBRabZwt6q+L8kD3X3TXO/xmPe7qKr2VNWe/fv3b8ZbAgAAAAAszZx37j4nyYur6u4k12RlOoafTXJsVW2fxpyUZN+0vC/JyUkybf+6JJ9ZrK+yz1d09xXdvau7d+3YsWPjvxsAAAAAgC1ktnC3uy/t7pO6e2dWHoj2we7+4SQfSvKD07ALk7x3Wt49rWfa/sHu7ql+flUdU1WnJDk1yQ1z9Q0AAAAAMILthx6y4V6d5Jqq+g9JPpbkyql+ZZJfqqq9SR7MSiCc7r6tqq5NcnuSh5Nc3N2PbH7bAAAAAABbx6aEu93920l+e1r+ZJIzVxnz/5L80Br7X5bksvk6BAAAAAAYy5xz7gIAAAAAMBPhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxIuAsAAAAAMCDhLgAAAADAgIS7AAAAAAADEu4CAAAAAAxotnC3qp5aVTdU1e9X1W1V9e+n+i9W1aeq6ubpdfpUr6p6c1XtrapbquqMhWNdWFV3Ta8L5+oZAAAAAGAU22c89kNJntfdX6iqJyf5var6jWnbv+7udz9m/LlJTp1eZyV5a5KzqurpSV6bZFeSTnJTVe3u7s/O2DsAAAAAwJY22527veIL0+qTp1cfZJfzkrx92u/DSY6tqhOSvDDJ9d394BToXp/knLn6BgAAAAAYwaxz7lbVtqq6OckDWQloPzJtumyaeuHyqjpmqp2Y5J6F3e+damvVAQAAAACOWrOGu939SHefnuSkJGdW1d9McmmSb0vynUmenuTVG/FeVXVRVe2pqj379+/fiEMCAAAAAGxZs4a7B3T3nyT5UJJzuvu+aeqFh5L8tyRnTsP2JTl5YbeTptpa9ce+xxXdvau7d+3YsWOG7wIAAAAAYOuYLdytqh1Vdey0/LQkL0jyiWke3VRVJXlJklunXXYneVmteHaSz3X3fUnen+Tsqjquqo5LcvZUAwAAAAA4am2f8dgnJLm6qrZlJUS+trt/vao+WFU7klSSm5P8+DT+uiQvSrI3yReTvDxJuvvBqvqpJDdO417f3Q/O2DcAAAAAwJY3W7jb3bckedYq9eetMb6TXLzGtquSXLWhDQIAAAAADGxT5twFAAAAAGBjCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABzRbuVtVTq+qGqvr9qrqtqv79VD+lqj5SVXur6l1V9ZSpfsy0vnfavnPhWJdO9Tur6oVz9QwAAAAAMIo579x9KMnzuvs7kpye5JyqenaSn05yeXd/c5LPJnnFNP4VST471S+fxqWqTktyfpJvT3JOkrdU1bYZ+wYAAAAA2PJmC3d7xRem1SdPr07yvCTvnupXJ3nJtHzetJ5p+/Orqqb6Nd39UHd/KsneJGfO1TcAAAAAwAhmnXO3qrZV1c1JHkhyfZI/SPIn3f3wNOTeJCdOyycmuSdJpu2fS/JXF+ur7AMAAAAAcFSaNdzt7ke6+/QkJ2Xlbttvm+u9quqiqtpTVXv2798/19sAAAAAAGwJs4a7B3T3nyT5UJK/m+TYqto+bTopyb5peV+Sk5Nk2v51ST6zWF9ln8X3uKK7d3X3rh07dszxbQAAAAAAbBmzhbtVtaOqjp2Wn5bkBUnuyErI+4PTsAuTvHda3j2tZ9r+we7uqX5+VR1TVackOTXJDXP1DQAAAAAwgu2HHnLYTkhydVVty0qIfG13/3pV3Z7kmqr6D0k+luTKafyVSX6pqvYmeTDJ+UnS3bdV1bVJbk/ycJKLu/uRGfsGAAAAANjyZgt3u/uWJM9apf7JrMy/+9j6/0vyQ2sc67Ikl210jwAAAAAAo9qUOXcBAAAAANhYwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAYkHAXAAAAAGBAwl0AAAAAgAEJdwEAAAAABiTcBQAAAAAY0GzhblWdXFUfqqrbq+q2qvqJqf66qtpXVTdPrxct7HNpVe2tqjur6oUL9XOm2t6qumSungEAAAAARjHnnbsPJ/lX3X1akmcnubiqTpu2Xd7dp0+v65Jk2nZ+km9Pck6St1TVtqraluTnkpyb5LQkFywch0PYecn7lt0CAAAAADCD7XMduLvvS3LftPynVXVHkhMPsst5Sa7p7oeSfKqq9iY5c9q2t7s/mSRVdc009va5egcAAAAA2Oo2Zc7dqtqZ5FlJPjKVXllVt1TVVVV13FQ7Mck9C7vdO9XWqgMAAAAAHLVmD3er6muS/GqSV3X355O8Nckzk5yelTt737hB73NRVe2pqj379+/fiEMCAAAAAGxZs4a7VfXkrAS7v9zdv5Yk3X1/dz/S3V9O8rb8xdQL+5KcvLD7SVNtrfqjdPcV3b2ru3ft2LFj478ZAAAAAIAtZLZwt6oqyZVJ7ujuNy3UT1gY9gNJbp2Wdyc5v6qOqapTkpya5IYkNyY5tapOqaqnZOWha7vn6hsAAAAAYASzPVAtyXOS/EiSj1fVzVPtNUkuqKrTk3SSu5P8WJJ0921VdW1WHpT2cJKLu/uRJKmqVyZ5f5JtSa7q7ttm7BsAAAAAYMubLdzt7t9LUqtsuu4g+1yW5LJV6tcdbD8AAAAAgKPNuqZlqKq/NXcjAAAAAACs33rn3H1LVd1QVf+8qr5u1o4AAAAAADikdYW73f3dSX44yclJbqqqd1TVC2btDAAAAACANa33zt10911JfjLJq5P8vSRvrqpPVNU/nKs5AAAAAABWt945d/92VV2e5I4kz0vy/d39N6bly2fsDwAAAACAVWxf57j/kuQXkrymu//sQLG7/7CqfnKWzgAAAAAAWNN6w93vTfJn3f1IklTVk5I8tbu/2N2/NFt3AAAAAACsar1z7v5WkqctrH/VVAMAAAAAYAnWG+4+tbu/cGBlWv6qeVoCAAAAAOBQ1hvu/t+qOuPASlX9nSR/dpDxAAAAAADMaL1z7r4qya9U1R8mqSR/Lck/mqspAAAAAAAObl3hbnffWFXfluRbp9Kd3f3n87UFAAAAAMDBrPfO3ST5ziQ7p33OqKp099tn6QoAAAAAgINaV7hbVb+U5JlJbk7yyFTuJMJdAAAAAIAlWO+du7uSnNbdPWczAAAAAACsz5PWOe7WrDxEDQAAAACALWC9d+4+I8ntVXVDkocOFLv7xbN0BQAAAADAQa033H3dnE0AAAAAAPD4rCvc7e7fqapvTHJqd/9WVX1Vkm3ztgYAAAAAwFrWNeduVf2zJO9O8vNT6cQk/2OmngAAAAAAOIT1PlDt4iTPSfL5JOnuu5J8/VxNAQAAAABwcOsNdx/q7i8dWKmq7Ul6npYAAAAAADiU9Ya7v1NVr0nytKp6QZJfSfI/52sLAAAAAICDWW+4e0mS/Uk+nuTHklyX5CfnagoAAAAAgIPbvp5B3f3lJG+bXgAAAAAALNm6wt2q+lRWmWO3u79pwzsCAAAAAOCQ1hXuJtm1sPzUJD+U5Okb3w4AAAAAAOuxrjl3u/szC6993f2fk3zvvK0BAAAAALCW9U7LcMbC6pOycifveu/6BQAAAABgg603oH3jwvLDSe5O8tIN7wYAAAAAgHVZV7jb3X9/7kYAAAAAAFi/9U7L8C8Ptr2737Qx7QAAAAAAsB7rnZZhV5LvTLJ7Wv/+JDckuWuOpgAAAAAAOLj1hrsnJTmju/80SarqdUne193/eK7GAAAAAABY25PWOe74JF9aWP/SVAMAAAAAYAnWe+fu25PcUFXvmdZfkuTqWToCAAAAAOCQ1hXudvdlVfUbSb57Kr28uz82X1sAAAAAABzMeqdlSJKvSvL57v7ZJPdW1Skz9QQAAAAAwCGsK9ytqtcmeXWSS6fSk5P897maAgAAAADg4NZ75+4PJHlxkv+bJN39h0m+dq6mAAAAAAA4uPWGu1/q7k7SSVJVXz1fSwAAAAAAHMp6w91rq+rnkxxbVf8syW8ledvBdqiqk6vqQ1V1e1XdVlU/MdWfXlXXV9Vd09fjpnpV1Zuram9V3VJVZywc68Jp/F1VdeHhfasAAAAAAEeO7YcaUFWV5F1Jvi3J55N8a5J/193XH2LXh5P8q+7+aFV9bZKbqur6JD+a5APd/YaquiTJJVmZz/fcJKdOr7OSvDXJWVX19CSvTbIrK3cO31RVu7v7s4/7uwUAAAAAOEIcMtzt7q6q67r7byU5VKC7uN99Se6blv+0qu5IcmKS85I8dxp2dZLfzkq4e16St0/TP3y4qo6tqhOmsdd394NJMgXE5yR553p7AQAAAAA40qx3WoaPVtV3Hu6bVNXOJM9K8pEkx0/Bb5L8UZLjp+UTk9yzsNu9U22t+mPf46Kq2lNVe/bv33+4rQIAAAAADGG94e5ZWbmb9g+m+XA/XlW3rGfHqvqaJL+a5FXd/fnFbYsPaXuiuvuK7t7V3bt27NixEYcEAAAAANiyDjotQ1V9Q3f/nyQvPJyDV9WTsxLs/nJ3/9pUvr+qTuju+6ZpFx6Y6vuSnLyw+0lTbV/+YhqHA/XfPpx+AAAAAACOFIe6c/d/JEl3fzrJm7r704uvg+04PYjtyiR3dPebFjbtTnLhtHxhkvcu1F9WK56d5HPT9A3vT3J2VR1XVcclOXuqAQAAAAActQ71QLVaWP6mx3ns5yT5kSQfr6qbp9prkrwhybVV9Yokn07y0mnbdUlelGRvki8meXmSdPeDVfVTSW6cxr3+wMPVAAAAAACOVocKd3uN5UPq7t/Lo8PhRc9fZXwnuXiNY12V5KrH8/4AAAAAAEeyQ4W731FVn89KSPu0aTnTenf3X5m1OwAAAAAAVnXQcLe7t21WIwAAAAAArN+hHqgGAAAAAMAWJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNwFAAAAABiQcPcotfOS9y27BQAAAADgCRDuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwIBmC3er6qqqeqCqbl2ova6q9lXVzdPrRQvbLq2qvVV1Z1W9cKF+zlTbW1WXzNUvAAAAAMBI5rxz9xeTnLNK/fLuPn16XZckVXVakvOTfPu0z1uqaltVbUvyc0nOTXJakgumsQAAAAAAR7Xtcx24u3+3qnauc/h5Sa7p7oeSfKqq9iY5c9q2t7s/mSRVdc009vaN7hcAAAAAYCTLmHP3lVV1yzRtw3FT7cQk9yyMuXeqrVUHAAAAADiqbXa4+9Ykz0xyepL7krxxow5cVRdV1Z6q2rN///6NOiwAAAAAwJa0qeFud9/f3Y9095eTvC1/MfXCviQnLww9aaqtVV/t2Fd0967u3rVjx46Nbx4AAAAAYAvZ1HC3qk5YWP2BJLdOy7uTnF9Vx1TVKUlOTXJDkhuTnFpVp1TVU7Ly0LXdm9kzAAAAAMBWNNsD1arqnUmem+QZVXVvktcmeW5VnZ6kk9yd5MeSpLtvq6prs/KgtIeTXNzdj0zHeWWS9yfZluSq7r5trp4BAAAAAEYxW7jb3ResUr7yIOMvS3LZKvXrkly3ga0BAAAAAAxvsx+oBgAAAADABhDuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwIBmC3er6qqqeqCqbl2oPb2qrq+qu6avx031qqo3V9Xeqrqlqs5Y2OfCafxdVXXhXP0CAAAAAIxkzjt3fzHJOY+pXZLkA919apIPTOtJcm6SU6fXRUnemqyEwUlem+SsJGcmee2BQBgAAAAA4Gg2W7jb3b+b5MHHlM9LcvW0fHWSlyzU394rPpzk2Ko6IckLk1zf3Q9292eTXJ+/HBgDAAAAABx1NnvO3eO7+75p+Y+SHD8tn5jknoVx9061teoAAAAAAEe1pT1Qrbs7SW/U8arqoqraU1V79u/fv1GHBQAAAADYkjY73L1/mm4h09cHpvq+JCcvjDtpqq1V/0u6+4ru3tXdu3bs2LHhjQMAAAAAbCWbHe7uTnLhtHxhkvcu1F9WK56d5HPT9A3vT3J2VR03PUjt7KkGAAAAAHBU2z7XgavqnUmem+QZVXVvktcmeUOSa6vqFUk+neSl0/Drkrwoyd4kX0zy8iTp7ger6qeS3DiNe313P/YhbQAAAAAAR53Zwt3uvmCNTc9fZWwnuXiN41yV5KoNbA0AAAAAYHhLe6AaAAAAAACHT7gLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLgLAAAAADAg4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMaCnhblXdXVUfr6qbq2rPVHt6VV1fVXdNX4+b6lVVb66qvVV1S1WdsYyeAQAAAAC2kmXeufv3u/v07t41rV+S5APdfWqSD0zrSXJuklOn10VJ3rrpnQIAAAAAbDFbaVqG85JcPS1fneQlC/W394oPJzm2qk5YQn8AAAAAAFvGssLdTvKbVXVTVV001Y7v7vum5T9Kcvy0fGKSexb2vXeqPUpVXVRVe6pqz/79++fqGwAAAABgS9i+pPf9ru7eV1Vfn+T6qvrE4sbu7qrqx3PA7r4iyRVJsmvXrse1LwAAAADAaJZy525375u+PpDkPUnOTHL/gekWpq8PTMP3JTl5YfeTphoAAAAAwFFr08PdqvrqqvraA8tJzk5ya5LdSS6chl2Y5L3T8u4kL6sVz07yuYXpGwAAAAAAjkrLmJbh+CTvqaoD7/+O7v5fVXVjkmur6hVJPp3kpdP465K8KMneJF9M8vLNbxkAAAAAYGvZ9HC3uz+Z5DtWqX8myfNXqXeSizehNQAAAACAYSxlzl0AAAAAAJ4Y4S4AAAAAwICEuwAAAAAAAxLuAgAAAAAMSLjLptt5yfuW3QIAAAAADE+4CwAAAAAwIOEuAAAAAMCAhLsAAAAAAAMS7gIAAAAADEi4CwAAAAAwIOEuAAAAAMCAhLtsGTsved+yWwAAAACAYQh3AQAAAAAGJNwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3AQAAAAAGJNxly9t5yfuW3QIAAAAAbDnCXQAAAACAAQl3AQAAAAAGJNxlWKZrAAAAAOBoJtwFAAAAABiQcBcAAAAAYEDCXQAAAACAAQl3OeKYixcAAACAo4FwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwl6PGWg9a8wA2AAAAAEYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJd2IJ2XvK+ZbcAAAAAwBYn3AUAAAAAGJBwF5bIHboAAAAAHC7hLvAoawXOgmgAAACArWWYcLeqzqmqO6tqb1Vdsux+YHQbFdY+3jBYSAwAAACwMYYId6tqW5KfS3JuktOSXFBVpy23K2AjbcXQdyv2BAAAAHDAEOFukjOT7O3uT3b3l5Jck+S8JfcEHCEeb4g7913Pyz7WVnMkf28AAADwRIwS7p6Y5J6F9XunGsCWsZFTUWzUsUaaNmNZ39sy/y22YnA997/HVjz3AAAARlXdveweDqmqfjDJOd39T6f1H0lyVne/cmHMRUkumla/Ncmdm97oimck+eMlvTdHB+cYc3OOMTfnGHNzjjEn5xdzc44xN+cYc3OOzeMbu3vHY4vbl9HJYdiX5OSF9ZOm2ld09xVJrtjMplZTVXu6e9ey++DI5Rxjbs4x5uYcY27OMebk/GJuzjHm5hxjbs6xzTXKtAw3Jjm1qk6pqqckOT/J7iX3BAAAAACwNEPcudvdD1fVK5O8P8m2JFd1921LbgsAAAAAYGmGCHeTpLuvS3LdsvtYh6VPDcERzznG3JxjzM05xtycY8zJ+cXcnGPMzTnG3Jxjm2iIB6oBAAAAAPBoo8y5CwAAAADAAuHuBqmqc6rqzqraW1WXLLsfxldVJ1fVh6rq9qq6rap+Yqq/rqr2VdXN0+tFy+6VcVXV3VX18elc2jPVnl5V11fVXdPX45bdJ2Oqqm9duFbdXFWfr6pXuY7xRFTVVVX1QFXdulBb9bpVK948/Xx2S1WdsbzOGcUa59h/rKpPTOfRe6rq2Km+s6r+bOF69l+X1jjDWOMcW/Ozsaouna5jd1bVC5fTNSNZ4xx718L5dXdV3TzVXcd43A6SV/iZbAlMy7ABqmpbkv+d5AVJ7k1yY5ILuvv2pTbG0KrqhCQndPdHq+prk9yU5CVJXprkC939n5bZH0eGqro7ya7u/uOF2s8kebC73zD9Z9Vx3f3qZfXIkWH6rNyX5KwkL4/rGIepqr4nyReSvL27/+ZUW/W6NYUj/yLJi7Jy7v1sd5+1rN4Zwxrn2NlJPjg96Pmnk2Q6x3Ym+fUD42A91jjHXpdVPhur6rQk70xyZpK/nuS3knxLdz+yqU0zlNXOscdsf2OSz3X3613HOBwHySt+NH4m23Tu3N0YZybZ292f7O4vJbkmyXlL7onBdfd93f3RaflPk9yR5MTldsVR4rwkV0/LV2flQxqeqOcn+YPu/vSyG2Fs3f27SR58THmt69Z5WfnFtrv7w0mOnX4ZgTWtdo51929298PT6oeTnLTpjXHEWOM6tpbzklzT3Q9196eS7M3K75+wpoOdY1VVWblh6J2b2hRHlIPkFX4mWwLh7sY4Mck9C+v3RgjHBpr+N/VZST4ylV45/SnDVf5knieok/xmVd1UVRdNteO7+75p+Y+SHL+c1jjCnJ9H/xLhOsZGWuu65Wc05vBPkvzGwvopVfWxqvqdqvruZTXFEWG1z0bXMTbadye5v7vvWqi5jnHYHpNX+JlsCYS7sMVV1dck+dUkr+ruzyd5a5JnJjk9yX1J3ri87jgCfFd3n5Hk3CQXT3/C9RW9MneP+Xt4QqrqKUlenORXppLrGLNx3WJOVfVvkzyc5Jen0n1JvqG7n5XkXyZ5R1X9lWX1x9B8NrJZLsij/8PddYzDtkpe8RV+Jts8wt2NsS/JyQvrJ001eEKq6slZuVD+cnf/WpJ09/3d/Uh3fznJ2+LPsngCunvf9PWBJO/Jyvl0/4E/kZm+PrC8DjlCnJvko919f+I6xizWum75GY0NU1U/muT7kvzw9Atrpj+V/8y0fFOSP0jyLUtrkmEd5LPRdYwNU1Xbk/zDJO86UHMd43CtllfEz2RLIdzdGDcmObWqTpnuTjo/ye4l98TgprmQrkxyR3e/aaG+OC/NDyS59bH7wnpU1VdPk9+nqr46ydlZOZ92J7lwGnZhkvcup0OOII+6Q8R1jBmsdd3aneRl0xOan52Vh8fct9oB4GCq6pwk/ybJi7v7iwv1HdMDI1NV35Tk1CSfXE6XjOwgn427k5xfVcdU1SlZOcdu2Oz+OGL8gySf6O57DxRcxzgca+UV8TPZUmxfdgNHgumpua9M8v4k25Jc1d23LbktxvecJD+S5ONVdfNUe02SC6rq9Kz8ecPdSX5sGc1xRDg+yXtWPpezPck7uvt/VdWNSa6tqlck+XRWHrgAh2X6j4MX5NHXqp9xHeNwVdU7kzw3yTOq6t4kr03yhqx+3bouK09l3pvki0levukNM5w1zrFLkxyT5Prpc/PD3f3jSb4nyeur6s+TfDnJj3f3eh+UxVFqjXPsuat9Nnb3bVV1bZLbszIlyMXd/cgS2mYgq51j3X1l/vIzEBLXMQ7PWnmFn8mWoKa/KAIAAAAAYCCmZQAAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAYk3AUAAAAAGJBwFwAAAABgQMJdAAAAAIABCXcBAAAAAAb0/wHz+JHftTMuvQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rv_le=user_df['reviewText'].apply(lambda x:len(x) )\n",
        "rv_le.plot(kind='hist',bins=2000,figsize=(24, 8),xlabel=\"length of reviews\")\n",
        "rv_le.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nje_ix7gAaf3",
        "outputId": "c3260e88-aa4f-46f3-aa38-85cbb25e0219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean of reviews per item: 17.359577642603007\n",
            "mean of words per review: 509.00214209211\n",
            "mean of words per item: 8836.062205899232\n"
          ]
        }
      ],
      "source": [
        "sum=0\n",
        "sum2=0\n",
        "for x in item_df['reviewText']:\n",
        "  sum+=len(x)\n",
        "  for y in x:\n",
        "   sum2 +=len(y)\n",
        "\n",
        "r_mean=sum/len(item_df['reviewText'])\n",
        "w_mean=sum2/(r_mean*len(item_df['reviewText']))\n",
        "print('mean of reviews per item:', r_mean)\n",
        "print('mean of words per review:', w_mean)\n",
        "print('mean of words per item:',r_mean * w_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMysaUvxxU3"
      },
      "source": [
        "# **Embedding Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WovD0fA5q-J6"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "embedding_dim=300\n",
        "min_frequent_word_num=10\n",
        "max_vocab_size=10000\n",
        "sequence_length=64\n",
        "document_length=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text= tf.strings.reduce_join( tf.strings.split(text)[:,:sequence_length-2],axis=-1,separator=' ')\n",
        "  return  text.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    user_corpus =list(map(tf_lower_and_split_punct,user_df['reviewText'])) \n",
        "    item_corpus = list( map(tf_lower_and_split_punct,item_df['reviewText']) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_word2vec_model():\n",
        "    if os.path.exists(\"word2vec.wordvectors\"):\n",
        "        print(\"loaded from word2vec.wordvectors\")\n",
        "        return KeyedVectors.load(\"word2vec.wordvectors\",mmap='r')\n",
        "    else:\n",
        "        # downloading google news word2vec model\n",
        "        if not os.path.exists(\"word2vec_google.bin\"):\n",
        "            downloaded_model = api.load('word2vec-google-news-300')\n",
        "            downloaded_model.save_word2vec_format('word2vec_google.bin',binary=True)\n",
        "            del downloaded_model\n",
        "        # loading google news word2vec model\n",
        "        google_word2vec = KeyedVectors.load_word2vec_format(\"word2vec_google.bin\", binary=True)\n",
        "\n",
        "       # tokenizing the whole reviews in text_corpus\n",
        "        text_corpus=[]\n",
        "        for i,doc in enumerate(user_corpus):    # iterate through each sentence in the reviews\n",
        "            for rv in doc:\n",
        "                for sen in sent_tokenize(rv.decode(\"utf-8\")):\n",
        "                    temp = []\n",
        "                    # tokenize the sentence into words          \n",
        "                    for j in word_tokenize(sen):\n",
        "                        temp.append(j.lower())\n",
        "                    text_corpus.append(temp)\n",
        "                    del temp\n",
        "\n",
        "\n",
        "        # creating a new word2vec model and initializing it from pretrained google_word2vec\n",
        "        word2vec_model=Word2Vec( text_corpus,max_final_vocab=max_vocab_size,min_count=min_frequent_word_num ,vector_size= embedding_dim,window = 5,workers=16, sg=1,epochs=1)\n",
        "        word2vec_model.build_vocab(text_corpus)\n",
        "\n",
        "        word2vec_model.build_vocab([google_word2vec.index_to_key],update=True)\n",
        "        word2vec_model.wv.vectors_lockf = np.ones(len(word2vec_model.wv))\n",
        "        word2vec_model.wv.intersect_word2vec_format(\"word2vec_google.bin\",binary=True,lockf=1.0)\n",
        "        \n",
        "        # fine tuning the model and saving it\n",
        "        word2vec_model.train(text_corpus, epochs=5, total_examples=word2vec_model.corpus_count)\n",
        "        word2vec_model.wv.save(\"word2vec.wordvectors\")\n",
        "        \n",
        "        del google_word2vec\n",
        "        del text_corpus[:]\n",
        "        gc.collect()\n",
        "  \n",
        "        return word2vec_model.wv\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded from word2vec.wordvectors\n",
            "embedding matrix shape : ( 9739  , 300 )\n"
          ]
        }
      ],
      "source": [
        "# loading the embedding lookup matrix shape=( 10k ,300 ) approximately\n",
        "embedding_matrix = load_word2vec_model() \n",
        "print( \"embedding matrix shape : (\",len(embedding_matrix.index_to_key),\" ,\",embedding_matrix.vector_size,\")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.',\n",
              " 'the',\n",
              " ',',\n",
              " 'i',\n",
              " 'a',\n",
              " 'and',\n",
              " 'to',\n",
              " 'it',\n",
              " 'of',\n",
              " 'is',\n",
              " 'this',\n",
              " 'in',\n",
              " 'for',\n",
              " 'but',\n",
              " 'that',\n",
              " 'my',\n",
              " 'with',\n",
              " 'not',\n",
              " 'are',\n",
              " 'have',\n",
              " 'like',\n",
              " 'you',\n",
              " 'was',\n",
              " '!',\n",
              " 'these',\n",
              " 'as',\n",
              " 'good',\n",
              " 'they',\n",
              " 'taste',\n",
              " 'so',\n",
              " 'on',\n",
              " 'flavor',\n",
              " 'coffee',\n",
              " 'great',\n",
              " 'very',\n",
              " 'its',\n",
              " 'or',\n",
              " 'just',\n",
              " 'them',\n",
              " 'be',\n",
              " 'one',\n",
              " 'love',\n",
              " 'at',\n",
              " 'tea',\n",
              " 'all',\n",
              " 'if',\n",
              " 'has',\n",
              " 'can',\n",
              " 'when',\n",
              " 'really',\n",
              " 'me',\n",
              " 'more',\n",
              " 'product',\n",
              " 'from',\n",
              " 'than',\n",
              " 'we',\n",
              " 'too',\n",
              " 'had',\n",
              " 'some',\n",
              " 'would',\n",
              " 'use',\n",
              " 'much',\n",
              " 'no',\n",
              " 'chocolate',\n",
              " 'other',\n",
              " 'little',\n",
              " 'dont',\n",
              " 'will',\n",
              " 'out',\n",
              " 'get',\n",
              " 'an',\n",
              " 'tried',\n",
              " 'up',\n",
              " 'about',\n",
              " 'make',\n",
              " 'ive',\n",
              " 'sweet',\n",
              " 'there',\n",
              " 'only',\n",
              " 'because',\n",
              " 'im',\n",
              " 'were',\n",
              " 'well',\n",
              " 'what',\n",
              " 'am',\n",
              " 'also',\n",
              " 'sugar',\n",
              " 'better',\n",
              " 'which',\n",
              " 'nice',\n",
              " 'water',\n",
              " 'drink',\n",
              " 'time',\n",
              " 'do',\n",
              " 'been',\n",
              " 'buy',\n",
              " 'price',\n",
              " 'try',\n",
              " 'tastes',\n",
              " 'eat',\n",
              " 'best',\n",
              " 'your',\n",
              " 'first',\n",
              " 'even',\n",
              " 'by',\n",
              " 'used',\n",
              " 'find',\n",
              " 'bit',\n",
              " 'cup',\n",
              " 'delicious',\n",
              " 'any',\n",
              " 'after',\n",
              " 'snack',\n",
              " 'organic',\n",
              " 'made',\n",
              " 'tasty',\n",
              " 'amazon',\n",
              " 'found',\n",
              " 'add',\n",
              " 'bag',\n",
              " 'favorite',\n",
              " 'way',\n",
              " 'think',\n",
              " 'lot',\n",
              " 'most',\n",
              " 'mix',\n",
              " 'many',\n",
              " 'always',\n",
              " 'now',\n",
              " 'easy',\n",
              " 'box',\n",
              " 'free',\n",
              " 'hot',\n",
              " 'again',\n",
              " 'milk',\n",
              " 'bought',\n",
              " 'then',\n",
              " 'fresh',\n",
              " 'flavors',\n",
              " 'brand',\n",
              " 'strong',\n",
              " 'food',\n",
              " 'makes',\n",
              " 'didnt',\n",
              " 'go',\n",
              " '?',\n",
              " 'did',\n",
              " 'their',\n",
              " 'our',\n",
              " 'does',\n",
              " 'since',\n",
              " 'something',\n",
              " 'right',\n",
              " 'healthy',\n",
              " 'over',\n",
              " 'without',\n",
              " 'pretty',\n",
              " 'texture',\n",
              " 'different',\n",
              " 'cookies',\n",
              " 'who',\n",
              " 'want',\n",
              " 'say',\n",
              " 'got',\n",
              " 'sauce',\n",
              " 'could',\n",
              " 'butter',\n",
              " 'oil',\n",
              " 'perfect',\n",
              " 'coconut',\n",
              " 'while',\n",
              " 'into',\n",
              " 'bars',\n",
              " 'enough',\n",
              " 'know',\n",
              " 'still',\n",
              " 'however',\n",
              " 'thought',\n",
              " 'how',\n",
              " 'store',\n",
              " 'stuff',\n",
              " 'two',\n",
              " 'fruit',\n",
              " 'never',\n",
              " 'cant',\n",
              " 'products',\n",
              " 'regular',\n",
              " 'rice',\n",
              " 'whole',\n",
              " 'quite',\n",
              " 'dark',\n",
              " 'salt',\n",
              " 'quality',\n",
              " 'doesnt',\n",
              " 'before',\n",
              " 'need',\n",
              " 'day',\n",
              " 'few',\n",
              " 'enjoy',\n",
              " 'using',\n",
              " 'though',\n",
              " 'years',\n",
              " 'ingredients',\n",
              " 'cereal',\n",
              " 'pack',\n",
              " 'tasting',\n",
              " 'gluten',\n",
              " 'bar',\n",
              " 'give',\n",
              " 'calories',\n",
              " 'those',\n",
              " 'small',\n",
              " 'every',\n",
              " 'hard',\n",
              " 'bad',\n",
              " 'less',\n",
              " 'put',\n",
              " 'eating',\n",
              " 'big',\n",
              " 'pasta',\n",
              " 'keep',\n",
              " 'size',\n",
              " 'tasted',\n",
              " 'green',\n",
              " 'high',\n",
              " 'being',\n",
              " 'sure',\n",
              " 'same',\n",
              " 'package',\n",
              " 'popcorn',\n",
              " 'cheese',\n",
              " 'order',\n",
              " 'added',\n",
              " 'kids',\n",
              " 'natural',\n",
              " 'definitely',\n",
              " 'wonderful',\n",
              " 'recommend',\n",
              " 'honey',\n",
              " 'long',\n",
              " 'real',\n",
              " 'each',\n",
              " 'chips',\n",
              " 'thing',\n",
              " 'both',\n",
              " 'usually',\n",
              " 'family',\n",
              " 'actually',\n",
              " 'soup',\n",
              " 'crackers',\n",
              " 'excellent',\n",
              " 'liked',\n",
              " 'ever',\n",
              " 'vanilla',\n",
              " 'he',\n",
              " 'flavored',\n",
              " 'looking',\n",
              " 'peanut',\n",
              " 'fan',\n",
              " 'work',\n",
              " 'light',\n",
              " 'far',\n",
              " 'blend',\n",
              " 'here',\n",
              " 'almost',\n",
              " 'off',\n",
              " 'new',\n",
              " 'amount',\n",
              " 'brands',\n",
              " 'juice',\n",
              " 'theyre',\n",
              " 'buying',\n",
              " 'bags',\n",
              " 'prefer',\n",
              " 'ordered',\n",
              " 'cinnamon',\n",
              " 'take',\n",
              " 'isnt',\n",
              " 'kind',\n",
              " 'trying',\n",
              " 'candy',\n",
              " 'breakfast',\n",
              " 'thats',\n",
              " 'smooth',\n",
              " 'people',\n",
              " 'bread',\n",
              " 'comes',\n",
              " 'anything',\n",
              " 'things',\n",
              " 'bitter',\n",
              " 'own',\n",
              " 'variety',\n",
              " 'low',\n",
              " 'energy',\n",
              " 'see',\n",
              " 'roast',\n",
              " 'morning',\n",
              " 'having',\n",
              " 'back',\n",
              " 'husband',\n",
              " 'black',\n",
              " 'crunchy',\n",
              " 'she',\n",
              " 'corn',\n",
              " 'going',\n",
              " 'id',\n",
              " 'quick',\n",
              " 'diet',\n",
              " 'chicken',\n",
              " 'rich',\n",
              " 'full',\n",
              " 'probably',\n",
              " 'feel',\n",
              " 'making',\n",
              " 'oatmeal',\n",
              " 'through',\n",
              " 'another',\n",
              " 'several',\n",
              " 'per',\n",
              " 'ginger',\n",
              " 'protein',\n",
              " 'apple',\n",
              " 'especially',\n",
              " 'old',\n",
              " 'down',\n",
              " 'meal',\n",
              " 'beans',\n",
              " 'oz',\n",
              " 'loves',\n",
              " 'snacks',\n",
              " 'purchased',\n",
              " 'flour',\n",
              " 'cookie',\n",
              " 'loved',\n",
              " 'local',\n",
              " 'happy',\n",
              " 'last',\n",
              " 'nothing',\n",
              " 'foods',\n",
              " 'may',\n",
              " 'purchase',\n",
              " 'spicy',\n",
              " 'white',\n",
              " 'cooking',\n",
              " 'come',\n",
              " 'said',\n",
              " 'wasnt',\n",
              " 'enjoyed',\n",
              " 'teas',\n",
              " 'nuts',\n",
              " 'might',\n",
              " 'ones',\n",
              " 'syrup',\n",
              " 'fat',\n",
              " 'should',\n",
              " 'review',\n",
              " 'drinks',\n",
              " 'grocery',\n",
              " 'seems',\n",
              " 'health',\n",
              " 'expensive',\n",
              " 'around',\n",
              " 'fine',\n",
              " 'reviews',\n",
              " 'half',\n",
              " 'bottle',\n",
              " 'came',\n",
              " 'treat',\n",
              " 'powder',\n",
              " 'extra',\n",
              " 'red',\n",
              " 'side',\n",
              " 'cups',\n",
              " 'drinking',\n",
              " 'dry',\n",
              " 'fact',\n",
              " 'keurig',\n",
              " 'cook',\n",
              " 'packaging',\n",
              " 'home',\n",
              " 'ok',\n",
              " 'instead',\n",
              " 'youre',\n",
              " 'cream',\n",
              " 'once',\n",
              " 'although',\n",
              " 'top',\n",
              " 'granola',\n",
              " 'dried',\n",
              " 'fiber',\n",
              " 'house',\n",
              " 'others',\n",
              " 'such',\n",
              " 'save',\n",
              " 'either',\n",
              " 'decided',\n",
              " 'large',\n",
              " 'getting',\n",
              " 'why',\n",
              " 'soft',\n",
              " 'serving',\n",
              " 'aftertaste',\n",
              " 'year',\n",
              " 'caramel',\n",
              " 'wheat',\n",
              " 'salty',\n",
              " 'us',\n",
              " 'smell',\n",
              " 'surprised',\n",
              " 'works',\n",
              " 'highly',\n",
              " 'ounce',\n",
              " 'rather',\n",
              " 'ill',\n",
              " 'yummy',\n",
              " 'times',\n",
              " 'chewy',\n",
              " 'mild',\n",
              " 'three',\n",
              " 'wont',\n",
              " 'artificial',\n",
              " 'sometimes',\n",
              " 'cold',\n",
              " 'coffees',\n",
              " 'plain',\n",
              " 'kcups',\n",
              " 'seeds',\n",
              " 'myself',\n",
              " 'baking',\n",
              " 'worth',\n",
              " 'noodles',\n",
              " 'received',\n",
              " 'bold',\n",
              " 'wanted',\n",
              " 'flavorful',\n",
              " 'maybe',\n",
              " 'often',\n",
              " 'brown',\n",
              " 'filling',\n",
              " 'disappointed',\n",
              " 'where',\n",
              " 'slightly',\n",
              " 'caffeine',\n",
              " 'instant',\n",
              " 'arrived',\n",
              " 'kcup',\n",
              " 'least',\n",
              " 'mixed',\n",
              " 'version',\n",
              " 'wish',\n",
              " 'deal',\n",
              " 'away',\n",
              " 'plus',\n",
              " 'her',\n",
              " 'everything',\n",
              " 'pieces',\n",
              " 'open',\n",
              " 'yet',\n",
              " 'creamy',\n",
              " 'minutes',\n",
              " 'type',\n",
              " 'alternative',\n",
              " 'lunch',\n",
              " 'gave',\n",
              " 'available',\n",
              " 'stars',\n",
              " 'look',\n",
              " 'stores',\n",
              " 'couple',\n",
              " 'item',\n",
              " 'case',\n",
              " 'lemon',\n",
              " 'spice',\n",
              " 'hand',\n",
              " 'problem',\n",
              " 'seem',\n",
              " 'absolutely',\n",
              " 'almond',\n",
              " 'aroma',\n",
              " 'almonds',\n",
              " 'until',\n",
              " 'cocoa',\n",
              " 'etc',\n",
              " 'convenient',\n",
              " 'able',\n",
              " 'theres',\n",
              " 'read',\n",
              " 'boxes',\n",
              " 'subscribe',\n",
              " 'mouth',\n",
              " 'part',\n",
              " 'days',\n",
              " 'similar',\n",
              " 'must',\n",
              " 'tuna',\n",
              " 'expected',\n",
              " 'company',\n",
              " 'ago',\n",
              " 'difference',\n",
              " 'let',\n",
              " 'choice',\n",
              " 'super',\n",
              " 'expect',\n",
              " 'glad',\n",
              " 'between',\n",
              " 'sweetness',\n",
              " 'wife',\n",
              " 'container',\n",
              " 'value',\n",
              " 'soda',\n",
              " 'cheaper',\n",
              " 'bite',\n",
              " 'contains',\n",
              " 'fast',\n",
              " 'recipe',\n",
              " 'adding',\n",
              " 'okay',\n",
              " 'amazing',\n",
              " 'microwave',\n",
              " 'starbucks',\n",
              " 'brew',\n",
              " 'cans',\n",
              " 'decaf',\n",
              " 'huge',\n",
              " 'crunch',\n",
              " 'says',\n",
              " 'everyone',\n",
              " 'recipes',\n",
              " 'stevia',\n",
              " 'beef',\n",
              " 'quickly',\n",
              " 'tell',\n",
              " 'raw',\n",
              " 'couldnt',\n",
              " 'ice',\n",
              " 'plastic',\n",
              " 'son',\n",
              " 'months',\n",
              " 'pepper',\n",
              " 'care',\n",
              " 'else',\n",
              " 'lots',\n",
              " 'french',\n",
              " 'nut',\n",
              " 'likes',\n",
              " 'ground',\n",
              " 'recommended',\n",
              " 'goes',\n",
              " 'heat',\n",
              " 'idea',\n",
              " 'jar',\n",
              " 'compared',\n",
              " 'easily',\n",
              " 'iced',\n",
              " 'salad',\n",
              " 'medium',\n",
              " 'hint',\n",
              " 'exactly',\n",
              " 'havent',\n",
              " 'second',\n",
              " 'orange',\n",
              " 'daughter',\n",
              " 'sodium',\n",
              " 'shipping',\n",
              " 'bland',\n",
              " 'took',\n",
              " 'grain',\n",
              " 'dish',\n",
              " 'packaged',\n",
              " 'special',\n",
              " 'course',\n",
              " 'seasoning',\n",
              " 'started',\n",
              " 'simply',\n",
              " 'soy',\n",
              " 'cut',\n",
              " 'packet',\n",
              " 'money',\n",
              " 'machine',\n",
              " 'itself',\n",
              " 'meat',\n",
              " 'opened',\n",
              " 'went',\n",
              " 'decent',\n",
              " 'arent',\n",
              " 'market',\n",
              " 'garlic',\n",
              " 'yes',\n",
              " 'glutenfree',\n",
              " 'reason',\n",
              " 'g',\n",
              " 'his',\n",
              " 'refreshing',\n",
              " 'healthier',\n",
              " 'help',\n",
              " 'weak',\n",
              " 'original',\n",
              " 'pleasant',\n",
              " 'packets',\n",
              " 'past',\n",
              " 'awesome',\n",
              " 'saw',\n",
              " 'baked',\n",
              " 'cracker',\n",
              " 'wouldnt',\n",
              " 'start',\n",
              " 'ingredient',\n",
              " 'recently',\n",
              " 'bowl',\n",
              " 'canned',\n",
              " 'thin',\n",
              " 'olive',\n",
              " 'smaller',\n",
              " 'wrong',\n",
              " 'overall',\n",
              " 'cost',\n",
              " 'sweetener',\n",
              " 'oats',\n",
              " 'next',\n",
              " 'name',\n",
              " 'anyone',\n",
              " 'glass',\n",
              " 'guess',\n",
              " 'combination',\n",
              " 'jerky',\n",
              " 'along',\n",
              " 'thick',\n",
              " 'normally',\n",
              " 'calorie',\n",
              " 'ordering',\n",
              " 'eaten',\n",
              " 'cooked',\n",
              " 'pleased',\n",
              " 'soups',\n",
              " 'pure',\n",
              " 'chili',\n",
              " 'fantastic',\n",
              " 'simple',\n",
              " 'youll',\n",
              " 'gives',\n",
              " 'single',\n",
              " 'pop',\n",
              " 'lipton',\n",
              " 'consistency',\n",
              " 'packs',\n",
              " 'already',\n",
              " 'potato',\n",
              " 'ate',\n",
              " 'crisp',\n",
              " 'longer',\n",
              " 'together',\n",
              " 'cherry',\n",
              " 'unfortunately',\n",
              " 'dinner',\n",
              " 'roasted',\n",
              " 'list',\n",
              " 'needed',\n",
              " 'satisfying',\n",
              " 'baby',\n",
              " 'grams',\n",
              " 'place',\n",
              " 'daily',\n",
              " 'color',\n",
              " 'items',\n",
              " 'k',\n",
              " 'spices',\n",
              " 'expecting',\n",
              " 'mostly',\n",
              " 'liquid',\n",
              " 'packages',\n",
              " 'mint',\n",
              " 'cheddar',\n",
              " 'strawberry',\n",
              " 'certainly',\n",
              " 'addition',\n",
              " 'gift',\n",
              " 'takes',\n",
              " 'someone',\n",
              " 'benefits',\n",
              " 'friends',\n",
              " 'overly',\n",
              " 'end',\n",
              " 'stick',\n",
              " 'change',\n",
              " 'dishes',\n",
              " 'believe',\n",
              " 'inside',\n",
              " 'seemed',\n",
              " 'smells',\n",
              " 'homemade',\n",
              " 'chip',\n",
              " 'excited',\n",
              " 'four',\n",
              " 'close',\n",
              " 'life',\n",
              " 'bulk',\n",
              " 'mixes',\n",
              " 'left',\n",
              " 'pot',\n",
              " 'line',\n",
              " 'experience',\n",
              " 'night',\n",
              " 'substitute',\n",
              " 'week',\n",
              " 'yogurt',\n",
              " 'somewhat',\n",
              " 'mine',\n",
              " 'run',\n",
              " 'packed',\n",
              " 'stronger',\n",
              " 'graham',\n",
              " 'crispy',\n",
              " 'tomato',\n",
              " 'contain',\n",
              " 'prepare',\n",
              " 'flavoring',\n",
              " 'leaves',\n",
              " 'due',\n",
              " 'opinion',\n",
              " 'during',\n",
              " 'cake',\n",
              " 'needs',\n",
              " 'larger',\n",
              " 'content',\n",
              " 'mind',\n",
              " 'drinker',\n",
              " 'espresso',\n",
              " 'fairly',\n",
              " 'sort',\n",
              " 'based',\n",
              " 'true',\n",
              " 'varieties',\n",
              " 'particular',\n",
              " 'chai',\n",
              " 'live',\n",
              " 'beverage',\n",
              " 'bean',\n",
              " 'meals',\n",
              " 'hit',\n",
              " 'gets',\n",
              " 'adds',\n",
              " 'clean',\n",
              " 'blueberry',\n",
              " 'bobs',\n",
              " 'kick',\n",
              " 'vegetables',\n",
              " 'peach',\n",
              " 'overpowering',\n",
              " 'month',\n",
              " 'licorice',\n",
              " 'star',\n",
              " 'sea',\n",
              " 'favorites',\n",
              " 'gum',\n",
              " 'peanuts',\n",
              " 'nutrition',\n",
              " 'label',\n",
              " 'pumpkin',\n",
              " 'extremely',\n",
              " 'splenda',\n",
              " 'maple',\n",
              " 'pleasantly',\n",
              " 'remember',\n",
              " 'tiny',\n",
              " 'nicely',\n",
              " 'unlike',\n",
              " 'gf',\n",
              " 'perfectly',\n",
              " 'noticed',\n",
              " 'brewed',\n",
              " 'bottles',\n",
              " 'option',\n",
              " 'traditional',\n",
              " 'weight',\n",
              " 'moist',\n",
              " 'mill',\n",
              " 'sauces',\n",
              " 'veggies',\n",
              " 'maker',\n",
              " 'candies',\n",
              " 'weve',\n",
              " 'impressed',\n",
              " 'convenience',\n",
              " 'normal',\n",
              " 'count',\n",
              " 'pancakes',\n",
              " 'means',\n",
              " 'uses',\n",
              " 'mango',\n",
              " 'grains',\n",
              " 'peppermint',\n",
              " 'wow',\n",
              " 'friend',\n",
              " 'gone',\n",
              " 'admit',\n",
              " 'sweetened',\n",
              " 'sale',\n",
              " 'potatoes',\n",
              " 'vegan',\n",
              " 'helps',\n",
              " 'except',\n",
              " 'generally',\n",
              " 'smoothies',\n",
              " 'him',\n",
              " 'personally',\n",
              " 'easier',\n",
              " 'directions',\n",
              " 'warm',\n",
              " 'chocolates',\n",
              " 'given',\n",
              " 'flakes',\n",
              " 'usual',\n",
              " 'tend',\n",
              " 'sour',\n",
              " 'subtle',\n",
              " 'slight',\n",
              " 'person',\n",
              " 'cereals',\n",
              " 'shop',\n",
              " 'cheap',\n",
              " 'leave',\n",
              " 'ready',\n",
              " 'heavy',\n",
              " 'weird',\n",
              " 'banana',\n",
              " 'five',\n",
              " 'body',\n",
              " 'spaghetti',\n",
              " 'supposed',\n",
              " 'reading',\n",
              " 'individual',\n",
              " 'vitamin',\n",
              " 'difficult',\n",
              " 'bits',\n",
              " 'curry',\n",
              " 'pantry',\n",
              " 'entire',\n",
              " 'done',\n",
              " 'types',\n",
              " 'fish',\n",
              " 'nutritional',\n",
              " 'dressing',\n",
              " 'rest',\n",
              " 'stomach',\n",
              " 'become',\n",
              " 'fudge',\n",
              " 'berry',\n",
              " 'truly',\n",
              " 'tart',\n",
              " 'lower',\n",
              " 'looks',\n",
              " 'bake',\n",
              " 'point',\n",
              " 'notice',\n",
              " 'perhaps',\n",
              " 'hazelnut',\n",
              " 'stop',\n",
              " 'looked',\n",
              " 'kid',\n",
              " 'barilla',\n",
              " 'stay',\n",
              " 'bottom',\n",
              " 'vitamins',\n",
              " 'afternoon',\n",
              " 'call',\n",
              " 'fun',\n",
              " 'world',\n",
              " 'today',\n",
              " 'italian',\n",
              " 'yum',\n",
              " 'salads',\n",
              " 'sample',\n",
              " 'handy',\n",
              " 'treats',\n",
              " 'vine',\n",
              " 'stale',\n",
              " 'serve',\n",
              " 'interesting',\n",
              " 'reviewers',\n",
              " 'whatever',\n",
              " 'giving',\n",
              " 'raspberry',\n",
              " 'reasonable',\n",
              " 'raisins',\n",
              " 'date',\n",
              " 'standard',\n",
              " 'eggs',\n",
              " 'sweeteners',\n",
              " 'office',\n",
              " 'carry',\n",
              " 'oh',\n",
              " 'boost',\n",
              " 'continue',\n",
              " 'soon',\n",
              " 'hate',\n",
              " 'unless',\n",
              " 'wrapped',\n",
              " 'stock',\n",
              " 'turned',\n",
              " 'felt',\n",
              " 'batch',\n",
              " 'switch',\n",
              " 'pay',\n",
              " 'called',\n",
              " 'sold',\n",
              " 'cashews',\n",
              " 'anyway',\n",
              " 'completely',\n",
              " 'vegetable',\n",
              " 'kinds',\n",
              " 'kitchen',\n",
              " 'chia',\n",
              " 'apples',\n",
              " 'carbs',\n",
              " 'finally',\n",
              " 'beat',\n",
              " 'note',\n",
              " 'fruity',\n",
              " 'straight',\n",
              " 'brewing',\n",
              " 'nearly',\n",
              " 'piece',\n",
              " 'pound',\n",
              " 'nutty',\n",
              " 'discovered',\n",
              " 'fair',\n",
              " 'formula',\n",
              " 'herbal',\n",
              " 'none',\n",
              " 'summer',\n",
              " 'various',\n",
              " 'opening',\n",
              " 'powdered',\n",
              " 'bitterness',\n",
              " 'children',\n",
              " 'mac',\n",
              " 'thanks',\n",
              " 'purchasing',\n",
              " 'compare',\n",
              " 'pouch',\n",
              " 'fit',\n",
              " 'higher',\n",
              " 'mean',\n",
              " 'basically',\n",
              " 'online',\n",
              " 'pour',\n",
              " 'pick',\n",
              " 'main',\n",
              " 'forward',\n",
              " 'servings',\n",
              " 'portion',\n",
              " 'problems',\n",
              " 'alone',\n",
              " 'berries',\n",
              " 'thank',\n",
              " 'filled',\n",
              " 'mountain',\n",
              " 'christmas',\n",
              " 'hoping',\n",
              " 'pods',\n",
              " 'keeps',\n",
              " 'stir',\n",
              " 'blends',\n",
              " 'avoid',\n",
              " 'processed',\n",
              " 'shape',\n",
              " 'number',\n",
              " 'thinking',\n",
              " 'creamer',\n",
              " 'including',\n",
              " 'craving',\n",
              " 'ounces',\n",
              " 'plenty',\n",
              " 'priced',\n",
              " 'seen',\n",
              " 'particularly',\n",
              " 'teeth',\n",
              " 'short',\n",
              " 'b',\n",
              " 'instructions',\n",
              " 'matter',\n",
              " 'heard',\n",
              " 'shake',\n",
              " 'acid',\n",
              " 'description',\n",
              " 'grind',\n",
              " 'under',\n",
              " 'balance',\n",
              " 'gourmet',\n",
              " 'worked',\n",
              " 'chew',\n",
              " 'program',\n",
              " 'picky',\n",
              " 'tomatoes',\n",
              " 'carbonated',\n",
              " 'appreciate',\n",
              " 'otherwise',\n",
              " 'touch',\n",
              " 'surprise',\n",
              " 'six',\n",
              " ...]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.index_to_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9743, 300)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vocab_size is equal to full_embedding_matrix shape[0]\n",
        "special_token_embedding = np.random.rand(4,embedding_matrix.vector_size)\n",
        "full_embedding_matrix = np.concatenate((special_token_embedding,embedding_matrix.vectors))\n",
        "full_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example\n",
        "# embedding_matrix['keep']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVT3Ur54LsIz"
      },
      "source": [
        "# **Text Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of batches in train data 4254\n",
            "number of batches in test data 472\n"
          ]
        }
      ],
      "source": [
        "# hyperparameter\n",
        "\n",
        "batch_size=32 # for seq2seq model\n",
        "num_batches=int(train_df.shape[0]/batch_size)\n",
        "num_batches_test=int(test_df.shape[0]/batch_size)\n",
        "print(\"number of batches in train data\",num_batches)\n",
        "print(\"number of batches in test data\",num_batches_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct_enc(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct_decin(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join(['[START]', text], separator=' ') \n",
        "  return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct_decout(text):\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.join([ text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4QVJNF8EGGe"
      },
      "source": [
        "- The conversion of tokens to ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_input_processor = tf.keras.layers.TextVectorization( max_tokens = max_vocab_size,\n",
        "                                                     standardize = tf_lower_and_split_punct_enc,\n",
        "                                                     output_sequence_length = sequence_length,  )\n",
        "dec_input_processor = tf.keras.layers.TextVectorization( max_tokens = max_vocab_size,\n",
        "                                                     standardize = tf_lower_and_split_punct_decin,\n",
        "                                                     output_sequence_length = sequence_length,  )\n",
        "\n",
        "dec_output_processor = tf.keras.layers.TextVectorization( max_tokens = max_vocab_size,\n",
        "                                                     standardize = tf_lower_and_split_punct_decout,\n",
        "                                                     output_sequence_length = sequence_length,  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_input_processor.set_vocabulary(['','[UNK]','[START]','[END]'] +  embedding_matrix.index_to_key )\n",
        "dec_input_processor.set_vocabulary(['','[UNK]','[START]','[END]'] +  embedding_matrix.index_to_key )\n",
        "dec_output_processor.set_vocabulary(['','[UNK]','[START]','[END]'] +  embedding_matrix.index_to_key )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3216\n",
            "load\n"
          ]
        }
      ],
      "source": [
        "print(enc_input_processor.get_vocabulary().index('caused'))\n",
        "print(enc_input_processor.get_vocabulary()[3351])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_text_processor vocab size : 9743\n",
            "['', '[UNK]', '[START]', '[END]', '.', 'the', ',', 'i', 'a', 'and', 'to', 'it', 'of', 'is', 'this', 'in']\n",
            "Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....\n",
            "tf.Tensor(\n",
            "[  41  320   35   12 1448 5540   17    5   32   13 1036    9    8  111\n",
            "  162    4    5   82  247   18   13    1   13    5  100    4    7  181\n",
            "   11   26    8  111  364    4    4    4    4    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0], shape=(64,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# included sos, eos, unk and space \n",
        "print(\"input_text_processor vocab size :\" ,len(enc_input_processor.get_vocabulary()))\n",
        "# Here are the first 16 words from the vocabulary:\n",
        "print(enc_input_processor.get_vocabulary()[:16])\n",
        "print(df['reviewText'][0])\n",
        "print(dec_output_processor(  df['reviewText'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **TF-IDF Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-08 11:33:43.452616: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.\n",
            "\n",
            "If you want XLA:CPU, do one of the following:\n",
            "\n",
            " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
            " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
            " - use experimental_jit_scope, or\n",
            " - use tf.function(jit_compile=True).\n",
            "\n",
            "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
            "proper command-line flag, not via TF_XLA_FLAGS).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the length of tf-idf vocab 9737\n",
            "['', '?', '[START]', '.', '!', '[END]', ',']\n",
            "['?', ',', '!', '.']\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "\n",
        "  tfidf_calculator = tf.keras.layers.TextVectorization(\n",
        "    max_tokens  = max_vocab_size,\n",
        "    output_mode ='tf-idf',\n",
        "    pad_to_max_tokens = True  \n",
        "    )\n",
        "  tfidf_calculator.adapt(enc_input_processor.get_vocabulary()[:] )\n",
        "  print(\"the length of tf-idf vocab\",len(tfidf_calculator.get_vocabulary()))\n",
        "  print( list(set(enc_input_processor.get_vocabulary())-set(tfidf_calculator.get_vocabulary()))[:9])\n",
        "  print( list(set(embedding_matrix.index_to_key)-set(tfidf_calculator.get_vocabulary()))[:9])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with tf.device('/CPU:0'):\n",
        "\n",
        "#     user_tfidf = list( map(tfidf_calculator, user_corpus))\n",
        "#     item_tfidf = list( map(tfidf_calculator, item_corpus))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Forming Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert string id to int id\n",
        "user_to_row = {}\n",
        "item_to_column = {}\n",
        "\n",
        "for i, user_id in enumerate(np.unique(df['userID'])):\n",
        "    user_to_row[user_id] = i\n",
        "\n",
        "for j, item_id in enumerate(np.unique(df['itemID'].tolist())):\n",
        "    item_to_column[item_id] = j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds_seq = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       [user_to_row[dp] for dp in train_df['userID']],\n",
        "       [item_to_column[dp] for dp in train_df['itemID']],\n",
        "       tf.cast(dec_input_processor(train_df['reviewText']),dtype=tf.int32),\n",
        "       tf.cast(dec_output_processor(train_df['reviewText']),dtype=tf.int32)       \n",
        "    )\n",
        ").shuffle(32768).batch(batch_size,drop_remainder=True)\n",
        "test_ds_seq = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "      [user_to_row[dp] for dp in test_df['userID']],\n",
        "      [item_to_column[dp] for dp in test_df['itemID']],\n",
        "      tf.cast(dec_input_processor(test_df['reviewText']),dtype=tf.int32),\n",
        "      tf.cast(dec_output_processor(test_df['reviewText']),dtype=tf.int32)         \n",
        "    )\n",
        ").shuffle(16384).batch(batch_size,drop_remainder=True)\n",
        "\n",
        "train_ds_pmf = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "       [user_to_row[dp] for dp in train_df['userID']],\n",
        "       [item_to_column[dp] for dp in train_df['itemID']],\n",
        "       tf.cast(train_df['rating'],dtype=tf.int8)\n",
        "    )\n",
        ").shuffle(32768).batch(1024,drop_remainder=True)\n",
        "test_ds_pmf = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "      [user_to_row[dp] for dp in test_df['userID']],\n",
        "      [item_to_column[dp] for dp in test_df['itemID']],\n",
        "      tf.cast(test_df['rating'],dtype=tf.int8)\n",
        "    )\n",
        ").shuffle(16384).batch(1024,drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train and test data number :  136129  ,  15125\n"
          ]
        }
      ],
      "source": [
        "train_data_num=train_df.shape[0]\n",
        "test_data_num=test_df.shape[0]\n",
        "print(\"train and test data number : \",train_data_num,\" , \",test_data_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([12034, 12955, 11842,  9708, 10459,  5295,  5122, 13475, 12212,\n",
            "        6818,  3471,  4479,  9423, 13458,  3059,  2559, 13715,  5687,\n",
            "        5095, 11143,  6215,  7772,  2798,  4996,  5407,  7660,  6660,\n",
            "        1031,  5072, 13565, 14305,  8013], dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([ 486, 1535,  587, 1819, 1090, 1317, 2106, 2296, 1112,  386,  691,\n",
            "         88,  222,  471, 1936, 2234,  919, 1239,  137,  612, 1000, 1504,\n",
            "        479,   36, 2008, 1867,   88,  749,  593, 1708, 1052,  757],\n",
            "      dtype=int32)>, <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\n",
            "array([[   2,    7,  611, ...,   74,  373, 1143],\n",
            "       [   2,   79,   98, ...,   45,    5,  627],\n",
            "       [   2,  129,   20, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,   14, 1389, ...,    4,    0,    0],\n",
            "       [   2,    5,  628, ...,    0,    0,    0],\n",
            "       [   2,   29,  697, ...,   15,  170,    4]], dtype=int32)>, <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\n",
            "array([[   7,  611,  121, ...,  373, 1143,   12],\n",
            "       [  79,   98,    8, ...,    5,  627,   12],\n",
            "       [ 129,   20, 8229, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  14, 1389,  259, ...,    3,    0,    0],\n",
            "       [   5,  628,   13, ...,    0,    0,    0],\n",
            "       [  29,  697,   10, ...,  170,    4,  747]], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "for i in train_ds_seq.take(1):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4PGxjttli6"
      },
      "source": [
        "# **User and Item Documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BwcnBKDxVMk"
      },
      "source": [
        "**User Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_doc = list( map(enc_input_processor,[doc[:document_length] for doc in user_df['reviewText']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWDCul-D_N99"
      },
      "source": [
        "**Item Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "phoN10nsXZGc"
      },
      "outputs": [],
      "source": [
        "item_doc = list( map(enc_input_processor,[doc[:document_length] for doc in item_df['reviewText']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1G79SrZySBqJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(item_doc[0])\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(item_doc[0] != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbR2h5ML5h70"
      },
      "source": [
        "### Converting ID to Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'It is a good stand by coffee you can count on.  I would reley on it for the daily use catagory.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_df['reviewText'][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[START] it is a good stand by coffee you can count on . i would [UNK] on it for the daily use [UNK] . [END]                                       '"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_vocab = enc_input_processor.get_vocabulary()\n",
        "\" \".join([input_vocab[id] for id in user_doc[0][0]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Context-aware Matrix Factorization for Rating Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "num_users=len(user_to_row)\n",
        "num_items=len(item_to_column)\n",
        "mean_inv = np.float32( train_df['rating'].mean())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_num=128 # number of topics\n",
        "units=int(feature_num/2 )# gru units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# del df\n",
        "# del user_df\n",
        "# del item_df\n",
        "# del user_corpus[:]\n",
        "# del item_corpus[:]\n",
        "# del train_df\n",
        "# del test_df\n",
        "\n",
        "# gc.collect()\n",
        "# gc.collect(0)\n",
        "# gc.collect(1)\n",
        "# gc.collect(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_textual_features = np.zeros(shape=(num_users, feature_num),dtype=np.float32)\n",
        "item_textual_features = np.zeros(shape=(num_items, feature_num),dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_recommender_features = np.zeros(shape=(num_users, feature_num),dtype=np.float64)\n",
        "item_recommender_features = np.zeros(shape=(num_items, feature_num),dtype=np.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uKWBtzhmMA5"
      },
      "source": [
        "## **PMF (Probabilistic Matrix Factorization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "5JAoyyjOnJis"
      },
      "outputs": [],
      "source": [
        "class PMF():\n",
        "    def __init__(self, num_feat=16, epsilon=1, _lambda=10, momentum=0.8,  batch_size=1024,num_item=9000,num_user=15000,mean_inv=3):\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.num_item=num_item\n",
        "        self.num_user=num_user\n",
        "        self.V =  0.1 * np.random.randn(self.num_item, self.num_feat).astype(np.float64)  # Item feature vectors\n",
        "        self.U =  0.1 * np.random.randn(self.num_user, self.num_feat).astype(np.float64)  # User feature vectors\n",
        "        self.V_inc = np.zeros((self.num_item, self.num_feat),dtype=np.float64)\n",
        "        self.U_inc = np.zeros((self.num_user, self.num_feat),dtype=np.float64)\n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.mean_inv= mean_inv  \n",
        "        \n",
        "    # ***Fit the model with train_tuple and evaluate RMSE on both train and test data.  ***********#\n",
        "    # ***************** train_vec=TrainData, test_vec=TestData*************#\n",
        "    def train(self):\n",
        "            \n",
        "            for batch_UserID,batch_ItemID, batch_rating  in train_ds_pmf:\n",
        "                  \n",
        "                # Compute Objective Function             \n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                              self.V[batch_ItemID, :]),\n",
        "                                  axis=1)  # mean_inv subtracted # np.multiply\n",
        "                \n",
        "                rawErr = pred_out - batch_rating.numpy() + self.mean_inv\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.V[batch_ItemID, :]) \\\n",
        "                       + self._lambda * (self.U[batch_UserID, :] )\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.U[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.V[batch_ItemID, :] ) \n",
        "                       # np.newaxis :increase the dimension\n",
        "               \n",
        "                dw_Item = np.zeros((self.num_item, self.num_feat))\n",
        "                dw_User = np.zeros((self.num_user, self.num_feat))\n",
        "                \n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "              \n",
        "                self.V_inc = self.momentum * self.V_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.U_inc = self.momentum * self.U_inc + self.epsilon * dw_User / self.batch_size\n",
        "                \n",
        "                self.V = self.V - self.V_inc\n",
        "                self.U = self.U - self.U_inc\n",
        "            \n",
        "                # Compute Objective Function after\n",
        "            self.evaluate()\n",
        "            self.update_recommender_features()\n",
        "    def evaluate(self):\n",
        "            rawErr=np.zeros((self.batch_size),dtype=np.float64).tolist()\n",
        "            for batch_UserID,batch_ItemID, batch_rating  in train_ds_pmf:\n",
        "                        \n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                        self.V[batch_ItemID, :]),\n",
        "                                axis=1)  # mean_inv subtracted\n",
        "\n",
        "                rawErr += pred_out - batch_rating.numpy() + self.mean_inv\n",
        "        \n",
        "            obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                    + 0.5 * self._lambda * (np.linalg.norm(self.U - user_textual_features) ** 2 + np.linalg.norm(self.V - item_textual_features) ** 2)\n",
        "\n",
        "            self.rmse_train.append(np.sqrt(obj / train_data_num))\n",
        "\n",
        "           # Compute test error\n",
        "            rawErr=np.zeros((self.batch_size),dtype=np.float64).tolist()\n",
        "            for batch_UserID,batch_ItemID, batch_rating  in test_ds_pmf:\n",
        "                pred_out = np.sum(np.multiply(self.U[batch_UserID, :],\n",
        "                                        self.V[batch_ItemID, :]),\n",
        "                                axis=1)  # mean_inv subtracted\n",
        "\n",
        "                rawErr += pred_out - batch_rating.numpy() + self.mean_inv\n",
        "\n",
        "            self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(test_data_num))\n",
        "\n",
        "            # Print info\n",
        "            print('\\nTraining RMSE: %f, Test RMSE %f' % (self.rmse_train[-1], self.rmse_test[-1]))\n",
        "\n",
        "\n",
        "    def update_recommender_features(self,):\n",
        "        user_recommender_features = self.U\n",
        "        item_recommender_features = self.V\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0y4xKXSRYU-"
      },
      "source": [
        "# **Adversarial Seq2Seq Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log files for training and test\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "graph_log_dir = 'logs/graph/' + current_time \n",
        "graph_summary_writer = tf.summary.create_file_writer(graph_log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PerplexityMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='perplexity',**kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.perplexity=self.add_weight(name='pl',initializer='zeros')\n",
        "\n",
        "    def update_state(self, nll_loss):\n",
        "        self.perplexity= 2 ** nll_loss\n",
        "\n",
        "    def result(self):\n",
        "        return self.perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_plx_gen_tch = PerplexityMetric(name='generator perplexity')  # teacher forcing mode\n",
        "train_plx_gen_plc = PerplexityMetric(name='generator perplexity')  # policy gradient mode\n",
        "train_acc_dis = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
        "\n",
        "test_plx_gen = PerplexityMetric(name='generator perplexity')  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Recurrent Review Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- it consists of two encoders and one decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UVYfYjX9YW"
      },
      "source": [
        "### **Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "TwRd0VNHkMf0"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,vocab_size, embedding_dim, enc_units):\n",
        "    super().__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding( self.vocab_size, self.embedding_dim, embeddings_initializer=keras.initializers.Constant(full_embedding_matrix),trainable=False)\n",
        "    self.gru= tf.keras.layers.Bidirectional(tf.keras.layers.GRU(  self.enc_units,return_state=True,  recurrent_initializer='glorot_uniform' ))\n",
        "\n",
        "\n",
        "  def call(self, reviews, state=None):\n",
        "    vectors = self.embedding(reviews)\n",
        "    _,encoder_forward_state,encoder_backward_state  = self.gru(vectors, initial_state=state)\n",
        " \n",
        "    return  tf.concat([ encoder_forward_state, encoder_backward_state],-1)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Decoder (Generator)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "skIgKP4iCABs"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,vocab_size, embedding_dim, dec_units):\n",
        "    super().__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim,embeddings_initializer=keras.initializers.Constant(full_embedding_matrix), trainable=False)\n",
        "    self.gru=tf.keras.layers.GRU( self.dec_units , return_state=True,return_sequences=True)\n",
        "    self.fc = tf.keras.layers.Dense(self.vocab_size, use_bias=False)\n",
        "    self.sf=tf.keras.layers.Activation('softmax')\n",
        "\n",
        "  def call(self, decoder_input, context_vector,state=None):\n",
        "\n",
        "     embedded_input = self.embedding(decoder_input)\n",
        "     joint_input_context = tf.concat([embedded_input, tf.tile(tf.expand_dims(context_vector,1),[1,embedded_input.shape[1],1])],2 )\n",
        "     outputs,dec_state = self.gru(joint_input_context, initial_state=state)\n",
        "     logits = self.fc( outputs)\n",
        "     prob_dist = self.sf(logits)\n",
        "\n",
        "     return prob_dist,dec_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "DyhJk5pGKW_N"
      },
      "outputs": [],
      "source": [
        "class GeneratorLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self,vocab_size):\n",
        "    self.name = 'masked_loss'\n",
        "    self.vocab_size=vocab_size\n",
        "    self.scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # Calculating the loss for a batch of reviews.\n",
        "\n",
        "    loss = self.scce(y_true,y_pred)\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss*=  mask\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v_zte_RHR5a"
      },
      "source": [
        "## **Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "84ZgGwB9HXi5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__( self, sequence_length, vocab_size, embedding_dim, filter_sizes, num_filters):\n",
        "      super().__init__()\n",
        "      self.sequence_length=sequence_length\n",
        "      self.vocab_size=vocab_size\n",
        "      self.embedding_dim=embedding_dim\n",
        "      self.filter_sizes=filter_sizes\n",
        "      self.num_filters= num_filters\n",
        "      self.dis_dropout_keep_prob = 0.75\n",
        "\n",
        "      self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim,weights=[full_embedding_matrix],name=\"discriminator_embedding\",trainable=False)\n",
        "     \n",
        "      self.conv_unigram= tf.keras.layers.Conv1D(self.num_filters, filter_sizes[0], activation=\"tanh\",name=\"conv_unigram\")\n",
        "      self.conv_bigram= tf.keras.layers.Conv1D(self.num_filters, filter_sizes[1],activation=\"tanh\",name=\"conv_bigram\")\n",
        "      self.conv_trigram= tf.keras.layers.Conv1D(self.num_filters, filter_sizes[2],activation=\"tanh\",name=\"conv_trigram\")\n",
        "      self.conv_fourgram= tf.keras.layers.Conv1D(self.num_filters, filter_sizes[3],activation=\"tanh\",name=\"conv_fourgram\")\n",
        "      self.conv_fivegram= tf.keras.layers.Conv1D(self.num_filters, filter_sizes[4],activation=\"tanh\",name=\"conv_fivegram\")\n",
        "\n",
        "      self.gmp_unigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_unigram\")\n",
        "      self.gmp_bigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_bigram\")\n",
        "      self.gmp_trigram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_trigram\")\n",
        "      self.gmp_fourgram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_fourgram\")\n",
        "      self.gmp_fivegram = tf.keras.layers.GlobalMaxPooling1D(name=\"gmp_fivegram\")\n",
        "\n",
        "      self.dropout=tf.keras.layers.Dropout(self.dis_dropout_keep_prob,name=\"dropout\")\n",
        "      self.fc=tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "\n",
        "    def get_reward(self, discriminator_inputs , context_vector,training=False ):\n",
        "      \n",
        "      embedded_input= self.embedding(discriminator_inputs)\n",
        "      joint_input_context =tf.concat([embedded_input, tf.tile(tf.expand_dims(context_vector,1),[1,embedded_input.shape[1],1])],2 )\n",
        "\n",
        "      cv_unigram=self.conv_unigram(joint_input_context)\n",
        "      cv_bigram=self.conv_bigram(joint_input_context)\n",
        "      cv_trigram=self.conv_trigram(joint_input_context)\n",
        "      cv_fourgram=self.conv_fourgram(joint_input_context)\n",
        "      cv_fivegram=self.conv_fivegram(joint_input_context)\n",
        "\n",
        "      gmp_unigram = self.gmp_unigram(cv_unigram)\n",
        "      gmp_bigram = self.gmp_bigram(cv_bigram)\n",
        "      gmp_trigram =  self.gmp_trigram(cv_trigram)\n",
        "      gmp_fourgram = self.gmp_fourgram(cv_fourgram)\n",
        "      gmp_fivegram = self.gmp_fivegram(cv_fivegram)\n",
        "    \n",
        "      gmp_overal = tf.concat([gmp_unigram,gmp_bigram,gmp_trigram,gmp_fourgram,gmp_fivegram],1)\n",
        "      \n",
        "      if training:\n",
        "        dropout = self.dropout(gmp_overal,training=training)\n",
        "        ath= self.fc(dropout)\n",
        "        gc.collect()\n",
        "        return ath[:,0],self.fc.weights[0][:,0],self.fc.bias\n",
        "      else:\n",
        "        ath= self.fc(gmp_overal)\n",
        "        gc.collect()\n",
        "        return ath[:,0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "FCRHY3LgfD2_"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'cross-entropy_loss'\n",
        "    self.bce = tf.keras.losses.BinaryCrossentropy( reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "\n",
        "    loss = self.bce(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Seq2Seq Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "MB7HymOiTfdl"
      },
      "outputs": [],
      "source": [
        "class MaskedLossReward(tf.keras.losses.Loss):\n",
        "  def __init__(self,vocab_size):\n",
        "    self.name = 'masked_loss_reward'\n",
        "    self.vocab_size=vocab_size\n",
        "    self.scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred,reward):\n",
        "    # Calculate the loss for each step.\n",
        "\n",
        "    loss = self.scce(y_true,y_pred)\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss*=  mask\n",
        "    loss *= reward\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "Z3NlswFZRbub"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(tf.keras.Model): \n",
        "    def __init__(self,num_topic,num_item ,num_user, units ,embedding_dim,vocab_size ,sequence_length, num_batches,num_batches_test, batch_size, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.use_tf_function = use_tf_function\n",
        "        self.num_batches_test = num_batches_test\n",
        "        self.num_batches = num_batches # train batch number\n",
        "        self.batch_size = batch_size\n",
        "        self.num_topic = num_topic\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.units = units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_item = num_item\n",
        "        self.num_user = num_user\n",
        "        self.alpha = 10\n",
        "        self.disc_l2_reg_lambda = 0.4\n",
        "        self.user_encoder = Encoder(vocab_size= self.vocab_size,  embedding_dim= self.embedding_dim, enc_units= self.units)\n",
        "        self.item_encoder = Encoder(vocab_size= self.vocab_size,  embedding_dim= self.embedding_dim, enc_units= self.units)\n",
        "        self.decoder = Decoder(vocab_size= self.vocab_size,  embedding_dim= self.embedding_dim, dec_units= 4 * self.units) #generator\n",
        "        self.discriminator = Discriminator(sequence_length= self.sequence_length, vocab_size= self.vocab_size,embedding_dim= self.embedding_dim, filter_sizes= [1, 2, 3 ,4, 5] ,num_filters=128)\n",
        "      \n",
        "        self.loss_gn = GeneratorLoss(vocab_size=self.vocab_size)\n",
        "        self.loss_ds = DiscriminatorLoss()\n",
        "        self.loss_fn = MaskedLossReward(vocab_size=self.vocab_size) # generator loss with reward\n",
        "\n",
        "        self.optimizer_gn = tf.optimizers.Adam(0.01)\n",
        "        self.optimizer_ds = tf.optimizers.Adam(1e-3)\n",
        "\n",
        "    def generate_textual_features(self):\n",
        "            \n",
        "          for start_index in range(0, self.num_user, self.batch_size):\n",
        "            end_index = min(start_index + self.batch_size, self.num_user)                           \n",
        "            batch_userID = np.arange(start_index, end_index)\n",
        "\n",
        "            # fetch a batch of user doc\n",
        "            batch_userdoc_flattend=[]\n",
        "            userdoc_slice_idx=[0]\n",
        "            for doc_id in batch_userID:\n",
        "              userdoc_slice_idx.append(userdoc_slice_idx[-1] + user_doc[doc_id].shape[0])\n",
        "              batch_userdoc_flattend = np.append(batch_userdoc_flattend,user_doc[doc_id])\n",
        "            batch_userdoc = tf.reshape(tf.convert_to_tensor( batch_userdoc_flattend,dtype=tf.int32),[userdoc_slice_idx[-1],self.sequence_length])\n",
        "\n",
        "            user_enc_state = self.user_encoder(batch_userdoc) # user vector representations      \n",
        "            user_context_vector = tf.stack([ tf.reduce_mean(user_enc_state[ userdoc_slice_idx[sl_num] : userdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(len(batch_userID))])\n",
        "            \n",
        "            user_textual_features[batch_userID]=user_context_vector.numpy()\n",
        "            \n",
        "          for start_index in range(0, self.num_item, self.batch_size):\n",
        "            end_index = min(start_index + self.batch_size, self.num_item)                           \n",
        "            batch_itemID = np.arange(start_index, end_index)\n",
        "\n",
        "            # fetch a batch of item doc\n",
        "            batch_itemdoc_flattend=[]\n",
        "            itemdoc_slice_idx=[0]\n",
        "            for doc_id in batch_itemID:\n",
        "              itemdoc_slice_idx.append(itemdoc_slice_idx[-1] + item_doc[doc_id].shape[0])\n",
        "              batch_itemdoc_flattend = np.append(batch_itemdoc_flattend,item_doc[doc_id])\n",
        "            batch_itemdoc = tf.reshape(tf.convert_to_tensor( batch_itemdoc_flattend,dtype=tf.int32),[itemdoc_slice_idx[-1],self.sequence_length])\n",
        "            \n",
        "            item_enc_state = self.item_encoder(batch_itemdoc) # item vector representations\n",
        "            item_context_vector = tf.stack([ tf.reduce_mean(item_enc_state[ itemdoc_slice_idx[sl_num] : itemdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(len(batch_itemID))])\n",
        "            \n",
        "            item_textual_features[batch_itemID]=item_context_vector.numpy()\n",
        "    \n",
        "    def teacher_forcing_train(self,num_steps=1):\n",
        "          total_gen_loss=0\n",
        "          for t_step in range(num_steps):\n",
        " \n",
        "            (batch_userID,batch_itemID ,batch_review_in,batch_review_out) = next(iter(train_ds_seq))\n",
        "            # fetch a batch of user doc\n",
        "            batch_userdoc_flattend=[]\n",
        "            userdoc_slice_idx=[0]\n",
        "            for doc_id in batch_userID:\n",
        "              userdoc_slice_idx.append(userdoc_slice_idx[-1] + user_doc[doc_id].shape[0])\n",
        "              batch_userdoc_flattend = np.append(batch_userdoc_flattend,user_doc[doc_id])\n",
        "            batch_userdoc = tf.reshape(tf.convert_to_tensor( batch_userdoc_flattend,dtype=tf.int32),[userdoc_slice_idx[-1],self.sequence_length])\n",
        "\n",
        "            # fetch a batch of item doc\n",
        "            batch_itemdoc_flattend=[]\n",
        "            itemdoc_slice_idx=[0]\n",
        "            for doc_id in batch_itemID:\n",
        "              itemdoc_slice_idx.append(itemdoc_slice_idx[-1] + item_doc[doc_id].shape[0])\n",
        "              batch_itemdoc_flattend = np.append(batch_itemdoc_flattend,item_doc[doc_id])\n",
        "            batch_itemdoc = tf.reshape(tf.convert_to_tensor( batch_itemdoc_flattend,dtype=tf.int32),[itemdoc_slice_idx[-1],self.sequence_length])\n",
        "            \n",
        "            with tf.GradientTape() as tape1 , tf.GradientTape() as tape2:\n",
        "              tape1.watch(self.user_encoder.trainable_variables + self.item_encoder.trainable_variables)\n",
        "              tape2.watch(self.decoder.trainable_variables)\n",
        "              \n",
        "              user_enc_state = self.user_encoder(batch_userdoc) # user vector representations      \n",
        "              item_enc_state = self.item_encoder(batch_itemdoc) # item vector representations\n",
        "                \n",
        "              user_context_vector = tf.stack([ tf.reduce_mean(user_enc_state[ userdoc_slice_idx[sl_num] : userdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(self.batch_size)])\n",
        "              item_context_vector = tf.stack([ tf.reduce_mean(item_enc_state[ itemdoc_slice_idx[sl_num] : itemdoc_slice_idx[sl_num+1] ],0) for  sl_num in range(self.batch_size)])\n",
        "              context_vector = tf.concat( [user_context_vector,item_context_vector],1)\n",
        "                           \n",
        "              # regularization \n",
        "              print(user_enc_state)\n",
        "              user_regularization_loss= (np.linalg.norm( user_recommender_features[batch_userID] - user_context_vector.numpy()) ** 2) /  user_context_vector.shape[0] \n",
        "              item_regularization_loss= (np.linalg.norm( user_recommender_features[batch_itemID] - item_context_vector.numpy()) ** 2) /  item_context_vector.shape[0] \n",
        "            \n",
        "              regularization_loss = tf.constant( self.alpha * (user_regularization_loss + item_regularization_loss) )\n",
        "              dec_pred, _ = self.decoder( batch_review_in , context_vector)             \n",
        "              gen_loss = self.loss_gn(batch_review_out , dec_pred)\n",
        "           \n",
        "            grad_enc = tape1.gradient([gen_loss,regularization_loss],self.user_encoder.trainable_variables + self.item_encoder.trainable_variables )\n",
        "            grad_dec = tape2.gradient(gen_loss,self.decoder.trainable_variables )\n",
        "\n",
        "            self.optimizer_gn.apply_gradients(zip(grad_enc+grad_dec, self.user_encoder.trainable_variables + self.item_encoder.trainable_variables+self.decoder.trainable_variables ))                 \n",
        "            \n",
        "            total_gen_loss += gen_loss\n",
        "            # total_regularization_loss += regularization_loss\n",
        "            if t_step % 10 == 0:\n",
        "              print(\"batch number: \",t_step,\"\\tgen loss: \", gen_loss.numpy())\n",
        "    \n",
        "          train_plx_gen_tch.update_state(total_gen_loss / num_steps)\n",
        "\n",
        "    def test(self,num_steps):\n",
        "        total_loss=0\n",
        "        for step in range(num_steps):\n",
        "            (batch_userID,batch_itemID ,_,_) = next(iter(test_ds_seq))\n",
        "            context_vector = tf.concat([user_textual_features[batch_userID],item_textual_features[batch_itemID]],1)                    \n",
        "            predicted_samples,dec_prob = self.generate_sample(context_vector=context_vector)\n",
        "            loss = self.loss_gn(predicted_samples ,tf.transpose( tf.stack(dec_prob), [1,0,2])  )\n",
        "            total_loss += loss\n",
        "            if step % 5 == 0:\n",
        "              print(\"batch number: \",step, \"\\tgen loss: \",loss.numpy())\n",
        "\n",
        "        test_plx_gen.update_state(total_loss / num_steps)\n",
        "  \n",
        "\n",
        "    \n",
        "    def adversarial_train(self,num_steps=1):\n",
        "        total_gen_loss=0\n",
        "        for step in range(num_steps):\n",
        "          # train generator for one step\n",
        "          generated_samples,batch_userID,batch_itemID, gen_loss =  self._train_step_gn_policy() #adversarial samples\n",
        "          total_gen_loss += gen_loss\n",
        "          # train discriminator for one step\n",
        "          disc_loss = self._train_step_disc(generated_samples,batch_userID,batch_itemID)\n",
        "          if step % 5 == 0:\n",
        "            print(\"batch number: \",step, \"\\t\\tgen loss: \",gen_loss.numpy(),\"\\t\\t\\tdisc loss: \",disc_loss.numpy())   \n",
        "        train_plx_gen_plc.update_state(total_gen_loss / num_steps)\n",
        "\n",
        "\n",
        "    def _train_step_gn_policy(self):\n",
        "            batch_userID = np.random.choice(range(0,self.num_user),self.batch_size).astype('int32')\n",
        "            batch_itemID = np.random.choice(range(0,self.num_item),self.batch_size).astype('int32') \n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "              context_vector = tf.concat([user_textual_features[batch_userID],item_textual_features[batch_itemID]],1)                    \n",
        "              generated_samples,dec_prob = self.generate_sample(context_vector=context_vector)            \n",
        "              reward =  self.discriminator.get_reward(generated_samples,context_vector)   # batchsize             \n",
        "              g_loss = self.loss_fn(generated_samples , tf.transpose( tf.stack(dec_prob) , [1,0,2]) ,tf.tile( tf.expand_dims(reward,1),[1,self.sequence_length]).numpy() )\n",
        "            \n",
        "            variables =  self.decoder.trainable_variables \n",
        "            gradients = tape.gradient(g_loss, variables)                  \n",
        "            self.optimizer_gn.apply_gradients(zip(gradients, variables))\n",
        "            \n",
        "            return generated_samples,batch_userID,batch_itemID,g_loss\n",
        "       \n",
        "    def _train_step_disc(self,negative_data,negative_user_indices,negative_item_indices):\n",
        "\n",
        "          with tf.GradientTape() as tape:\n",
        "            (positive_user_indices,positive_item_indices,_,positive_data) = next(iter(train_ds_seq)) # ground-truth data\n",
        "\n",
        "            #data shape (batch_size * seq length)\n",
        "            whole_user_indices = tf.concat([positive_user_indices,negative_user_indices],0)\n",
        "            whole_item_indices = tf.concat([positive_item_indices,negative_item_indices],0)\n",
        "\n",
        "            positive_labels = tf.ones(batch_size, dtype=tf.int32) \n",
        "            negative_labels = tf.zeros(batch_size, dtype=tf.int32) \n",
        "            labels = tf.concat([positive_labels, negative_labels], 0)\n",
        "\n",
        "            shuffle_indices = tf.random.shuffle( tf.range(0, len(labels),dtype=tf.int32))\n",
        "            whole_data = tf.gather(tf.concat([positive_data,negative_data],0),shuffle_indices)    \n",
        "            labels = tf.gather(labels,shuffle_indices)\n",
        "            whole_user_indices = tf.gather(whole_user_indices,shuffle_indices)\n",
        "            whole_item_indices = tf.gather(whole_item_indices,shuffle_indices)\n",
        "            query_embedding = tf.concat([tf.gather(user_textual_features , whole_user_indices) ,tf.gather( item_textual_features , whole_item_indices)], 1)\n",
        "            # query shape (batch_size ,2.feature_num)\n",
        "            dis_reward,weights,bias = self.discriminator.get_reward( whole_data,query_embedding,training=True)\n",
        "            l2_loss = tf.nn.l2_loss(weights) + tf.nn.l2_loss(bias)\n",
        "            disc_loss = self.loss_ds(labels,dis_reward) + (self.disc_l2_reg_lambda * l2_loss)\n",
        "         \n",
        "          variables = self.discriminator.trainable_variables \n",
        "          gradients = tape.gradient(disc_loss, variables)\n",
        "          self.optimizer_ds.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "          train_acc_dis.update_state(labels,dis_reward)\n",
        "          return disc_loss\n",
        "\n",
        "\n",
        "    def generate_sample(self, context_vector ):\n",
        "   \n",
        "        dec_out = [tf.convert_to_tensor(batch_size * [[2]])]\n",
        "        dec_prob=[]\n",
        "        dec_state=None    \n",
        "        for _ in range(self.sequence_length):           \n",
        "            d_prob,dec_state = self.decoder( dec_out[-1], context_vector ,dec_state)          \n",
        "            dec_prob.append(d_prob[:,-1])   \n",
        "            dec_out.append(tf.random.categorical(d_prob[:,-1],1,dtype=tf.int32))            \n",
        "            del d_prob          \n",
        "        gc.collect()\n",
        "        \n",
        "        return tf.squeeze(tf.stack(dec_out,1))[:,1:], dec_prob \n",
        "\n",
        "\n",
        "    \n",
        "    def train(self):\n",
        "        print(\"\\n\\nTeacher Forcing Train:\")\n",
        "        self.teacher_forcing_train(num_steps= 128)  # t step\n",
        "        print(\"\\n\\nAdversarial Train:\")          \n",
        "        self.adversarial_train(num_steps= 64)           # g step\n",
        "        print(\"\\n\\nGenerator Test:\")          \n",
        "        self.test(num_steps= 16)\n",
        "       \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3YKdf1-uW8Q"
      },
      "source": [
        "# **Multi-Task Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "khZxlR9oRxVe"
      },
      "outputs": [],
      "source": [
        "class MultiTaskModel(tf.keras.Model):\n",
        "      def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pmf_model = PMF(num_feat=feature_num,num_item= num_items ,num_user= num_users, mean_inv=mean_inv)\n",
        "        self.seq2seq_model = Seq2Seq(num_topic=feature_num,num_item= num_items ,num_user= num_users,units=units, embedding_dim= embedding_dim,vocab_size=full_embedding_matrix.shape[0],sequence_length=sequence_length, num_batches= num_batches,num_batches_test=num_batches_test,batch_size= batch_size)      \n",
        "     \n",
        "      def train(self,n_epochs):    \n",
        "          ckpt.restore(manager.latest_checkpoint)\n",
        "          if manager.latest_checkpoint:\n",
        "            print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "          else:\n",
        "            print(\"Initializing from scratch.\")\n",
        "          #tf.profiler.experimental.start('logs')\n",
        "          for epoch in range(n_epochs):\n",
        "              print(\"\\n\\nepoch : \", int(ckpt.step))\n",
        "              self.seq2seq_model.generate_textual_features()\n",
        "\n",
        "              print(\"********************************************* PMF Model Training Turn *********************************************\")\n",
        "              self.pmf_model.train()\n",
        "              print(\"\\n\\n******************************************* Seq2Seq Model Training Turn *******************************************\")                                         \n",
        "              self.seq2seq_model.train()\n",
        "             \n",
        "              with train_summary_writer.as_default():\n",
        "                  tf.summary.scalar('Training perplexity for generator in Teacher Forcing mode', train_plx_gen_tch.result(), step=int(ckpt.step))\n",
        "                  tf.summary.scalar('Training perplexity for generator in Policy Gradient mode', train_plx_gen_plc.result(), step=int(ckpt.step))\n",
        "                  tf.summary.scalar('Training accuracy for discriminator', train_acc_dis.result(), step=int(ckpt.step))\n",
        "              \n",
        "              with test_summary_writer.as_default():\n",
        "                  tf.summary.scalar('Test perplexity for generator', test_plx_gen.result(), step=int(ckpt.step))\n",
        "           \n",
        "\n",
        "              ckpt.step.assign_add(1)\n",
        "              save_path = manager.save()\n",
        "              print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.step), save_path))\n",
        "            \n",
        "          #tf.profiler.experimental.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzxSK6IUr6O",
        "outputId": "212b1776-5de7-4896-f09a-4ea54c2405df"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "gc.collect(0)\n",
        "gc.collect(1)\n",
        "gc.collect(2)\n",
        "\n",
        "# creating an instance of Multi_Task Model\n",
        "mt_model = MultiTaskModel()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(0), optimizer=tf.keras.optimizers.Adam(), net=mt_model)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing from scratch.\n",
            "\n",
            "\n",
            "epoch :  0\n",
            "********************************************* PMF Model Training Turn *********************************************\n",
            "\n",
            "Training RMSE: 3.205794, Test RMSE 1.185805\n",
            "\n",
            "\n",
            "******************************************* Seq2Seq Model Training Turn *******************************************\n",
            "\n",
            "\n",
            "Teacher Forcing Train:\n",
            "tf.Tensor(\n",
            "[[-6.4845103e-01  8.8623345e-02  5.3488284e-01 ...  2.6415110e-01\n",
            "  -3.8404855e-01 -4.2775601e-02]\n",
            " [-6.5011251e-01  8.9746334e-02  5.3588980e-01 ...  2.4784100e-01\n",
            "  -3.0954295e-01 -1.1373051e-01]\n",
            " [-6.6797507e-01  9.4825432e-02  5.4690373e-01 ...  1.8043613e-01\n",
            "  -3.7219340e-01 -1.1034797e-04]\n",
            " ...\n",
            " [-6.5121323e-01  1.0755326e-01  5.5060446e-01 ...  2.1566907e-01\n",
            "  -3.5926333e-01 -8.4177278e-02]\n",
            " [-1.1015286e-02  7.7838287e-02  8.5451119e-02 ...  3.6944032e-01\n",
            "  -3.8141868e-01 -1.6174975e-01]\n",
            " [ 2.5590837e-02  9.7441792e-02  2.8726427e-02 ...  3.5412568e-01\n",
            "  -3.9229009e-01 -1.5264311e-01]], shape=(367, 128), dtype=float32)\n",
            "batch number:  0 \tgen loss:  9.191233\n",
            "tf.Tensor(\n",
            "[[ 0.5701415  -0.9524205   0.77811575 ...  0.8894085   0.5352233\n",
            "   0.30067497]\n",
            " [ 0.520713   -0.9536289   0.7801623  ...  0.6663547   0.34060016\n",
            "   0.17439894]\n",
            " [ 0.51577765 -0.9535131   0.7805309  ...  0.73954356  0.33466417\n",
            "   0.20058443]\n",
            " ...\n",
            " [ 0.52256775 -0.953862    0.77991754 ...  0.7942985   0.3820099\n",
            "   0.22231072]\n",
            " [ 0.51936275 -0.9535602   0.78024536 ...  0.75096536  0.37012377\n",
            "   0.15403116]\n",
            " [ 0.5713541  -0.9518136   0.77826107 ...  0.7351013   0.39552823\n",
            "   0.21659903]], shape=(380, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9732485  -0.9992261   0.9892649  ...  0.9004347  -0.15259902\n",
            "  -0.20775808]\n",
            " [ 0.9955871  -0.9992853   0.9880504  ...  0.90797704  0.03131319\n",
            "  -0.04010683]\n",
            " [-0.01540268  0.01628058  0.17104575 ...  0.9109994  -0.03914668\n",
            "  -0.11974918]\n",
            " ...\n",
            " [ 0.12851799  0.15236336  0.00491336 ...  0.9377813  -0.0727557\n",
            "  -0.17072357]\n",
            " [ 0.25177032 -0.06219996  0.3167287  ...  0.94643867 -0.08847314\n",
            "  -0.16721743]\n",
            " [ 0.14162429  0.20724949  0.365723   ...  0.9121674  -0.12940782\n",
            "  -0.04841551]], shape=(382, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99873966 -0.99987364  0.9993431  ...  0.96898437 -0.40046254\n",
            "  -0.21004783]\n",
            " [ 0.42407876 -0.62869394  0.6806925  ...  0.9737993  -0.3701638\n",
            "  -0.32179254]\n",
            " [ 0.99977446 -0.99989176  0.99931544 ...  0.9709309  -0.39634052\n",
            "  -0.29658768]\n",
            " ...\n",
            " [ 0.3956519  -0.1704867   0.67306393 ...  0.98300505 -0.4187835\n",
            "  -0.4570798 ]\n",
            " [ 0.3651559   0.4128891   0.64012927 ...  0.98395413 -0.36825803\n",
            "  -0.33897316]\n",
            " [ 0.11204791  0.5149336   0.6810481  ...  0.984904   -0.33248433\n",
            "  -0.3451149 ]], shape=(358, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.36464593 -0.44202167  0.7079357  ...  0.98671    -0.62363005\n",
            "  -0.21606937]\n",
            " [ 0.16218832  0.4636323   0.68314314 ...  0.9895186  -0.7196806\n",
            "  -0.49323735]\n",
            " [ 0.22070518  0.21022522  0.35378256 ...  0.9858231  -0.56085044\n",
            "  -0.24336925]\n",
            " ...\n",
            " [ 0.54449433 -0.99853     0.99965256 ...  0.99476135 -0.74189836\n",
            "  -0.67955685]\n",
            " [ 0.9964919  -0.99996054  0.99990034 ...  0.9898473  -0.74183524\n",
            "  -0.46156344]\n",
            " [ 0.34912607  0.28069532  0.66464746 ...  0.9941947  -0.75531733\n",
            "  -0.6369459 ]], shape=(321, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.29189268  0.22071062  0.30714136 ...  0.9965187  -0.8068834\n",
            "  -0.6395958 ]\n",
            " [ 0.44314548 -0.06085895  0.6309651  ...  0.99721104 -0.85108054\n",
            "  -0.5532343 ]\n",
            " [ 0.00176665  0.5206513   0.5430609  ...  0.9977529  -0.82340074\n",
            "  -0.6216214 ]\n",
            " ...\n",
            " [ 0.23668581  0.45794106  0.73198414 ...  0.997755   -0.85852647\n",
            "  -0.73339844]\n",
            " [ 0.3984261  -0.02490313  0.3007765  ...  0.998293   -0.8803286\n",
            "  -0.7478721 ]\n",
            " [ 0.09031965  0.58492726  0.38252723 ...  0.99507564 -0.769507\n",
            "  -0.49647224]], shape=(348, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.777066   -0.999986    0.9999937  ...  0.99741334 -0.8153202\n",
            "  -0.22326209]\n",
            " [ 0.7358052  -0.99998504  0.99999374 ...  0.9967421  -0.79007506\n",
            "  -0.32696855]\n",
            " [ 0.25414607 -0.7375838   0.9935618  ...  0.998055   -0.8722539\n",
            "  -0.690605  ]\n",
            " ...\n",
            " [ 0.87875074 -0.9999888   0.9999934  ...  0.9980712  -0.9466283\n",
            "  -0.6539771 ]\n",
            " [ 0.9413546  -0.99998623  0.99999404 ...  0.9991871  -0.9019899\n",
            "  -0.74898344]\n",
            " [ 0.9484259  -0.9999889   0.99999315 ...  0.9992224  -0.9361486\n",
            "  -0.8036711 ]], shape=(371, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.32786688  0.46123275  0.4215065  ...  0.9995581  -0.97053784\n",
            "  -0.7754708 ]\n",
            " [ 0.9638461  -0.9999702   0.99999785 ...  0.99885386 -0.9196372\n",
            "  -0.5032194 ]\n",
            " [ 0.22412997  0.4474568   0.50911266 ...  0.99939394 -0.8357015\n",
            "  -0.55538225]\n",
            " ...\n",
            " [ 0.10066859  0.79552174  0.6391421  ...  0.9987171  -0.87698275\n",
            "  -0.5612182 ]\n",
            " [ 0.66484296 -0.9317094   0.9998544  ...  0.99862325 -0.8370637\n",
            "  -0.45103356]\n",
            " [ 0.9918098  -0.99999285  0.999998   ...  0.999658   -0.9638302\n",
            "  -0.75858384]], shape=(337, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9996085  -0.99999654  0.99999934 ...  0.9994214  -0.87203366\n",
            "  -0.4214556 ]\n",
            " [ 0.17285287  0.5046379   0.7005788  ...  0.9996522  -0.884159\n",
            "  -0.6603402 ]\n",
            " [ 0.21465433  0.44653633  0.68444216 ...  0.99980396 -0.89070076\n",
            "  -0.59920406]\n",
            " ...\n",
            " [ 0.19828759  0.49797508  0.7253266  ...  0.9994123  -0.6883071\n",
            "  -0.5407915 ]\n",
            " [ 0.36545599  0.22854985  0.536043   ...  0.9994506  -0.76656806\n",
            "  -0.39206162]\n",
            " [ 0.04069869  0.5658961   0.8114043  ...  0.999313   -0.69337493\n",
            "  -0.15703213]], shape=(388, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.8588607  -0.9999971   0.9999997  ...  0.9998964  -0.78070664\n",
            "  -0.66262513]\n",
            " [ 0.36056897  0.06854268  0.4571371  ...  0.9996853  -0.85763395\n",
            "  -0.4139931 ]\n",
            " [ 0.01149379  0.70298946  0.7635999  ...  0.9997932  -0.8230786\n",
            "  -0.6725011 ]\n",
            " ...\n",
            " [ 0.98276776 -0.9999977   0.9999997  ...  0.999495   -0.82212454\n",
            "  -0.49958634]\n",
            " [ 0.72478455 -0.9999941   0.99999976 ...  0.9994991  -0.7608522\n",
            "  -0.43960223]\n",
            " [ 0.03503019  0.41874325  0.4865934  ...  0.99975747 -0.8798016\n",
            "  -0.50038487]], shape=(320, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.7749014  -0.9999987   0.99999976 ...  0.99967474 -0.9114787\n",
            "  -0.51519245]\n",
            " [ 0.28508252 -0.9999982   0.9999998  ...  0.99985015 -0.9099344\n",
            "  -0.560912  ]\n",
            " [ 0.7761999  -0.9999987   0.99999976 ...  0.9999513  -0.92856073\n",
            "  -0.48781267]\n",
            " ...\n",
            " [ 0.70457816 -0.99999905  0.99999976 ...  0.9999052  -0.93842214\n",
            "  -0.64117604]\n",
            " [ 0.78367746 -0.99999875  0.9999998  ...  0.9997851  -0.858286\n",
            "  -0.3107198 ]\n",
            " [ 0.7208019  -0.99999875  0.9999998  ...  0.9999446  -0.9084158\n",
            "  -0.6412023 ]], shape=(389, 128), dtype=float32)\n",
            "batch number:  10 \tgen loss:  6.429465\n",
            "tf.Tensor(\n",
            "[[ 0.9273493  -0.9999992   0.9999999  ...  0.9999813  -0.93846995\n",
            "  -0.5518457 ]\n",
            " [ 0.8302263  -0.9999992   0.9999999  ...  0.99983805 -0.91850805\n",
            "  -0.3543606 ]\n",
            " [ 0.7498053  -0.99999934  0.9999999  ...  0.9998987  -0.9485321\n",
            "  -0.5344932 ]\n",
            " ...\n",
            " [ 0.11112869 -0.288763    0.70217466 ...  0.9998657  -0.9503506\n",
            "  -0.5100215 ]\n",
            " [ 0.24631381  0.07204562  0.53268117 ...  0.999985   -0.95817584\n",
            "  -0.6521629 ]\n",
            " [ 0.19131662  0.49096042  0.7175006  ...  0.99998045 -0.94313973\n",
            "  -0.6581557 ]], shape=(411, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.1511809   0.4315654   0.24965273 ...  0.99990475 -0.93800414\n",
            "  -0.56529653]\n",
            " [-0.09939938  0.6174529   0.5695027  ...  0.9999867  -0.95239884\n",
            "  -0.6364319 ]\n",
            " [-0.10964678  0.57801     0.4655304  ...  0.9999798  -0.94077265\n",
            "  -0.4536629 ]\n",
            " ...\n",
            " [ 0.95713776 -0.9999993   0.9999999  ...  0.9998689  -0.84359634\n",
            "  -0.2512765 ]\n",
            " [ 0.9819777  -0.9999992   0.99999994 ...  0.99993706 -0.9671118\n",
            "  -0.7357715 ]\n",
            " [ 0.9816952  -0.9999994   0.99999994 ...  0.999952   -0.97921354\n",
            "  -0.7954919 ]], shape=(370, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.21301942  0.13687609  0.2857917  ...  0.9999487  -0.95695513\n",
            "  -0.5687139 ]\n",
            " [ 0.92866325 -0.9999995   0.99999994 ...  0.9999506  -0.94740546\n",
            "  -0.50879204]\n",
            " [ 0.87598133 -0.9999996   0.99999994 ...  0.9999841  -0.9681529\n",
            "  -0.57896084]\n",
            " ...\n",
            " [ 0.13385347  0.43108842  0.44329834 ...  0.99999607 -0.9849473\n",
            "  -0.604326  ]\n",
            " [-0.1053826   0.68786097  0.76583767 ...  0.99990094 -0.94846356\n",
            "  -0.46000862]\n",
            " [-0.08925659  0.7381509   0.7193004  ...  0.99997324 -0.95737517\n",
            "  -0.40286458]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9960799  -0.99999964  1.         ...  0.99994344 -0.94542366\n",
            "  -0.3633249 ]\n",
            " [ 0.99715656 -0.9999996   1.         ...  0.9999539  -0.9439664\n",
            "  -0.3572616 ]\n",
            " [ 0.9825148  -0.9999997   1.         ...  0.9999807  -0.95658314\n",
            "  -0.48607555]\n",
            " ...\n",
            " [ 0.11718591  0.325357    0.5046647  ...  0.9999649  -0.966863\n",
            "  -0.47801954]\n",
            " [ 0.1517807   0.22041447  0.40870985 ...  0.99990076 -0.933857\n",
            "  -0.15093437]\n",
            " [-0.419025    0.7121003   0.5750116  ...  0.99999595 -0.9436275\n",
            "  -0.5462531 ]], shape=(382, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.74719983 -0.9999945   0.9999941  ...  0.99998045 -0.92101556\n",
            "  -0.55076927]\n",
            " [ 0.31148344 -0.07416901  0.37059352 ...  0.99998313 -0.9525643\n",
            "  -0.16450803]\n",
            " [-0.44713852  0.46328372  0.6184738  ...  0.9999973  -0.98719794\n",
            "  -0.5935798 ]\n",
            " ...\n",
            " [ 0.17996666  0.10696436  0.4939206  ...  0.99996895 -0.963544\n",
            "  -0.3397656 ]\n",
            " [ 0.14001374  0.11483151  0.52199966 ...  0.9999751  -0.9043373\n",
            "  -0.29319322]\n",
            " [-0.26594222  0.7085773   0.7850372  ...  0.99999464 -0.9564176\n",
            "  -0.49526358]], shape=(316, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.98836595 -0.99999964  1.         ...  0.99995273 -0.8889914\n",
            "  -0.16476998]\n",
            " [ 0.99815476 -0.9999996   1.         ...  0.99998283 -0.9818122\n",
            "  -0.592963  ]\n",
            " [ 0.99872816 -0.9999996   1.         ...  0.99998325 -0.9616434\n",
            "  -0.34278107]\n",
            " ...\n",
            " [ 0.00460181  0.48453435  0.41870397 ...  0.99998    -0.9833469\n",
            "  -0.47335953]\n",
            " [-0.575409    0.9123366   0.56374866 ...  0.99997574 -0.9743967\n",
            "  -0.50059175]\n",
            " [ 0.9995668  -0.9999996   1.         ...  0.99998033 -0.9732272\n",
            "  -0.46117088]], shape=(368, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.05719639  0.68340623  0.6735548  ...  0.9999966  -0.92864114\n",
            "  -0.3016052 ]\n",
            " [-0.48522088  0.8308399   0.66649497 ...  0.9999964  -0.97111833\n",
            "  -0.35432112]\n",
            " [ 0.03394183  0.0865764   0.41939947 ...  0.9999981  -0.98377055\n",
            "  -0.5094831 ]\n",
            " ...\n",
            " [ 0.9997964  -0.9999997   1.         ...  0.99999577 -0.9873374\n",
            "  -0.58086866]\n",
            " [-0.1387188   0.18827789  0.2991008  ...  0.9999924  -0.976247\n",
            "  -0.44033638]\n",
            " [ 0.09413034  0.09499077  0.37042308 ...  0.99999785 -0.96740746\n",
            "  -0.5257161 ]], shape=(299, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5519848   0.6587469   0.5484967  ...  0.9999781  -0.9577805\n",
            "  -0.49462748]\n",
            " [-0.50356215  0.74855876  0.47884598 ...  0.9999864  -0.95385593\n",
            "  -0.4712142 ]\n",
            " [-0.3817485   0.7302732   0.76374424 ...  0.99999994 -0.9971269\n",
            "  -0.26804888]\n",
            " ...\n",
            " [ 0.9999333  -0.9999997   1.         ...  0.9999932  -0.98472863\n",
            "  -0.4169663 ]\n",
            " [ 0.9997446  -0.9999997   1.         ...  0.99998605 -0.9427417\n",
            "  -0.27414185]\n",
            " [ 0.9998718  -0.9999997   1.         ...  0.99998724 -0.9859655\n",
            "  -0.5095103 ]], shape=(345, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9738221  -0.99999964  1.         ...  0.9999904  -0.98967427\n",
            "  -0.44209006]\n",
            " [-0.27184302  0.5896384   0.62883174 ...  0.99999857 -0.97413135\n",
            "  -0.39738595]\n",
            " [ 0.997839   -0.9999997   1.         ...  0.99999243 -0.9746641\n",
            "  -0.34148595]\n",
            " ...\n",
            " [ 0.9981631  -0.9999997   1.         ...  0.99999917 -0.9811579\n",
            "  -0.347315  ]\n",
            " [ 0.999879   -0.9999994   1.         ...  0.9999522  -0.888899\n",
            "   0.17961246]\n",
            " [-0.34903288  0.5050203   0.58624893 ...  0.999999   -0.9881171\n",
            "  -0.54113454]], shape=(361, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99998885 -0.9999997   1.         ...  0.9999968  -0.9514102\n",
            "  -0.414732  ]\n",
            " [ 0.99999034 -0.9999997   1.         ...  0.9999916  -0.933656\n",
            "  -0.28011915]\n",
            " [ 0.9999817  -0.9999997   1.         ...  0.999999   -0.9946778\n",
            "  -0.49113062]\n",
            " ...\n",
            " [ 0.07698069  0.00560168  0.33042017 ...  0.99999714 -0.9664643\n",
            "  -0.21031332]\n",
            " [-0.29646474  0.47894675  0.5409218  ...  0.99999607 -0.9750272\n",
            "  -0.46714753]\n",
            " [-0.5689793   0.7287775   0.81017256 ...  0.9999991  -0.9775929\n",
            "  -0.44260874]], shape=(398, 128), dtype=float32)\n",
            "batch number:  20 \tgen loss:  6.225844\n",
            "tf.Tensor(\n",
            "[[-0.7654946   0.95320743  0.5897959  ...  0.9999996  -0.9773164\n",
            "  -0.3860621 ]\n",
            " [-0.3946771   0.83777344  0.81057507 ...  1.         -0.99571526\n",
            "  -0.23162436]\n",
            " [-0.75452286  0.9554976   0.79980916 ...  0.9999997  -0.9863805\n",
            "  -0.45675975]\n",
            " ...\n",
            " [-0.21476758  0.2356977   0.33041292 ...  0.9999971  -0.9906948\n",
            "  -0.5073319 ]\n",
            " [ 0.9864855  -0.9999997   1.         ...  0.9999993  -0.98874587\n",
            "  -0.42194226]\n",
            " [-0.52049536  0.8158491   0.633908   ...  0.99999326 -0.9785481\n",
            "  -0.31302497]], shape=(361, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.93681264 -0.99999964  1.         ...  0.99999666 -0.97849995\n",
            "  -0.16707258]\n",
            " [ 0.9703245  -0.99999964  1.         ...  0.99999213 -0.9642282\n",
            "  -0.15605178]\n",
            " [ 0.9962294  -0.99999964  1.         ...  0.99998844 -0.95839936\n",
            "  -0.2938222 ]\n",
            " ...\n",
            " [ 0.99633485 -0.99999946  1.         ...  0.9999943  -0.9876287\n",
            "  -0.28021863]\n",
            " [ 0.9998925  -0.9999994   1.         ...  0.9999879  -0.98019505\n",
            "  -0.4096235 ]\n",
            " [ 0.9997151  -0.9999994   1.         ...  0.9999916  -0.97156864\n",
            "  -0.26468584]], shape=(454, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.93306786 -0.99999964  1.         ...  0.9999998  -0.9850871\n",
            "  -0.365336  ]\n",
            " [ 0.9984272  -0.9999996   1.         ...  0.9999942  -0.9897002\n",
            "  -0.42120212]\n",
            " [ 0.9990229  -0.99999964  1.         ...  0.99999636 -0.97605616\n",
            "  -0.4162526 ]\n",
            " ...\n",
            " [-0.31879976  0.5900594   0.2998655  ...  0.9999993  -0.98364353\n",
            "  -0.2601388 ]\n",
            " [-0.10331603  0.3370013   0.6694462  ...  0.99999875 -0.97285235\n",
            "  -0.35316154]\n",
            " [-0.04567185  0.04420045  0.40249127 ...  0.9999978  -0.9817929\n",
            "  -0.40503752]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.63278115  0.7574308   0.33111775 ...  0.99999744 -0.98852086\n",
            "  -0.40881696]\n",
            " [ 0.99698186 -0.9999997   1.         ...  0.9999957  -0.98874795\n",
            "  -0.33134472]\n",
            " [ 0.9994106  -0.99999946  1.         ...  0.9999981  -0.97842085\n",
            "  -0.27626052]\n",
            " ...\n",
            " [-0.30484253  0.5061937   0.45944032 ...  0.99999547 -0.95820934\n",
            "  -0.20313333]\n",
            " [-0.17321964  0.2798255   0.49933898 ...  0.99999404 -0.98214835\n",
            "  -0.3715752 ]\n",
            " [-0.66777295  0.7445311   0.77324045 ...  0.9999989  -0.99004924\n",
            "  -0.36622587]], shape=(344, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.54434186  0.73501843  0.7077931  ...  0.99999934 -0.98050773\n",
            "  -0.17840576]\n",
            " [-0.5152899   0.4541866   0.60111135 ...  0.99999404 -0.98325604\n",
            "  -0.24964641]\n",
            " [-0.21942721  0.33379042  0.4649706  ...  0.9999991  -0.95924145\n",
            "  -0.04195464]\n",
            " ...\n",
            " [-0.35622364  0.3756846   0.57809705 ...  0.99999857 -0.9823985\n",
            "  -0.2747332 ]\n",
            " [-0.11432604  0.41706     0.5037275  ...  0.99999774 -0.9635076\n",
            "  -0.21879154]\n",
            " [-0.6894537   0.6153137   0.5186168  ...  0.9999768  -0.9229826\n",
            "   0.20955643]], shape=(365, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-2.8355584e-01  2.9548618e-01  4.5712119e-01 ...  9.9999315e-01\n",
            "  -9.6211106e-01 -1.3340977e-01]\n",
            " [-7.7488744e-01  8.1445289e-01  1.1300633e-01 ...  9.9999779e-01\n",
            "  -9.7969490e-01 -3.0192524e-01]\n",
            " [-3.6141983e-01  5.6409436e-01  7.6399201e-01 ...  9.9999666e-01\n",
            "  -9.8146313e-01 -2.7984065e-01]\n",
            " ...\n",
            " [-6.0097504e-01  4.0626636e-01  7.4516475e-01 ...  9.9999803e-01\n",
            "  -9.6110332e-01 -6.6803634e-02]\n",
            " [-3.8666657e-01  4.6374175e-01  7.1953940e-01 ...  9.9999982e-01\n",
            "  -9.9309301e-01 -2.8104398e-01]\n",
            " [ 9.9286006e-04  3.3074233e-01  3.5372928e-01 ...  9.9999952e-01\n",
            "  -9.7760433e-01 -2.2012115e-01]], shape=(344, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99997485 -0.99999964  1.         ...  0.9999954  -0.98474556\n",
            "  -0.13205248]\n",
            " [ 0.9993927  -0.99999964  1.         ...  0.9999981  -0.980904\n",
            "  -0.05603399]\n",
            " [-0.5266077   0.7530451   0.79220855 ...  0.99999744 -0.9818203\n",
            "  -0.08104949]\n",
            " ...\n",
            " [-0.19549312  0.37870172  0.48176253 ...  0.99999785 -0.9801271\n",
            "  -0.2844717 ]\n",
            " [-0.0392705   0.3908496   0.37165046 ...  0.99999684 -0.98693097\n",
            "  -0.16181141]\n",
            " [-0.6524936   0.7803707   0.74992615 ...  0.9999997  -0.98431575\n",
            "  -0.29044223]], shape=(393, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.74602276  0.93103915  0.73985857 ...  0.999997   -0.98584086\n",
            "  -0.04812955]\n",
            " [-0.50456804  0.7622663   0.81156784 ...  0.99999976 -0.9906799\n",
            "  -0.23866457]\n",
            " [-0.47251597  0.5027907   0.1654196  ...  0.999997   -0.98390037\n",
            "  -0.12561566]\n",
            " ...\n",
            " [ 0.9909151  -0.99999964  1.         ...  0.9999964  -0.9734749\n",
            "  -0.23000877]\n",
            " [ 0.98916876 -0.9999997   1.         ...  0.99999756 -0.98592687\n",
            "  -0.13503216]\n",
            " [ 0.9986435  -0.99999964  1.         ...  0.9999948  -0.9694379\n",
            "  -0.1910987 ]], shape=(346, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99809265 -0.99999964  1.         ...  0.9999997  -0.97417456\n",
            "  -0.1641977 ]\n",
            " [ 0.98019433 -0.99999964  1.         ...  0.99999994 -0.9929329\n",
            "  -0.3810162 ]\n",
            " [-0.5166951   0.7225789   0.8406373  ...  0.9999927  -0.968498\n",
            "  -0.01673493]\n",
            " ...\n",
            " [ 0.76556504 -0.99999946  1.         ...  0.9999981  -0.98257375\n",
            "  -0.2534853 ]\n",
            " [ 0.8683507  -0.99999946  1.         ...  0.9999999  -0.99684095\n",
            "  -0.4281304 ]\n",
            " [ 0.9998643  -0.9999997   1.         ...  0.99999744 -0.99535\n",
            "  -0.32577235]], shape=(347, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9985746  -0.99999964  1.         ...  0.9999997  -0.98560876\n",
            "  -0.21069293]\n",
            " [ 0.99536175 -0.99999964  1.         ...  0.9999998  -0.9764837\n",
            "  -0.176831  ]\n",
            " [ 0.9851961  -0.99999964  1.         ...  0.99999774 -0.9925722\n",
            "  -0.15456541]\n",
            " ...\n",
            " [ 0.9179312  -0.99999946  1.         ...  0.99999493 -0.986542\n",
            "  -0.23561835]\n",
            " [ 0.9955599  -0.9999997   1.         ...  0.99999565 -0.9914098\n",
            "  -0.09095839]\n",
            " [ 0.9992805  -0.9999995   1.         ...  0.9999946  -0.98713887\n",
            "  -0.03579552]], shape=(345, 128), dtype=float32)\n",
            "batch number:  30 \tgen loss:  5.8962455\n",
            "tf.Tensor(\n",
            "[[-0.6401651   0.5836179   0.39683557 ...  0.9999976  -0.9888221\n",
            "  -0.16962422]\n",
            " [-0.65270936  0.7770167   0.6638872  ...  0.99999917 -0.98318124\n",
            "  -0.03306988]\n",
            " [-0.6371523   0.89153004  0.69816387 ...  0.9999995  -0.9814065\n",
            "  -0.09720714]\n",
            " ...\n",
            " [-0.38205558  0.6654442   0.7134725  ...  0.9999968  -0.956744\n",
            "  -0.04080909]\n",
            " [ 0.64686483 -0.9999997   0.9999707  ...  0.9999897  -0.97250706\n",
            "   0.08613348]\n",
            " [-0.10408723  0.41384852  0.26059315 ...  0.99999785 -0.9950972\n",
            "  -0.21629845]], shape=(389, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999833  -0.9999996   1.         ...  0.99999785 -0.9878727\n",
            "  -0.08045366]\n",
            " [ 0.99996936 -0.9999996   1.         ...  0.999998   -0.98683196\n",
            "  -0.148594  ]\n",
            " [ 0.9999382  -0.9999994   1.         ...  0.999998   -0.99083024\n",
            "  -0.16388811]\n",
            " ...\n",
            " [ 0.66262484 -0.9999997   1.         ...  0.99999994 -0.983255\n",
            "  -0.10416091]\n",
            " [ 0.9614515  -0.99999946  1.         ...  0.9999978  -0.98509014\n",
            "  -0.08964834]\n",
            " [-0.39281133  0.39337078  0.28938693 ...  0.99999994 -0.9892655\n",
            "  -0.01006882]], shape=(382, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9972919  -0.99999964  1.         ...  0.99999595 -0.9832651\n",
            "  -0.00451563]\n",
            " [ 0.8621391  -0.9999996   1.         ...  0.9999965  -0.9835231\n",
            "  -0.12689106]\n",
            " [ 0.9734302  -0.99999964  1.         ...  0.99999976 -0.9648347\n",
            "   0.04001657]\n",
            " ...\n",
            " [-0.49204573  0.42282817  0.47440097 ...  0.99999666 -0.98720384\n",
            "  -0.05007174]\n",
            " [ 0.9906261  -0.9999997   1.         ...  0.999998   -0.97237104\n",
            "   0.0153516 ]\n",
            " [ 0.9946193  -0.99999964  1.         ...  0.99999565 -0.96835345\n",
            "  -0.08544252]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.22507308 -0.9999932   0.9960624  ...  0.99999917 -0.9917759\n",
            "  -0.26233107]\n",
            " [ 0.27144328  0.06947144  0.34557325 ...  0.99999994 -0.98549944\n",
            "  -0.09732632]\n",
            " [ 0.96602845 -0.99999964  1.         ...  0.99999815 -0.9944571\n",
            "  -0.11858838]\n",
            " ...\n",
            " [-0.29699317 -0.9843393   0.94251746 ...  0.9999975  -0.9599577\n",
            "   0.0065239 ]\n",
            " [ 0.7745051  -0.9999994   1.         ...  0.99999994 -0.9840505\n",
            "  -0.00892919]\n",
            " [ 0.90321296 -0.9999994   1.         ...  0.9999995  -0.9731816\n",
            "  -0.1047124 ]], shape=(380, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.73836035 -0.99999964  1.         ...  1.         -0.9961643\n",
            "   0.09278613]\n",
            " [ 0.9798122  -0.99999964  1.         ...  0.9999955  -0.96398026\n",
            "  -0.09767848]\n",
            " [ 0.99463797 -0.99999964  1.         ...  0.9999983  -0.9872214\n",
            "   0.04655594]\n",
            " ...\n",
            " [-0.4109767   0.58746827  0.28343192 ...  0.99999446 -0.95822024\n",
            "   0.19469027]\n",
            " [-0.7064406   0.526887    0.2528312  ...  0.9999969  -0.96929306\n",
            "  -0.05713346]\n",
            " [-0.5469062   0.8232656   0.5360213  ...  0.9999988  -0.9827151\n",
            "   0.04536258]], shape=(416, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.09848309  0.20120537  0.22884029 ...  0.9999972  -0.98689944\n",
            "   0.03434424]\n",
            " [ 0.27386937  0.12465628  0.18081933 ...  0.99999917 -0.99143696\n",
            "  -0.05256504]\n",
            " [-0.6348207   0.6990049   0.8122345  ...  0.9999963  -0.977324\n",
            "  -0.03216282]\n",
            " ...\n",
            " [-0.04314996 -0.9999911   0.99740845 ...  0.9999984  -0.99373674\n",
            "   0.06642303]\n",
            " [-0.05617154  0.33815202  0.5469564  ...  0.9999983  -0.9907127\n",
            "  -0.07463347]\n",
            " [-0.28182492  0.38186547  0.20335044 ...  0.9999984  -0.9891303\n",
            "  -0.1905705 ]], shape=(396, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.56391805  0.7555119   0.7672498  ...  0.99999917 -0.98723894\n",
            "   0.00702487]\n",
            " [-0.36128148  0.3093061   0.39064497 ...  0.9999998  -0.9851207\n",
            "   0.02257901]\n",
            " [ 0.8206303  -0.99999964  1.         ...  0.9999991  -0.9802669\n",
            "   0.07936479]\n",
            " ...\n",
            " [ 0.97814924 -0.9999996   1.         ...  0.99999833 -0.9916286\n",
            "  -0.09999926]\n",
            " [ 0.9637158  -0.99999964  1.         ...  0.99999976 -0.9948109\n",
            "  -0.06363324]\n",
            " [ 0.98495334 -0.9999996   1.         ...  0.9999999  -0.99070907\n",
            "  -0.09705506]], shape=(387, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-1.48080423e-01  3.11895251e-01  4.86504823e-01 ...  9.99999940e-01\n",
            "  -9.97304559e-01  4.02346887e-02]\n",
            " [ 8.51647019e-01 -9.99999583e-01  1.00000000e+00 ...  9.99998152e-01\n",
            "  -9.87026632e-01 -9.56160191e-04]\n",
            " [ 9.97493684e-01 -9.99999583e-01  1.00000000e+00 ...  9.99999940e-01\n",
            "  -9.97838378e-01  5.91546334e-02]\n",
            " ...\n",
            " [-1.43682301e-01  3.00314575e-01  3.55332494e-01 ...  9.99998689e-01\n",
            "  -9.89111900e-01 -5.88452555e-02]\n",
            " [-6.76907599e-01  3.25168908e-01  8.23409498e-01 ...  9.99999702e-01\n",
            "  -9.88973200e-01 -1.35114208e-01]\n",
            " [-6.51327297e-02  2.17796981e-01  1.06790856e-01 ...  9.99999881e-01\n",
            "  -9.86709297e-01 -6.40303493e-02]], shape=(320, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.17699413  0.29824838  0.52905464 ...  0.9999989  -0.99193084\n",
            "  -0.01146318]\n",
            " [-0.6769633   0.7511259   0.70779985 ...  0.99999917 -0.9811308\n",
            "   0.05151388]\n",
            " [ 0.94679606 -0.99999964  1.         ...  1.         -0.9961617\n",
            "  -0.11335062]\n",
            " ...\n",
            " [ 0.9999751  -0.99999946  1.         ...  0.99999976 -0.99742573\n",
            "   0.16612619]\n",
            " [-0.6307259   0.6787042   0.82779765 ...  0.9999998  -0.9872337\n",
            "  -0.09009634]\n",
            " [ 0.2455945   0.21812339  0.2876294  ...  1.         -0.9934101\n",
            "   0.01963241]], shape=(457, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99998933 -0.9999997   1.         ...  0.9999998  -0.99003226\n",
            "   0.0476436 ]\n",
            " [ 0.99999124 -0.9999997   1.         ...  0.99999994 -0.99425066\n",
            "   0.00136784]\n",
            " [ 0.9999635  -0.99999964  1.         ...  0.9999999  -0.99284947\n",
            "   0.03997768]\n",
            " ...\n",
            " [ 0.64301866 -0.9999995   0.9999117  ...  0.9999997  -0.9826436\n",
            "  -0.01145809]\n",
            " [ 0.99212503 -0.9999995   1.         ...  0.9999971  -0.98334724\n",
            "   0.08550417]\n",
            " [ 0.9999974  -0.99999964  1.         ...  0.99999714 -0.9838434\n",
            "   0.07177615]], shape=(365, 128), dtype=float32)\n",
            "batch number:  40 \tgen loss:  5.768396\n",
            "tf.Tensor(\n",
            "[[ 9.9999982e-01 -9.9999970e-01  1.0000000e+00 ...  9.9999863e-01\n",
            "  -9.8731053e-01  9.4835728e-02]\n",
            " [ 9.9999994e-01 -9.9999970e-01  1.0000000e+00 ...  9.9999964e-01\n",
            "  -9.9066973e-01  9.9541154e-03]\n",
            " [ 9.9999982e-01 -9.9999970e-01  1.0000000e+00 ...  9.9999881e-01\n",
            "  -9.9205178e-01  4.2659119e-02]\n",
            " ...\n",
            " [ 9.9948943e-01 -9.9999970e-01  1.0000000e+00 ...  9.9999988e-01\n",
            "  -9.7621727e-01  1.3937111e-04]\n",
            " [ 9.9761748e-01 -9.9999970e-01  1.0000000e+00 ...  9.9999988e-01\n",
            "  -9.7617865e-01  4.2111252e-04]\n",
            " [ 9.9751765e-01 -9.9999970e-01  1.0000000e+00 ...  1.0000000e+00\n",
            "  -9.9549067e-01  1.5133905e-01]], shape=(399, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.9999997   1.         ...  0.9999983  -0.98213416\n",
            "   0.00436052]\n",
            " [-0.19444457  0.55510056  0.70411307 ...  0.9999983  -0.986671\n",
            "  -0.04917955]\n",
            " [ 0.9999773  -0.99999946  1.         ...  0.99999994 -0.9903075\n",
            "  -0.10842785]\n",
            " ...\n",
            " [ 0.99953395 -0.9999997   1.         ...  0.99999964 -0.986845\n",
            "   0.05415189]\n",
            " [ 0.9999038  -0.9999997   1.         ...  0.9999999  -0.9826019\n",
            "   0.0740808 ]\n",
            " [ 0.99999994 -0.9999997   1.         ...  0.9999986  -0.9884297\n",
            "  -0.03523335]], shape=(333, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.9999997   1.         ...  0.99999994 -0.9872152\n",
            "   0.01939878]\n",
            " [ 0.9999997  -0.9999995   1.         ...  0.9999987  -0.99436074\n",
            "  -0.10576673]\n",
            " [ 0.9999993  -0.9999996   1.         ...  0.99999756 -0.98193675\n",
            "   0.05748826]\n",
            " ...\n",
            " [-0.90911293  0.9195715   0.7331825  ...  1.         -0.99631596\n",
            "  -0.13815923]\n",
            " [-0.01163493  0.26080418  0.27278414 ...  1.         -0.9960148\n",
            "   0.03574608]\n",
            " [-0.46086365  0.5287759   0.48389313 ...  0.9999998  -0.99510264\n",
            "  -0.0019834 ]], shape=(426, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.61745995  0.65195084  0.53890294 ...  0.99999946 -0.9910134\n",
            "  -0.0056749 ]\n",
            " [ 0.8750774  -0.9999979   0.999727   ...  0.9999994  -0.98566663\n",
            "   0.03122521]\n",
            " [-0.5062289   0.62745833  0.6018917  ...  0.9999984  -0.97667605\n",
            "   0.0449046 ]\n",
            " ...\n",
            " [-0.64496046  0.7792195   0.67106307 ...  0.9999997  -0.9889529\n",
            "   0.12991291]\n",
            " [-0.68319076  0.8513195   0.60207164 ...  0.9999999  -0.98501486\n",
            "   0.09478807]\n",
            " [-0.42921576  0.7400517   0.83039874 ...  0.9999991  -0.981052\n",
            "   0.25085515]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.6393989   0.7060209   0.7025531  ...  0.999999   -0.9940618\n",
            "   0.05089913]\n",
            " [ 0.99995315 -0.99999976  1.         ...  0.99999857 -0.97953284\n",
            "  -0.08563148]\n",
            " [ 0.9946895  -0.99999976  0.9999998  ...  0.99999857 -0.9795421\n",
            "  -0.0852087 ]\n",
            " ...\n",
            " [ 1.         -0.99999976  1.         ...  0.9999993  -0.9711225\n",
            "   0.1194235 ]\n",
            " [-0.2009916   0.48672202  0.13317798 ...  1.         -0.9858331\n",
            "  -0.02360133]\n",
            " [ 0.0732461   0.06281608  0.33378878 ...  0.99999994 -0.994989\n",
            "  -0.08933628]], shape=(427, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999997   1.         ...  0.99999905 -0.9907753\n",
            "   0.11978541]\n",
            " [-0.51872593  0.6204589   0.8033035  ...  0.99999994 -0.9834749\n",
            "   0.21042201]\n",
            " [ 0.10603259  0.32796666  0.28662038 ...  0.99999976 -0.99335146\n",
            "  -0.06548293]\n",
            " ...\n",
            " [-0.09715603  0.30868644  0.36061046 ...  0.99999726 -0.9905657\n",
            "   0.06708461]\n",
            " [-0.15103275  0.24228473  0.40385717 ...  0.99999785 -0.98955023\n",
            "   0.01962827]\n",
            " [-0.0359982   0.35958892  0.50217944 ...  0.99999833 -0.99099404\n",
            "  -0.03777732]], shape=(415, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.03972075  0.427167    0.3348913  ...  0.99999994 -0.99174947\n",
            "  -0.02459376]\n",
            " [-0.35139066  0.7151575   0.5721311  ...  0.9999988  -0.98479944\n",
            "   0.04602526]\n",
            " [ 0.01128052  0.21471797  0.32953194 ...  1.         -0.98342144\n",
            "  -0.0465763 ]\n",
            " ...\n",
            " [ 0.9999497  -0.99999976  1.         ...  0.9999968  -0.9694725\n",
            "   0.26665312]\n",
            " [ 1.         -0.99999976  1.         ...  1.         -0.9979629\n",
            "  -0.00908049]\n",
            " [ 0.9997892  -0.99999976  1.         ...  1.         -0.9883185\n",
            "   0.20409366]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.99999976  1.         ...  0.9999999  -0.9906672\n",
            "   0.07712481]\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.9945826\n",
            "  -0.02085459]\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.9878734\n",
            "   0.12836675]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.99989307\n",
            "  -0.03486079]\n",
            " [ 0.9997276  -0.9999997   0.99999994 ...  0.99999785 -0.95991164\n",
            "   0.25192985]\n",
            " [ 0.99999994 -0.99999976  1.         ...  0.99999785 -0.9813952\n",
            "   0.0341552 ]], shape=(375, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.16830109  0.20823383  0.06971683 ...  0.9999989  -0.9870706\n",
            "  -0.03436355]\n",
            " [ 0.18248114  0.29158646  0.77977735 ...  0.9999989  -0.98837054\n",
            "   0.07971143]\n",
            " [ 0.49751604  0.14643382  0.40437898 ...  1.         -0.99413157\n",
            "   0.01827049]\n",
            " ...\n",
            " [-0.10979987  0.41924486  0.42703733 ...  0.9999997  -0.9940887\n",
            "   0.22183533]\n",
            " [ 0.34491578 -0.5598253   0.8521751  ...  0.99999994 -0.9944419\n",
            "   0.20416547]\n",
            " [-0.46049935  0.76490456  0.5886243  ...  1.         -0.9963074\n",
            "   0.26300514]], shape=(292, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.14209054  0.4136374   0.4607419  ...  0.99999994 -0.99734026\n",
            "  -0.1616803 ]\n",
            " [-0.19362052  0.2678023   0.43917465 ...  1.         -0.98711425\n",
            "   0.12589142]\n",
            " [-0.20767456  0.47741273  0.81678736 ...  0.999999   -0.996443\n",
            "   0.07874039]\n",
            " ...\n",
            " [ 1.         -0.9999997   1.         ...  0.9999978  -0.9839733\n",
            "  -0.05013987]\n",
            " [ 1.         -0.9999997   1.         ...  0.9999977  -0.98445976\n",
            "  -0.0354017 ]\n",
            " [ 1.         -0.9999997   1.         ...  0.9999999  -0.9832442\n",
            "   0.19277564]], shape=(371, 128), dtype=float32)\n",
            "batch number:  50 \tgen loss:  5.868444\n",
            "tf.Tensor(\n",
            "[[ 0.99997693 -0.99999976  1.         ...  1.         -0.98081183\n",
            "  -0.04868   ]\n",
            " [ 0.89352655 -0.99523425  0.9326119  ...  0.9999999  -0.9951292\n",
            "   0.11641382]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999964 -0.9847139\n",
            "   0.16670367]\n",
            " ...\n",
            " [ 1.         -0.99999976  1.         ...  0.9999979  -0.97047186\n",
            "   0.09533529]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999964 -0.98485684\n",
            "   0.09090689]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999983  -0.981985\n",
            "   0.23169361]], shape=(360, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.04954757  0.45086077  0.39072937 ...  0.999998   -0.988765\n",
            "   0.0304205 ]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999875 -0.98233384\n",
            "   0.22293545]\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.98715353\n",
            "   0.24376523]\n",
            " ...\n",
            " [ 0.54070723 -0.00440277  0.45008865 ...  0.99999946 -0.9843719\n",
            "   0.09521814]\n",
            " [ 0.03157286  0.4126501   0.7401614  ...  0.9999999  -0.9690974\n",
            "   0.19185714]\n",
            " [ 0.00813696  0.3595814   0.47983372 ...  0.99999917 -0.98761886\n",
            "   0.20051517]], shape=(404, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99998015 -0.9999998   1.         ...  0.99999994 -0.9933355\n",
            "   0.10284255]\n",
            " [ 0.9999357  -0.9999998   0.9999998  ...  0.9999998  -0.98896396\n",
            "   0.21969862]\n",
            " [-0.4667377   0.8530768   0.7316255  ...  0.99999946 -0.98799974\n",
            "   0.1393781 ]\n",
            " ...\n",
            " [-0.24777083  0.6440923   0.8150709  ...  0.99999994 -0.99107623\n",
            "   0.15979828]\n",
            " [-0.1350029   0.72597533  0.6495986  ...  0.99999917 -0.98858887\n",
            "  -0.0203921 ]\n",
            " [-0.2391195   0.1515955   0.11045747 ...  1.         -0.98292315\n",
            "   0.25347695]], shape=(356, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99998105 -0.99999976  1.         ...  0.99999994 -0.99245375\n",
            "   0.03951842]\n",
            " [-0.3449258   0.8254203   0.472366   ...  0.9999989  -0.9810208\n",
            "   0.1332335 ]\n",
            " [ 0.3493803  -0.16667067  0.26716903 ...  0.9999989  -0.97860026\n",
            "   0.22073014]\n",
            " ...\n",
            " [ 0.38043943  0.36210108  0.24327348 ...  0.9999992  -0.9950683\n",
            "   0.00670117]\n",
            " [ 0.3244893   0.18733548  0.27174646 ...  0.99999547 -0.993693\n",
            "   0.3299482 ]\n",
            " [-0.128569    0.7394614   0.43540236 ...  0.99999994 -0.9858742\n",
            "  -0.04589817]], shape=(406, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.13908824  0.5012087  -0.13097864 ...  1.         -0.9866106\n",
            "  -0.01236502]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999994 -0.9945731\n",
            "   0.16831063]\n",
            " [-0.10860989  0.51246554  0.35705265 ...  1.         -0.9968619\n",
            "  -0.02486364]\n",
            " ...\n",
            " [ 0.34120783 -0.28717074  0.6927219  ...  1.         -0.9871374\n",
            "   0.09484949]\n",
            " [ 1.         -0.99999976  1.         ...  0.9999998  -0.98755217\n",
            "   0.23233537]\n",
            " [ 1.         -0.99999976  1.         ...  0.9999993  -0.99285185\n",
            "  -0.05812528]], shape=(399, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999998   1.         ...  0.99999934 -0.96423745\n",
            "   0.2392871 ]\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.9907158\n",
            "   0.33529004]\n",
            " [-0.03475031  0.5296021   0.81284815 ...  1.         -0.99454117\n",
            "   0.02432393]\n",
            " ...\n",
            " [ 0.49987945  0.08582613  0.65532035 ...  0.99999964 -0.9766867\n",
            "   0.06309484]\n",
            " [-0.02323296  0.840104    0.7476101  ...  1.         -0.9937674\n",
            "   0.10395007]\n",
            " [ 0.14400819  0.367831    0.50483245 ...  1.         -0.99571276\n",
            "   0.11896037]], shape=(413, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.6252621   0.10671967  0.47092143 ...  0.99999994 -0.9847127\n",
            "  -0.01830409]\n",
            " [ 0.89086777 -0.8198356   0.6499157  ...  0.9999992  -0.9937665\n",
            "   0.08228192]\n",
            " [ 0.99999774 -0.9999997   1.         ...  0.99999976 -0.99365366\n",
            "   0.09402199]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  0.99999917 -0.9875764\n",
            "   0.140589  ]\n",
            " [ 0.289079    0.7171896   0.58591425 ...  0.99999803 -0.9789128\n",
            "   0.12692308]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999999  -0.9936764\n",
            "   0.2847218 ]], shape=(355, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.52295876 -0.03011645  0.31711617 ...  0.99999803 -0.98010457\n",
            "   0.08146752]\n",
            " [-0.01404681  0.78733414  0.8991368  ...  1.         -0.9993388\n",
            "  -0.0253254 ]\n",
            " [ 0.5645429   0.5349138   0.73387146 ...  0.9999973  -0.9563371\n",
            "   0.27186823]\n",
            " ...\n",
            " [ 0.07905021  0.41037259  0.24890846 ...  0.99999964 -0.97879976\n",
            "   0.3374099 ]\n",
            " [ 0.5099935   0.14111151  0.61597884 ...  0.99999976 -0.97689086\n",
            "  -0.03363756]\n",
            " [ 0.10377049  0.41317055  0.11538721 ...  0.99999994 -0.9897121\n",
            "   0.07480267]], shape=(358, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9996407  -0.9999998   0.9999939  ...  0.9999984  -0.9834492\n",
            "   0.12714343]\n",
            " [ 0.29232594  0.40306622  0.12357538 ...  0.99999994 -0.9880249\n",
            "   0.05217096]\n",
            " [ 0.5902089  -0.1828217   0.25758407 ...  0.9999997  -0.9794367\n",
            "   0.07386424]\n",
            " ...\n",
            " [ 0.5102981  -0.21003735  0.32125148 ...  1.         -0.9828831\n",
            "   0.144939  ]\n",
            " [ 0.5312593  -0.04094677  0.2408301  ...  0.99999994 -0.99454325\n",
            "   0.04214853]\n",
            " [ 0.6212889   0.10471348  0.41152427 ...  0.9999998  -0.99059623\n",
            "   0.02846611]], shape=(410, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.3696916   0.27427953  0.42227173 ...  0.99999994 -0.9866822\n",
            "   0.11848099]\n",
            " [ 0.6913956  -0.5816043   0.7725895  ...  0.99999994 -0.988335\n",
            "   0.07951245]\n",
            " [-0.12873624  0.7700815   0.4309878  ...  0.99999994 -0.99112916\n",
            "   0.1659628 ]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.9902061\n",
            "   0.14199676]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999992  -0.9854751\n",
            "   0.18350035]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999887 -0.9773348\n",
            "   0.28875446]], shape=(379, 128), dtype=float32)\n",
            "batch number:  60 \tgen loss:  5.4550886\n",
            "tf.Tensor(\n",
            "[[ 0.06096844  0.5526874   0.5380537  ...  0.99999744 -0.9805134\n",
            "   0.23620763]\n",
            " [ 0.3085069   0.2984964   0.39843452 ...  0.9999974  -0.9835358\n",
            "   0.20181075]\n",
            " [ 0.5448813  -0.04866843  0.13027209 ...  0.99999994 -0.9905481\n",
            "   0.03562914]\n",
            " ...\n",
            " [ 0.5261163  -0.33856168  0.03129689 ...  0.99999714 -0.9619398\n",
            "   0.1797135 ]\n",
            " [ 0.34759653  0.12954195  0.24789545 ...  0.99999857 -0.98398256\n",
            "  -0.04112907]\n",
            " [ 1.         -0.99999976  1.         ...  1.         -0.9868385\n",
            "  -0.07886976]], shape=(402, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.5477791  -0.04597974  0.27352494 ...  0.99999994 -0.977696\n",
            "   0.03039744]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999905 -0.9894564\n",
            "   0.10598195]\n",
            " [ 0.02541066  0.17561404  0.35773823 ...  1.         -0.99825853\n",
            "   0.01965869]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  0.99999774 -0.9678652\n",
            "   0.3011613 ]\n",
            " [ 0.99998945 -0.9999998   1.         ...  0.9999998  -0.9779103\n",
            "  -0.06289405]\n",
            " [ 0.9999596  -0.9999997   0.99999994 ...  1.         -0.9978432\n",
            "   0.02008449]], shape=(313, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.26757985  0.8565824   0.69640934 ...  0.99999696 -0.96881676\n",
            "   0.04342293]\n",
            " [ 0.21226029  0.701492    0.76112366 ...  0.9999977  -0.9772734\n",
            "   0.09674311]\n",
            " [ 0.5778576  -0.0488291   0.29691252 ...  0.99999917 -0.98438174\n",
            "   0.28055882]\n",
            " ...\n",
            " [-0.35387042  0.9369847   0.5873543  ...  1.         -0.9920593\n",
            "  -0.04094907]\n",
            " [ 0.3901686  -0.10498437  0.22011647 ...  0.99999994 -0.97610724\n",
            "   0.2716188 ]\n",
            " [ 0.41244194 -0.03309107  0.30787596 ...  0.9999991  -0.98849154\n",
            "   0.07897038]], shape=(372, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.20903876  0.08384385  0.08523876 ...  0.9999995  -0.9743456\n",
            "   0.13344987]\n",
            " [ 0.09693032  0.7753303   0.5389397  ...  0.9999993  -0.97980046\n",
            "   0.13348466]\n",
            " [ 0.38492683  0.02339792  0.36054757 ...  0.9999999  -0.9692576\n",
            "   0.02608781]\n",
            " ...\n",
            " [ 0.73771334 -0.49355012  0.22693509 ...  0.9999974  -0.94797397\n",
            "   0.21638168]\n",
            " [-0.39052057  0.5444363  -0.17528924 ...  0.9999992  -0.98355293\n",
            "   0.15771681]\n",
            " [-0.07556411  0.6666015   0.79658884 ...  0.99999917 -0.97818726\n",
            "   0.10940726]], shape=(374, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999998   1.         ...  0.99999994 -0.9633603\n",
            "   0.20132072]\n",
            " [ 0.514303    0.17936783  0.46302357 ...  1.         -0.9704227\n",
            "   0.15324727]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999998  -0.98304504\n",
            "  -0.01559457]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  0.9999995  -0.9670358\n",
            "   0.2929422 ]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999996  -0.9795952\n",
            "   0.22706404]\n",
            " [ 0.7785674  -0.88393027  0.6513806  ...  0.9999997  -0.96960557\n",
            "   0.13971323]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.25526667 -0.89861566  0.16248961 ...  0.9999984  -0.9507646\n",
            "   0.23546767]\n",
            " [ 0.35951862 -0.10742446  0.40991497 ...  0.99999917 -0.978349\n",
            "   0.14879587]\n",
            " [ 0.3594999  -0.10744637  0.4098587  ...  0.99999934 -0.9863433\n",
            "   0.12809046]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  0.9999999  -0.9771637\n",
            "   0.11163061]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.9732858\n",
            "   0.126062  ]\n",
            " [ 1.         -0.9999998   1.         ...  0.999999   -0.9661473\n",
            "   0.09890132]], shape=(436, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999998   1.         ...  0.99999946 -0.96460664\n",
            "   0.30970222]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999969  -0.9396909\n",
            "   0.20013562]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999992  -0.9819958\n",
            "   0.17752185]\n",
            " ...\n",
            " [-0.00240779  0.5002007   0.27669638 ...  0.99999994 -0.9820599\n",
            "  -0.18570442]\n",
            " [ 0.1194161   0.21157707  0.26353553 ...  0.99999994 -0.9598619\n",
            "   0.2682759 ]\n",
            " [ 0.10847691  0.15906557  0.45600045 ...  0.9999993  -0.9788639\n",
            "   0.13607335]], shape=(348, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.12930728  0.34211034  0.18657537 ...  0.9999993  -0.98689514\n",
            "   0.0033689 ]\n",
            " [ 0.00581512  0.2414491   0.3757436  ...  0.9999995  -0.9937917\n",
            "  -0.06510123]\n",
            " [ 0.13667932  0.20466807  0.46536523 ...  0.999999   -0.9773593\n",
            "   0.0442726 ]\n",
            " ...\n",
            " [ 0.45860022 -0.02735172  0.3320212  ...  0.999999   -0.9538216\n",
            "   0.18816671]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999988  -0.97830284\n",
            "   0.19997942]\n",
            " [ 1.         -0.9999999   1.         ...  1.         -0.99465925\n",
            "  -0.09333987]], shape=(378, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.99999976  1.         ...  1.         -0.959392\n",
            "   0.22428988]\n",
            " [ 0.99999994 -0.9999998   1.         ...  0.99999744 -0.97647256\n",
            "   0.25053155]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999998  -0.9301413\n",
            "   0.4897905 ]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.97190195\n",
            "   0.1721113 ]\n",
            " [ 0.997954   -0.9999998   0.9998308  ...  0.9999999  -0.9766506\n",
            "   0.18519147]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.974167\n",
            "   0.2793757 ]], shape=(344, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999875 -0.9999999   1.         ...  1.         -0.97461766\n",
            "  -0.01027305]\n",
            " [-0.19343135  0.84809715  0.6527483  ...  1.         -0.9528161\n",
            "   0.07474837]\n",
            " [ 0.6058755  -0.14402337  0.3555519  ...  0.99999994 -0.9703137\n",
            "   0.2945883 ]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.99999815 -0.97099835\n",
            "   0.08603211]\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.98800045\n",
            "   0.05408328]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999999  -0.9530216\n",
            "   0.5020888 ]], shape=(395, 128), dtype=float32)\n",
            "batch number:  70 \tgen loss:  5.43499\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999999   1.         ...  0.99999976 -0.9746223\n",
            "   0.14391422]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999997  -0.95296466\n",
            "   0.2163917 ]\n",
            " [ 0.49497816  0.04229056  0.31268036 ...  0.99999946 -0.9781761\n",
            "   0.03603411]\n",
            " ...\n",
            " [ 0.9999969  -0.9999999   1.         ...  0.99999994 -0.96676475\n",
            "   0.2057063 ]\n",
            " [ 0.99983704 -0.9999999   0.99999976 ...  0.9999999  -0.94537973\n",
            "  -0.00616793]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999993  -0.97043246\n",
            "   0.1495583 ]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.12416086  0.53316665 -0.18733954 ...  1.         -0.99534374\n",
            "   0.42828324]\n",
            " [-0.12800874  0.44548002  0.6479934  ...  0.9999997  -0.95886093\n",
            "   0.05012068]\n",
            " [-0.00692557  0.6529478   0.7311555  ...  0.999999   -0.95406324\n",
            "   0.11276455]\n",
            " ...\n",
            " [ 0.6454294  -0.9041482   0.29247585 ...  1.         -0.96557474\n",
            "   0.01865733]\n",
            " [-0.0438869   0.41368186  0.05277698 ...  0.9999998  -0.9302552\n",
            "   0.23401073]\n",
            " [ 0.6212486  -0.640196    0.73007363 ...  0.99999994 -0.9759743\n",
            "   0.2796449 ]], shape=(407, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.20204061  0.46834397 -0.29869518 ...  0.99999994 -0.9571937\n",
            "   0.23791721]\n",
            " [ 0.24203466  0.16686802  0.47228155 ...  0.9999991  -0.9815018\n",
            "  -0.01420842]\n",
            " [ 0.1736004   0.4800049   0.04799163 ...  1.         -0.9696006\n",
            "  -0.02541966]\n",
            " ...\n",
            " [ 0.99597365 -0.9999999   0.99987537 ...  0.9999983  -0.9662428\n",
            "   0.21516564]\n",
            " [ 0.3115587   0.3543717   0.22494933 ...  0.9999998  -0.96036345\n",
            "   0.11549661]\n",
            " [-0.01965077  0.44342715  0.60202813 ...  0.99999994 -0.91759586\n",
            "   0.22337113]], shape=(313, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.9999998   1.         ...  0.9999993  -0.990189\n",
            "  -0.03416512]\n",
            " [ 0.9999997  -0.9999999   1.         ...  1.         -0.9545737\n",
            "   0.1244643 ]\n",
            " [ 0.48815775  0.06993     0.23692162 ...  0.99999994 -0.98238635\n",
            "  -0.03267464]\n",
            " ...\n",
            " [ 0.40872082  0.1917334  -0.02368311 ...  0.999999   -0.9775097\n",
            "   0.09697858]\n",
            " [ 0.41924185  0.07291558  0.03399308 ...  0.99999774 -0.9467366\n",
            "   0.13196865]\n",
            " [ 0.46697685 -0.17203878  0.1420329  ...  0.99999994 -0.93864524\n",
            "   0.14885768]], shape=(344, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.34537974  0.72410476  0.29267976 ...  0.99999774 -0.93515384\n",
            "  -0.09555875]\n",
            " [ 1.         -0.9999998   1.         ...  0.9999994  -0.9854912\n",
            "  -0.04222355]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.96160173\n",
            "   0.09295698]\n",
            " ...\n",
            " [ 0.13730174  0.20679802  0.1801581  ...  0.99999964 -0.9629864\n",
            "   0.2799586 ]\n",
            " [ 0.22864605 -0.36313733  0.61733824 ...  0.9999997  -0.96017027\n",
            "   0.24418554]\n",
            " [-0.43435496  0.7523731   0.43909895 ...  0.999999   -0.9838419\n",
            "   0.06862269]], shape=(370, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.30752254  0.8128288   0.38641235 ...  1.         -0.9586786\n",
            "   0.3598618 ]\n",
            " [ 1.         -0.9999999   1.         ...  1.         -0.9749679\n",
            "   0.06539689]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999998  -0.9362035\n",
            "   0.13761654]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.99999857 -0.934646\n",
            "   0.08776749]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999992  -0.9358843\n",
            "  -0.07586773]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999934 -0.96679527\n",
            "   0.03864349]], shape=(433, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.18738066  0.62565273  0.35980147 ...  1.         -0.96934706\n",
            "   0.07657699]\n",
            " [-0.11098146  0.29456812  0.01638134 ...  0.99999976 -0.96671754\n",
            "   0.20988667]\n",
            " [ 0.14187765  0.42846403  0.3405389  ...  0.99999833 -0.9590033\n",
            "   0.24805968]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.99999934 -0.97233856\n",
            "   0.23500201]\n",
            " [ 0.3090593   0.07344063  0.347067   ...  0.99999994 -0.9736958\n",
            "   0.41600338]\n",
            " [-0.16571823  0.6320522   0.55180544 ...  0.99999994 -0.96060073\n",
            "   0.00740537]], shape=(366, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999946 -0.9999999   1.         ...  0.99999994 -0.972931\n",
            "   0.16460873]\n",
            " [ 0.99996763 -0.9999998   1.         ...  0.99999994 -0.9854393\n",
            "   0.0498814 ]\n",
            " [ 0.0537986   0.25845632  0.09703992 ...  0.99999994 -0.9652536\n",
            "   0.04831288]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  0.9999993  -0.96823925\n",
            "   0.27754143]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.9578773\n",
            "   0.05981609]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999998  -0.96225286\n",
            "   0.16334501]], shape=(410, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.22403339  0.14131722 -0.18167506 ...  0.9999988  -0.9666044\n",
            "   0.13565421]\n",
            " [ 0.9999948  -0.9999999   0.99999994 ...  0.9999985  -0.9465523\n",
            "   0.05129594]\n",
            " [ 0.31214365  0.2611932  -0.07562973 ...  0.9999977  -0.9368774\n",
            "   0.16212012]\n",
            " ...\n",
            " [ 0.07159369  0.490955    0.19831051 ...  0.9999986  -0.97453\n",
            "   0.34313232]\n",
            " [ 0.32208765  0.20147733  0.11675278 ...  0.9999969  -0.9548645\n",
            "   0.25690514]\n",
            " [ 0.49677527 -0.86927545  0.2682564  ...  0.9999969  -0.95484966\n",
            "   0.25682917]], shape=(331, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999985  -0.9999999   1.         ...  0.9999999  -0.9746635\n",
            "   0.29494825]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999976 -0.9783822\n",
            "   0.13480204]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999997  -0.97209746\n",
            "   0.09342132]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.9999984  -0.9567505\n",
            "   0.24994214]\n",
            " [ 0.99991864 -0.9999999   0.9999978  ...  0.99999976 -0.9788695\n",
            "   0.00995562]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999982  -0.95273024\n",
            "   0.4752498 ]], shape=(341, 128), dtype=float32)\n",
            "batch number:  80 \tgen loss:  5.429634\n",
            "tf.Tensor(\n",
            "[[ 0.9995874  -0.9999999   0.9999943  ...  0.9999986  -0.9861005\n",
            "   0.17674676]\n",
            " [ 0.50801766 -0.03859176  0.04921597 ...  0.99999994 -0.9645615\n",
            "   0.15630317]\n",
            " [ 0.1121662   0.38785997 -0.22355911 ...  0.99999833 -0.97416526\n",
            "   0.22223096]\n",
            " ...\n",
            " [ 0.15649982  0.23208071  0.03397592 ...  0.99999917 -0.9669871\n",
            "   0.02668713]\n",
            " [ 1.         -0.9999998   1.         ...  0.99999857 -0.98061126\n",
            "   0.22254555]\n",
            " [ 0.9999858  -0.9999999   0.99999994 ...  0.99999857 -0.9683304\n",
            "   0.23750044]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.2044144   0.79077506  0.18878095 ...  0.99999994 -0.94998586\n",
            "   0.19280012]\n",
            " [ 0.16211835  0.2710947  -0.01718947 ...  1.         -0.97719836\n",
            "   0.03450315]\n",
            " [ 1.         -0.9999999   1.         ...  1.         -0.9814406\n",
            "   0.10980679]\n",
            " ...\n",
            " [ 0.16048169  0.22923169 -0.04646955 ...  0.99999994 -0.9535708\n",
            "   0.4151275 ]\n",
            " [ 0.99789906 -0.9999999   0.9999841  ...  0.9999987  -0.96826774\n",
            "   0.08524271]\n",
            " [-0.16166075  0.7100792   0.1809472  ...  0.99999994 -0.9321978\n",
            "   0.14450976]], shape=(383, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999987  -0.9999999   1.         ...  0.99999934 -0.9688142\n",
            "   0.05872133]\n",
            " [ 0.36657977 -0.10825809  0.16047992 ...  0.999999   -0.9706907\n",
            "   0.18570155]\n",
            " [ 0.4435913   0.06264838 -0.06719225 ...  0.99999857 -0.95846426\n",
            "   0.34935468]\n",
            " ...\n",
            " [ 0.10920624  0.24205202 -0.21467207 ...  0.9999995  -0.9608594\n",
            "   0.3665948 ]\n",
            " [ 0.36711362 -0.01399768  0.2623183  ...  0.99999976 -0.9493015\n",
            "   0.05205954]\n",
            " [ 0.11877368  0.3042883  -0.21035866 ...  0.9999999  -0.97343576\n",
            "   0.14354452]], shape=(390, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.12950134  0.4563525  -0.16137676 ...  0.9999977  -0.9405485\n",
            "   0.29586494]\n",
            " [ 0.15871602  0.40274078 -0.08001331 ...  0.9999985  -0.96679235\n",
            "   0.18665382]\n",
            " [-0.02353322  0.43767226 -0.00604105 ...  0.99999934 -0.9740842\n",
            "   0.10283198]\n",
            " ...\n",
            " [-0.09305532  0.3973614  -0.29639846 ...  0.9999989  -0.975894\n",
            "   0.14160785]\n",
            " [ 0.9997551  -0.9999999   0.9999634  ...  0.99999744 -0.9655602\n",
            "   0.41313398]\n",
            " [ 0.9977858  -0.9999999   0.99948967 ...  0.9999996  -0.983223\n",
            "   0.10503644]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99808985 -0.99999994  0.99928    ...  0.9999999  -0.9762294\n",
            "  -0.02180485]\n",
            " [ 0.99999994 -0.9999999   1.         ...  0.9999952  -0.94496846\n",
            "   0.27140152]\n",
            " [ 0.9999999  -0.99999994  1.         ...  0.99999994 -0.9662722\n",
            "   0.20272547]\n",
            " ...\n",
            " [ 0.287229    0.15624769  0.18276645 ...  0.99999917 -0.93838435\n",
            "   0.22720122]\n",
            " [ 0.46357203 -0.1972165   0.14456071 ...  1.         -0.96679235\n",
            "   0.2187787 ]\n",
            " [ 0.03735078  0.39386433 -0.15301389 ...  0.99999994 -0.96232295\n",
            "   0.3482267 ]], shape=(351, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.14588206  0.3862697   0.00321126 ...  0.9999988  -0.95510566\n",
            "   0.1678442 ]\n",
            " [ 0.42196736  0.00714012 -0.065341   ...  1.         -0.98520505\n",
            "   0.2915747 ]\n",
            " [ 0.13579853  0.22917078 -0.24701205 ...  0.99999756 -0.917694\n",
            "   0.22279167]\n",
            " ...\n",
            " [ 0.99999875 -0.99999994  0.9999997  ...  0.99999624 -0.96408236\n",
            "   0.2826087 ]\n",
            " [ 0.28967956 -0.9687097  -0.13111079 ...  0.99999905 -0.97151184\n",
            "   0.1724836 ]\n",
            " [ 0.7064622  -0.9798576   0.5554366  ...  0.99999887 -0.975474\n",
            "  -0.0720856 ]], shape=(338, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999999  -0.99999994  1.         ...  0.9999992  -0.9800042\n",
            "   0.0516848 ]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.9999991  -0.98181254\n",
            "   0.33226183]\n",
            " [ 0.99999994 -0.99999994  1.         ...  1.         -0.9878599\n",
            "   0.01864188]\n",
            " ...\n",
            " [ 0.36222437  0.12574531  0.13923107 ...  0.99999624 -0.9585769\n",
            "   0.25578812]\n",
            " [ 0.27861968 -0.04044319  0.05288469 ...  0.9999998  -0.97214216\n",
            "   0.12776506]\n",
            " [ 0.09473737  0.27941334 -0.12072885 ...  0.9999996  -0.9863463\n",
            "   0.32467595]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.28695527 -0.11480737 -0.04288805 ...  0.9999999  -0.9665659\n",
            "   0.11667381]\n",
            " [ 0.00851916  0.2903962  -0.23512983 ...  0.9999998  -0.98490375\n",
            "   0.18658753]\n",
            " [-0.00368734  0.25346157 -0.25280532 ...  1.         -0.9628099\n",
            "   0.18041413]\n",
            " ...\n",
            " [ 0.03437515  0.40511283 -0.5674354  ...  0.999997   -0.97185725\n",
            "   0.1978121 ]\n",
            " [ 0.99999917 -0.99999994  0.99999994 ...  0.9999996  -0.9846043\n",
            "   0.12482071]\n",
            " [ 0.0453456   0.10100151  0.11568382 ...  0.9999979  -0.9746866\n",
            "   0.39574164]], shape=(358, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.9999999   0.99999994 ...  0.999999   -0.9714872\n",
            "   0.03227783]\n",
            " [-0.16186649  0.48197377 -0.17756867 ...  0.9999998  -0.99077344\n",
            "   0.09594065]\n",
            " [ 0.99999994 -0.99999994  0.99999994 ...  0.9999993  -0.9839987\n",
            "   0.25753564]\n",
            " ...\n",
            " [ 0.22934507 -0.4232528   0.21337105 ...  0.9999998  -0.98422104\n",
            "   0.13192661]\n",
            " [ 0.999998   -0.99999994  0.9999999  ...  1.         -0.9808879\n",
            "   0.16051579]\n",
            " [ 0.9997444  -0.99999994  0.9999619  ...  0.99999905 -0.98169595\n",
            "   0.15314525]], shape=(462, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.9999999   0.99999994 ...  0.9999985  -0.977674\n",
            "   0.23265088]\n",
            " [ 0.9999972  -0.9999999   0.99999994 ...  0.9999986  -0.9539134\n",
            "   0.068436  ]\n",
            " [ 0.99999994 -0.99999994  0.99999994 ...  0.99999976 -0.9873358\n",
            "   0.26704347]\n",
            " ...\n",
            " [ 0.99972093 -0.99999994  0.9996747  ...  0.99999994 -0.97781056\n",
            "   0.15103516]\n",
            " [ 0.9990955  -0.99999994  0.99949414 ...  0.99999934 -0.9471644\n",
            "   0.11865177]\n",
            " [-0.3240943   0.6507055  -0.27057698 ...  1.         -0.9836955\n",
            "   0.27329665]], shape=(395, 128), dtype=float32)\n",
            "batch number:  90 \tgen loss:  5.283636\n",
            "tf.Tensor(\n",
            "[[-0.11816672  0.16881834  0.02105344 ...  1.         -0.98749447\n",
            "   0.02220158]\n",
            " [ 0.999866   -0.99999994  0.9987906  ...  0.99999887 -0.96204025\n",
            "   0.22393133]\n",
            " [ 0.14569525 -0.00836042 -0.15160865 ...  0.99999994 -0.9954289\n",
            "   0.14641604]\n",
            " ...\n",
            " [ 0.9999999  -0.9999999   0.99999994 ...  0.99999994 -0.95718884\n",
            "   0.2646023 ]\n",
            " [ 0.99999994 -0.9999999   0.99998695 ...  0.99999815 -0.9756769\n",
            "   0.11000903]\n",
            " [ 0.9999881  -0.9999999   0.9996382  ...  0.99999917 -0.98502105\n",
            "   0.1505572 ]], shape=(295, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999833 -0.99999994  0.9999798  ...  0.9999989  -0.97292006\n",
            "   0.09650698]\n",
            " [ 0.94096303 -0.99999994  0.9432806  ...  0.9999991  -0.953216\n",
            "   0.26189324]\n",
            " [-0.48641744  0.34858847 -0.12098391 ...  0.99999857 -0.9830751\n",
            "  -0.08463041]\n",
            " ...\n",
            " [-0.34028086  0.01772797 -0.3204494  ...  0.99999994 -0.96988326\n",
            "   0.1800287 ]\n",
            " [ 0.86404175 -0.99999994  0.91543466 ...  0.99999833 -0.9774124\n",
            "   0.2164764 ]\n",
            " [ 0.99999684 -0.99999994  0.99997073 ...  0.99999905 -0.97089005\n",
            "   0.28270325]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5238658   0.6755757  -0.76503724 ...  0.999995   -0.94969976\n",
            "   0.2327697 ]\n",
            " [-0.14493527  0.25122634 -0.4015328  ...  0.99999905 -0.9582808\n",
            "  -0.00712478]\n",
            " [ 0.17878553  0.06698912 -0.07735489 ...  0.99999994 -0.9827487\n",
            "   0.15283099]\n",
            " ...\n",
            " [ 0.27760467  0.00416034 -0.12065339 ...  0.99999744 -0.9543879\n",
            "   0.1049158 ]\n",
            " [ 0.9999609  -0.99999994  0.9999428  ...  0.99999976 -0.98648167\n",
            "   0.07336316]\n",
            " [ 0.9960598  -0.9999999   0.99825126 ...  1.         -0.97581565\n",
            "   0.10757001]], shape=(422, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9992773  -0.9999999   0.9870162  ...  0.9999968  -0.96366334\n",
            "   0.19831781]\n",
            " [ 0.83270305 -0.9999999   0.68981874 ...  0.99999976 -0.9890565\n",
            "  -0.02049106]\n",
            " [ 0.9999955  -0.9999999   0.999735   ...  0.9999996  -0.96157116\n",
            "   0.13088004]\n",
            " ...\n",
            " [-0.3565561   0.3833312  -0.44154447 ...  1.         -0.99442667\n",
            "   0.32852778]\n",
            " [-0.16809812 -0.16242251 -0.3464982  ...  1.         -0.9527547\n",
            "   0.07327419]\n",
            " [-0.50168085  0.28176597 -0.3709343  ...  0.9999999  -0.96062225\n",
            "   0.14978501]], shape=(387, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99949807 -0.9999998   0.83301187 ...  0.99999917 -0.97893983\n",
            "   0.01700955]\n",
            " [ 0.9999346  -0.99999994  0.93842024 ...  0.99999684 -0.97455055\n",
            "   0.13598675]\n",
            " [-0.3648516   0.19469571 -0.3232707  ...  0.9999984  -0.97078025\n",
            "   0.13485965]\n",
            " ...\n",
            " [-0.41658184  0.50020987 -0.47649878 ...  0.9999986  -0.9863135\n",
            "   0.13022226]\n",
            " [-0.43430454  0.16218702 -0.21281737 ...  0.99999815 -0.95739913\n",
            "   0.35379383]\n",
            " [-0.4832479   0.5938108  -0.49969247 ...  0.99999696 -0.97076106\n",
            "   0.10185683]], shape=(366, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99989694 -0.9999999   0.9996733  ...  1.         -0.9712026\n",
            "   0.106043  ]\n",
            " [ 0.9995429  -0.9999998   0.9989743  ...  0.99999964 -0.9839403\n",
            "   0.21774198]\n",
            " [ 0.9999337  -0.99999994  0.99855924 ...  0.9999994  -0.97707826\n",
            "   0.10944106]\n",
            " ...\n",
            " [-0.27184042  0.31416836 -0.4738718  ...  0.9999998  -0.9348961\n",
            "   0.15439285]\n",
            " [ 0.25341973  0.02761751  0.08617487 ...  0.9999999  -0.9458485\n",
            "   0.0798703 ]\n",
            " [ 0.9998446  -0.99999994  0.9994897  ...  0.999999   -0.9528903\n",
            "   0.17210822]], shape=(429, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9994652  -0.9999999   1.         ...  0.9999998  -0.97722965\n",
            "   0.15315399]\n",
            " [-0.09760095  0.00861328 -0.38485953 ...  0.9999972  -0.9350736\n",
            "   0.08180228]\n",
            " [ 0.99990577 -0.9999999   1.         ...  0.99999964 -0.9696104\n",
            "   0.2134272 ]\n",
            " ...\n",
            " [-0.18392149  0.06311652 -0.42137992 ...  0.9999988  -0.9480118\n",
            "   0.05235514]\n",
            " [-0.34805396  0.41208085 -0.37249267 ...  0.99999994 -0.9456229\n",
            "   0.08996029]\n",
            " [-0.35864386  0.34196976 -0.5396726  ...  0.9999963  -0.9353208\n",
            "   0.19075048]], shape=(303, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99982685 -0.99999994  1.         ...  0.9999976  -0.9380665\n",
            "   0.07420959]\n",
            " [-0.2829064   0.25402755 -0.3740057  ...  0.9999993  -0.97129846\n",
            "   0.08765855]\n",
            " [ 0.9968506  -0.9999999   1.         ...  0.9999991  -0.9746814\n",
            "   0.00542874]\n",
            " ...\n",
            " [-0.31313694  0.06132019 -0.4153546  ...  1.         -0.9620301\n",
            "   0.23913592]\n",
            " [-0.37326062  0.39699733 -0.51144695 ...  0.9999998  -0.9616721\n",
            "   0.25542933]\n",
            " [-0.216297    0.17186971 -0.43979698 ...  0.9999998  -0.9320341\n",
            "   0.27767408]], shape=(338, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.01906729 -0.07123364 -0.20139326 ...  0.9999999  -0.96695125\n",
            "   0.11964632]\n",
            " [-0.42449477  0.33588335 -0.59536976 ...  1.         -0.97893965\n",
            "   0.11730832]\n",
            " [-0.211109    0.30418628 -0.36265764 ...  0.99999994 -0.97769284\n",
            "   0.07285541]\n",
            " ...\n",
            " [-0.34025154  0.41967776 -0.45285913 ...  1.         -0.9747149\n",
            "   0.16604243]\n",
            " [ 0.93614    -0.99999994  1.         ...  0.9999996  -0.9827623\n",
            "  -0.06608564]\n",
            " [ 0.60404605 -0.99999994  1.         ...  0.9999992  -0.9842121\n",
            "   0.01116698]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.76425123 -0.99999994  1.         ...  0.9999998  -0.9734477\n",
            "   0.03175073]\n",
            " [ 0.15843649  0.01203489  0.00125827 ...  0.9999993  -0.98031884\n",
            "  -0.06956661]\n",
            " [-0.14890815 -0.02191905 -0.21364608 ...  0.99999887 -0.9571596\n",
            "   0.13662268]\n",
            " ...\n",
            " [ 0.89073795 -0.99999994  1.         ...  0.99999934 -0.94868135\n",
            "   0.05642325]\n",
            " [ 0.97996926 -0.99999994  1.         ...  0.99999917 -0.9506173\n",
            "   0.11306511]\n",
            " [ 0.9634632  -0.99999994  1.         ...  0.9999999  -0.95054746\n",
            "   0.24692188]], shape=(346, 128), dtype=float32)\n",
            "batch number:  100 \tgen loss:  5.546455\n",
            "tf.Tensor(\n",
            "[[ 0.8568887  -0.99999994  1.         ...  0.9999992  -0.98815584\n",
            "   0.3116028 ]\n",
            " [ 0.6356531  -0.99999994  1.         ...  0.99999994 -0.98822176\n",
            "   0.19478802]\n",
            " [ 0.7101397  -0.9999999   1.         ...  0.99999595 -0.9255751\n",
            "   0.46411994]\n",
            " ...\n",
            " [-0.1247791   0.02943517 -0.06868136 ...  0.99999994 -0.9692445\n",
            "  -0.03259436]\n",
            " [ 0.09999689  0.00229859 -0.00897914 ...  0.9999988  -0.9691724\n",
            "  -0.0017066 ]\n",
            " [ 0.19973053 -0.9999721   0.9999526  ...  0.99999934 -0.95316625\n",
            "   0.09453463]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.13231716  0.07625259 -0.35304257 ...  0.9999999  -0.97297794\n",
            "   0.04136034]\n",
            " [-0.7015284   0.5574903  -0.6227571  ...  0.9999998  -0.9688487\n",
            "   0.13510214]\n",
            " [-0.16928272  0.04512078 -0.2816487  ...  0.999999   -0.9782591\n",
            "   0.30351675]\n",
            " ...\n",
            " [-0.5338902   0.15033723 -0.47275832 ...  0.99999905 -0.9721264\n",
            "   0.01122219]\n",
            " [-0.25484058 -0.00816992 -0.3477687  ...  0.99999994 -0.97718817\n",
            "   0.2408142 ]\n",
            " [-0.3998754   0.2985061  -0.45037952 ...  0.99999934 -0.98379886\n",
            "   0.08034705]], shape=(470, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.95218956 -0.99999994  1.         ...  1.         -0.94415903\n",
            "   0.05766528]\n",
            " [ 0.99208087 -0.99999994  1.         ...  1.         -0.95312023\n",
            "   0.2188151 ]\n",
            " [ 0.96774817 -0.99999994  1.         ...  0.9999992  -0.96764207\n",
            "   0.18535693]\n",
            " ...\n",
            " [ 0.942824   -0.9999999   1.         ...  0.99999994 -0.98314625\n",
            "   0.03103268]\n",
            " [ 0.97950673 -0.99999994  1.         ...  0.99999803 -0.9409546\n",
            "   0.19761404]\n",
            " [ 0.68576664 -0.9999998   1.         ...  0.999996   -0.9375181\n",
            "   0.287094  ]], shape=(338, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9576784  -0.99999994  1.         ...  0.9999976  -0.9560257\n",
            "   0.17398596]\n",
            " [ 0.9925689  -0.99999994  1.         ...  0.9999983  -0.9616353\n",
            "   0.24875842]\n",
            " [ 0.98596275 -0.99999994  1.         ...  0.99999845 -0.9843608\n",
            "   0.06946298]\n",
            " ...\n",
            " [ 0.9655198  -0.99999994  1.         ...  0.9999973  -0.94466084\n",
            "   0.33418286]\n",
            " [-0.05568921  0.11312556 -0.379526   ...  0.99999696 -0.9395291\n",
            "   0.25413984]\n",
            " [-0.14714295  0.16580054 -0.36898744 ...  0.99999917 -0.9861441\n",
            "   0.29571068]], shape=(330, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9897443  -0.9999999   1.         ...  0.9999988  -0.9820333\n",
            "   0.15494476]\n",
            " [ 0.9802672  -0.99999994  1.         ...  0.9999995  -0.97623414\n",
            "   0.3463283 ]\n",
            " [ 0.9967675  -0.99999994  1.         ...  0.9999975  -0.9581751\n",
            "   0.13977008]\n",
            " ...\n",
            " [-0.04133582  0.14915024 -0.16917908 ...  1.         -0.9676906\n",
            "   0.21257144]\n",
            " [ 0.20142862 -0.03214322 -0.14883421 ...  1.         -0.9828689\n",
            "   0.2559562 ]\n",
            " [-0.02638803 -0.31047538 -0.02003803 ...  0.9999991  -0.9838089\n",
            "   0.24094272]], shape=(374, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9998639  -0.9999999   1.         ...  0.9999999  -0.98747045\n",
            "  -0.07659743]\n",
            " [ 0.99986845 -0.99999994  1.         ...  0.9999984  -0.9577967\n",
            "   0.14845984]\n",
            " [-0.23747613  0.22041865 -0.2799658  ...  0.9999995  -0.96494716\n",
            "   0.16519834]\n",
            " ...\n",
            " [ 0.1618956   0.03189019 -0.23674099 ...  0.99999917 -0.9849147\n",
            "   0.11401554]\n",
            " [ 0.98595506 -0.99999994  1.         ...  0.99999726 -0.9703858\n",
            "   0.15749836]\n",
            " [ 0.94011253 -0.99999994  1.         ...  1.         -0.9896035\n",
            "   0.06227748]], shape=(394, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999986  -0.99999994  1.         ...  0.99999994 -0.9913809\n",
            "   0.34699506]\n",
            " [ 0.9999588  -0.9999998   1.         ...  0.99999785 -0.95875555\n",
            "   0.19496398]\n",
            " [ 0.9999924  -0.99999994  1.         ...  0.99999815 -0.9664456\n",
            "   0.31516364]\n",
            " ...\n",
            " [-0.31473416  0.10322724 -0.30046326 ...  1.         -0.9850859\n",
            "  -0.02539287]\n",
            " [ 0.922708   -0.99999994  1.         ...  1.         -0.9963798\n",
            "   0.3739879 ]\n",
            " [ 0.154296    0.07617178  0.04959897 ...  0.99999994 -0.9888245\n",
            "  -0.03540912]], shape=(382, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.28025234  0.23514809 -0.48124662 ...  0.99999994 -0.98817927\n",
            "  -0.00732228]\n",
            " [ 0.9999488  -0.99999994  1.         ...  0.99999994 -0.9884994\n",
            "   0.07538987]\n",
            " [ 0.90482086 -0.99999994  1.         ...  0.99999976 -0.9751432\n",
            "   0.1948982 ]\n",
            " ...\n",
            " [-0.48714307  0.48654094 -0.76999605 ...  0.9999998  -0.98157626\n",
            "  -0.05316858]\n",
            " [-0.25902542  0.11998782 -0.6199286  ...  0.99999994 -0.9792543\n",
            "   0.27826163]\n",
            " [-0.20727836  0.19051541 -0.37313908 ...  0.99999994 -0.98284966\n",
            "  -0.04708179]], shape=(399, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.99999994  1.         ...  0.9999996  -0.97753507\n",
            "   0.04391351]\n",
            " [ 0.9999998  -0.99999994  1.         ...  0.9999997  -0.97874326\n",
            "   0.2609318 ]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999964 -0.99166775\n",
            "   0.35665178]\n",
            " ...\n",
            " [-0.02397058  0.09634867 -0.38701612 ...  1.         -0.98530376\n",
            "   0.1167349 ]\n",
            " [ 0.99999124 -0.99999994  1.         ...  0.99999785 -0.9860026\n",
            "   0.27862346]\n",
            " [-0.2215541   0.28891972 -0.580238   ...  0.999999   -0.9860644\n",
            "   0.15118028]], shape=(389, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99999994 -0.99999994  1.         ...  0.99999624 -0.9613768\n",
            "   0.10702066]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.9999989  -0.9846155\n",
            "   0.26255444]\n",
            " [ 0.9999991  -0.9999999   1.         ...  0.99999624 -0.9713403\n",
            "   0.22534892]\n",
            " ...\n",
            " [ 0.9999911  -0.9999999   1.         ...  1.         -0.9899317\n",
            "   0.14165023]\n",
            " [ 0.9999999  -0.99999994  1.         ...  0.9999999  -0.97713506\n",
            "   0.37695792]\n",
            " [-0.40427417  0.03654694 -0.53077143 ...  0.9999998  -0.97962946\n",
            "  -0.08500446]], shape=(344, 128), dtype=float32)\n",
            "batch number:  110 \tgen loss:  5.271228\n",
            "tf.Tensor(\n",
            "[[ 0.9999994  -0.9999999   1.         ...  0.9999998  -0.98465794\n",
            "   0.20419572]\n",
            " [ 0.99947804 -0.9999998   1.         ...  0.9999992  -0.99231833\n",
            "   0.458007  ]\n",
            " [ 0.9745405  -0.9999999   1.         ...  0.9999998  -0.9868752\n",
            "   0.07972933]\n",
            " ...\n",
            " [ 0.9999918  -0.99999994  1.         ...  1.         -0.982256\n",
            "   0.06480215]\n",
            " [-0.12117267  0.3787887  -0.35125497 ...  0.99999976 -0.9858818\n",
            "   0.17231889]\n",
            " [ 0.9999815  -0.99999994  1.         ...  0.99999994 -0.9891758\n",
            "   0.1639833 ]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.45403174  0.402575   -0.6257569  ...  1.         -0.99222845\n",
            "   0.14001405]\n",
            " [ 0.9999978  -0.99999994  1.         ...  0.9999999  -0.98237413\n",
            "   0.04895899]\n",
            " [ 0.9984783  -0.99999994  1.         ...  0.9999999  -0.98823744\n",
            "   0.2242857 ]\n",
            " ...\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999917 -0.9936263\n",
            "   0.23390493]\n",
            " [-0.33343872  0.33440393 -0.49008942 ...  0.9999998  -0.98739326\n",
            "   0.17313504]\n",
            " [-0.54688764  0.4921371  -0.7036144  ...  0.9999998  -0.9908521\n",
            "   0.2657663 ]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.15108243  0.48487875 -0.40552413 ...  0.9999992  -0.99459195\n",
            "   0.01058483]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.9999989  -0.9889723\n",
            "   0.27698404]\n",
            " [-0.2371422   0.42705044 -0.4215068  ...  1.         -0.9969297\n",
            "  -0.00960397]\n",
            " ...\n",
            " [-0.1231839  -0.16392928 -0.36086237 ...  0.99999994 -0.9905788\n",
            "   0.23799747]\n",
            " [ 0.9997052  -0.99999994  1.         ...  0.99999994 -0.98917526\n",
            "   0.14798652]\n",
            " [-0.25156778  0.3071936  -0.48472294 ...  0.9999998  -0.9817217\n",
            "   0.2171669 ]], shape=(301, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.14565274  0.23590724 -0.4493776  ...  0.999999   -0.9953563\n",
            "   0.30150074]\n",
            " [ 0.9285691  -0.9999999   1.         ...  1.         -0.98820865\n",
            "   0.16659264]\n",
            " [ 0.9999947  -0.99999994  1.         ...  0.99999976 -0.98381776\n",
            "  -0.0305797 ]\n",
            " ...\n",
            " [ 1.         -0.99999994  1.         ...  1.         -0.9967603\n",
            "   0.00182868]\n",
            " [ 1.         -0.99999994  1.         ...  0.9999997  -0.98928857\n",
            "   0.03222089]\n",
            " [ 0.99999946 -0.99999994  1.         ...  0.99999994 -0.9902103\n",
            "   0.34086645]], shape=(321, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.20447904  0.26234445 -0.40917292 ...  0.9999997  -0.984691\n",
            "   0.33694252]\n",
            " [ 0.89993703 -0.9999998   1.         ...  0.9999992  -0.9932202\n",
            "   0.22852752]\n",
            " [ 0.20694862  0.30841035 -0.1391583  ...  0.9999993  -0.9859126\n",
            "   0.05701728]\n",
            " ...\n",
            " [-0.2164428   0.32705238 -0.31361514 ...  0.99999726 -0.9810613\n",
            "   0.26744077]\n",
            " [ 0.09735247 -0.9874486   0.99979967 ...  0.9999993  -0.98222166\n",
            "   0.14943089]\n",
            " [ 0.9999993  -0.99999994  1.         ...  0.99999875 -0.9927403\n",
            "   0.10927537]], shape=(407, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.8105877  -0.99999577  1.         ...  0.99999917 -0.9928984\n",
            "   0.07562713]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999972  -0.97651297\n",
            "   0.08428941]\n",
            " [ 1.         -0.99999994  1.         ...  0.99999887 -0.99396807\n",
            "  -0.02419392]\n",
            " ...\n",
            " [-0.2592507   0.2741357  -0.43551162 ...  1.         -0.98996645\n",
            "   0.09564044]\n",
            " [-0.288136    0.18506974 -0.3917617  ...  0.9999999  -0.98721695\n",
            "   0.01794156]\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.9955421\n",
            "   0.23431225]], shape=(363, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9983533  -0.9999999   1.         ...  0.9999999  -0.9956447\n",
            "  -0.03226997]\n",
            " [ 0.9999999  -0.99999994  1.         ...  0.9999971  -0.9813933\n",
            "   0.24589813]\n",
            " [ 1.         -0.99999994  1.         ...  0.99999994 -0.99313706\n",
            "  -0.06554674]\n",
            " ...\n",
            " [-0.53444934  0.38657895 -0.32087067 ...  0.99999964 -0.9930177\n",
            "   0.06229158]\n",
            " [-0.7007934   0.43168217 -0.624958   ...  0.9999998  -0.9881344\n",
            "   0.11685219]\n",
            " [ 0.12695299  0.26358634 -0.2332185  ...  0.99999857 -0.99376136\n",
            "   0.00492335]], shape=(326, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.         -0.99999994  1.         ...  0.99999994 -0.9948161\n",
            "  -0.05957811]\n",
            " [-0.06350833  0.53525    -0.5253629  ...  0.99999905 -0.9948535\n",
            "   0.16689308]\n",
            " [ 1.         -0.99999994  1.         ...  0.9999983  -0.9924388\n",
            "   0.320899  ]\n",
            " ...\n",
            " [-0.36495826  0.24747635 -0.44267902 ...  0.99999833 -0.9801709\n",
            "  -0.02515557]\n",
            " [ 1.         -0.99999994  1.         ...  0.9999999  -0.9941923\n",
            "   0.32729483]\n",
            " [ 0.99983627 -0.9999999   1.         ...  0.9999994  -0.98247284\n",
            "   0.20181324]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.4290643   0.36797848 -0.4808886  ...  0.99999946 -0.98541415\n",
            "   0.37370256]\n",
            " [ 1.         -0.99999994  1.         ...  0.9999995  -0.978204\n",
            "   0.24976029]\n",
            " [ 0.9952823  -0.99999994  1.         ...  0.99999946 -0.9963278\n",
            "   0.3434846 ]\n",
            " ...\n",
            " [ 0.99999994 -0.9999999   1.         ...  0.9999971  -0.9863351\n",
            "   0.33000132]\n",
            " [ 0.99999994 -0.9999999   1.         ...  0.99999946 -0.98094225\n",
            "  -0.05018417]\n",
            " [ 0.99999994 -0.9999999   1.         ...  0.999997   -0.9844099\n",
            "   0.22208093]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.29413238  0.09530367 -0.4473268  ...  0.9999992  -0.9951269\n",
            "  -0.09819539]\n",
            " [-0.27532747  0.10637329 -0.37774968 ...  0.9999973  -0.99198705\n",
            "   0.10624705]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999887 -0.9910357\n",
            "   0.05617971]\n",
            " ...\n",
            " [-0.2674594   0.31615883 -0.33045295 ...  0.9999994  -0.9805496\n",
            "   0.33005285]\n",
            " [-0.65368253  0.44915608 -0.6321823  ...  0.99999523 -0.9630819\n",
            "   0.34654272]\n",
            " [-0.16784525  0.14233264 -0.38305622 ...  0.99999875 -0.9877994\n",
            "   0.21548687]], shape=(410, 128), dtype=float32)\n",
            "batch number:  120 \tgen loss:  5.182746\n",
            "tf.Tensor(\n",
            "[[ 0.99999833 -0.99999994  1.         ...  0.99999994 -0.99275625\n",
            "   0.32530093]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999994 -0.98813385\n",
            "   0.20575991]\n",
            " [ 0.92989564 -0.99999994  1.         ...  0.99999785 -0.99204385\n",
            "   0.1912878 ]\n",
            " ...\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999815 -0.99049383\n",
            "  -0.05400008]\n",
            " [ 0.9029539  -0.99999994  1.         ...  0.9999998  -0.99201083\n",
            "   0.00511264]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999976 -0.9889869\n",
            "   0.3339546 ]], shape=(400, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999263  -0.99999994  1.         ...  0.9999989  -0.9945054\n",
            "   0.0447192 ]\n",
            " [ 0.9563481  -0.99999994  1.         ...  0.999999   -0.99309075\n",
            "   0.17678738]\n",
            " [ 0.8496221  -0.9999999   1.         ...  0.9999976  -0.98682827\n",
            "   0.2893669 ]\n",
            " ...\n",
            " [ 0.999998   -0.99999994  1.         ...  0.9999991  -0.9921254\n",
            "   0.25981563]\n",
            " [-0.24757491  0.3492702  -0.17877153 ...  0.99999994 -0.9948628\n",
            "   0.34298307]\n",
            " [-0.5915855   0.40036553 -0.33050534 ...  0.99999994 -0.99081635\n",
            "  -0.0144679 ]], shape=(374, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999998  -0.9999998   1.         ...  0.99999976 -0.97873855\n",
            "   0.10779421]\n",
            " [ 0.999999   -0.99999994  1.         ...  0.99999964 -0.98400456\n",
            "   0.2647469 ]\n",
            " [ 0.84524584 -0.99999994  1.         ...  0.9999986  -0.98883086\n",
            "   0.0930736 ]\n",
            " ...\n",
            " [ 0.99952173 -0.99999994  1.         ...  0.9999991  -0.9955072\n",
            "   0.10813957]\n",
            " [-0.46413273  0.18993206 -0.37510958 ...  0.9999941  -0.97810864\n",
            "   0.16455384]\n",
            " [ 0.97926146 -0.99999994  1.         ...  0.9999991  -0.99627966\n",
            "   0.05355829]], shape=(346, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5106317   0.42645264 -0.3635654  ...  0.9999931  -0.9754161\n",
            "   0.46469355]\n",
            " [ 0.19511428 -0.99798065  1.         ...  0.9999999  -0.99282104\n",
            "   0.14317608]\n",
            " [-0.39536417  0.02921301  0.8627633  ...  0.99999994 -0.99160355\n",
            "   0.21454437]\n",
            " ...\n",
            " [-0.443765    0.43743822 -0.37310213 ...  1.         -0.9974452\n",
            "   0.24582307]\n",
            " [-0.6447562   0.6111862  -0.5312822  ...  0.99999994 -0.99724346\n",
            "  -0.1275154 ]\n",
            " [-0.5508189   0.331918   -0.47714528 ...  1.         -0.9964911\n",
            "  -0.0930073 ]], shape=(404, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.23265198  0.2170561  -0.2937557  ...  1.         -0.9976976\n",
            "   0.0927073 ]\n",
            " [-0.12197537  0.18787716 -0.3547431  ...  0.9999995  -0.9959985\n",
            "   0.06751639]\n",
            " [-0.4640464   0.40778357 -0.01537722 ...  0.999999   -0.98029995\n",
            "   0.11000918]\n",
            " ...\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999964 -0.99592245\n",
            "   0.2583638 ]\n",
            " [ 0.9999984  -0.99999994  1.         ...  0.99999905 -0.9924779\n",
            "   0.12071169]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.9999999  -0.997773\n",
            "   0.0183533 ]], shape=(394, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.08219504  0.24015456 -0.2398173  ...  0.99999917 -0.9903278\n",
            "   0.05709308]\n",
            " [-0.41782394  0.18417315 -0.33268884 ...  0.9999954  -0.97888654\n",
            "   0.37536836]\n",
            " [-0.6045873   0.4531799  -0.38365468 ...  0.99999934 -0.9868251\n",
            "  -0.1187239 ]\n",
            " ...\n",
            " [-0.46609086  0.36853334 -0.3427438  ...  0.99999994 -0.9911431\n",
            "   0.2174557 ]\n",
            " [-0.2578198   0.19898446 -0.31007764 ...  0.99999994 -0.9889986\n",
            "  -0.00975422]\n",
            " [-0.57283705  0.40496373 -0.64540666 ...  0.99999887 -0.9910597\n",
            "   0.22545716]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.54989725  0.40581548 -0.31415647 ...  0.9999998  -0.9815558\n",
            "   0.09110449]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.99999905 -0.99201345\n",
            "   0.05504537]\n",
            " [ 0.99997896 -0.9999999   1.         ...  0.9999989  -0.9902815\n",
            "   0.02285589]\n",
            " ...\n",
            " [-0.09504873  0.23520744 -0.34563214 ...  0.9999981  -0.9838119\n",
            "   0.11692103]\n",
            " [ 0.99999994 -0.9999999   1.         ...  1.         -0.999433\n",
            "   0.0759419 ]\n",
            " [ 1.         -0.99999994  1.         ...  0.99999905 -0.9915932\n",
            "   0.11535601]], shape=(366, 128), dtype=float32)\n",
            "\n",
            "\n",
            "Adversarial Train:\n",
            "batch number:  0 \t\tgen loss:  3.1795146 \t\t\tdisc loss:  1.2896894\n",
            "batch number:  5 \t\tgen loss:  0.11729052 \t\t\tdisc loss:  0.8156358\n",
            "batch number:  10 \t\tgen loss:  0.39924073 \t\t\tdisc loss:  0.46005756\n",
            "batch number:  15 \t\tgen loss:  1.4435531 \t\t\tdisc loss:  0.5374005\n",
            "batch number:  20 \t\tgen loss:  0.32058588 \t\t\tdisc loss:  0.41193146\n",
            "batch number:  25 \t\tgen loss:  0.03241099 \t\t\tdisc loss:  0.3970946\n",
            "batch number:  30 \t\tgen loss:  0.70311815 \t\t\tdisc loss:  0.3834461\n",
            "batch number:  35 \t\tgen loss:  0.11212504 \t\t\tdisc loss:  0.28908277\n",
            "batch number:  40 \t\tgen loss:  0.092435166 \t\t\tdisc loss:  0.2606105\n",
            "batch number:  45 \t\tgen loss:  0.18754382 \t\t\tdisc loss:  0.26853976\n",
            "batch number:  50 \t\tgen loss:  0.058885187 \t\t\tdisc loss:  0.22428776\n",
            "batch number:  55 \t\tgen loss:  0.050980173 \t\t\tdisc loss:  0.20899364\n",
            "batch number:  60 \t\tgen loss:  0.15541591 \t\t\tdisc loss:  0.19612014\n",
            "\n",
            "\n",
            "Generator Test:\n",
            "batch number:  0 \tgen loss:  9.218946\n",
            "batch number:  5 \tgen loss:  9.203686\n",
            "batch number:  10 \tgen loss:  9.200345\n",
            "batch number:  15 \tgen loss:  9.211445\n",
            "Saved checkpoint for epoch 1: ./tf_ckpts/ckpt-1\n",
            "\n",
            "\n",
            "epoch :  1\n",
            "********************************************* PMF Model Training Turn *********************************************\n",
            "\n",
            "Training RMSE: 6.253608, Test RMSE 1.231195\n",
            "\n",
            "\n",
            "******************************************* Seq2Seq Model Training Turn *******************************************\n",
            "\n",
            "\n",
            "Teacher Forcing Train:\n",
            "tf.Tensor(\n",
            "[[-0.37689388  0.30195406 -0.24786712 ...  0.99999964 -0.9800545\n",
            "   0.04142706]\n",
            " [-0.13612513  0.10975385 -0.07123759 ...  0.99999917 -0.98862964\n",
            "  -0.03556458]\n",
            " [-0.14703931  0.37421978 -0.04873437 ...  0.9999999  -0.98917127\n",
            "  -0.04626697]\n",
            " ...\n",
            " [ 1.         -0.99999994  1.         ...  0.99999994 -0.9940792\n",
            "   0.02578504]\n",
            " [ 0.99977535 -0.99999994  1.         ...  0.99999994 -0.996426\n",
            "   0.05804196]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.9999993  -0.989901\n",
            "   0.14704558]], shape=(385, 128), dtype=float32)\n",
            "batch number:  0 \tgen loss:  8.097166\n",
            "tf.Tensor(\n",
            "[[-0.55471456  0.36892554 -0.5563765  ...  0.9999984  -0.9828894\n",
            "   0.04206243]\n",
            " [-0.40490746  0.19667606 -0.35965773 ...  0.99999994 -0.99243623\n",
            "  -0.12104081]\n",
            " [ 0.99999994 -0.99999994  1.         ...  0.999999   -0.990743\n",
            "   0.19960329]\n",
            " ...\n",
            " [-0.25482967  0.3805513  -0.21623993 ...  0.99999994 -0.9832687\n",
            "  -0.03062541]\n",
            " [-0.2194855   0.0143959  -0.30067104 ...  0.9999989  -0.9785978\n",
            "   0.2432294 ]\n",
            " [-0.09649688  0.23598085 -0.26560125 ...  0.9999984  -0.9862909\n",
            "   0.12542948]], shape=(392, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5302852   0.20758419 -0.62321985 ...  0.9999995  -0.98731965\n",
            "   0.00434079]\n",
            " [-0.6242769   0.46178478 -0.7457545  ...  0.9999999  -0.9892638\n",
            "   0.3438779 ]\n",
            " [-0.5489395   0.508732   -0.53947526 ...  0.9999985  -0.9931802\n",
            "   0.15757738]\n",
            " ...\n",
            " [ 1.         -0.9999999   1.         ...  0.99999994 -0.9847689\n",
            "   0.22747718]\n",
            " [ 0.99998593 -0.9999998   1.         ...  0.99999994 -0.9923384\n",
            "  -0.01141055]\n",
            " [-0.48699865  0.38298377 -0.5265642  ...  1.         -0.99161124\n",
            "   0.36943492]], shape=(341, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.30882555  0.28062928 -0.7234188  ...  0.99999994 -0.9946018\n",
            "   0.32635716]\n",
            " [-0.30852973  0.30777922 -0.72566867 ...  1.         -0.99280804\n",
            "   0.3678153 ]\n",
            " [ 0.5525289  -0.0984292   0.43332505 ...  0.99999994 -0.99235874\n",
            "   0.16695598]\n",
            " ...\n",
            " [ 1.         -0.9999998   1.         ...  1.         -0.97862154\n",
            "   0.44446087]\n",
            " [ 1.         -0.9999999   1.         ...  0.9999991  -0.9893955\n",
            "   0.3729152 ]\n",
            " [-0.40649256  0.21390563 -0.77966374 ...  0.9999999  -0.98849505\n",
            "   0.21508104]], shape=(358, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.71451855  0.5722934  -0.27230957 ...  0.9999989  -0.99391836\n",
            "   0.3278122 ]\n",
            " [-0.8397211   0.6300674  -0.45997065 ...  0.99999523 -0.9917188\n",
            "   0.31209832]\n",
            " [-0.7680268   0.61942875 -0.45730516 ...  0.99999535 -0.9901763\n",
            "   0.50859296]\n",
            " ...\n",
            " [-0.05354004 -0.04422049  0.5316761  ...  1.         -0.99551314\n",
            "   0.34277996]\n",
            " [-0.5051351   0.01796692 -0.3726173  ...  0.99999994 -0.9968609\n",
            "   0.37490463]\n",
            " [-0.3129318   0.20196813 -0.22740485 ...  0.99999994 -0.99412876\n",
            "   0.44410717]], shape=(428, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.7176516   0.6380498  -0.19197084 ...  0.99999964 -0.9986986\n",
            "   0.4977557 ]\n",
            " [-0.87606573  0.84227604 -0.17284134 ...  0.9999989  -0.99872285\n",
            "   0.51681316]\n",
            " [ 0.96323884 -0.99999994  1.         ...  0.99999964 -0.9988366\n",
            "   0.56409717]\n",
            " ...\n",
            " [-0.83788556  0.7532491  -0.09691267 ...  1.         -0.99768627\n",
            "   0.62299395]\n",
            " [-0.8815688   0.7843357   0.12444171 ...  0.9999985  -0.9966479\n",
            "   0.74996513]\n",
            " [-0.5543182   0.5692618  -0.02224871 ...  0.9999984  -0.9981333\n",
            "   0.6611827 ]], shape=(363, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.900246    0.80306554  0.15235007 ...  0.99999976 -0.99940264\n",
            "   0.5881409 ]\n",
            " [ 0.9949825  -1.          1.         ...  0.9999997  -0.9994577\n",
            "   0.81801844]\n",
            " [-0.30693743  0.43906027  0.23271395 ...  0.999999   -0.9995009\n",
            "   0.7200845 ]\n",
            " ...\n",
            " [ 0.99999964 -1.          1.         ...  0.9999973  -0.9991332\n",
            "   0.84743035]\n",
            " [-0.6711488   0.51599205  0.2154672  ...  0.99999905 -0.9995447\n",
            "   0.7282018 ]\n",
            " [ 0.99998873 -1.          1.         ...  0.9999999  -0.9993498\n",
            "   0.7029943 ]], shape=(331, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.984375   -1.          1.         ...  0.9999898  -0.9998303\n",
            "   0.82210034]\n",
            " [-0.78465116  0.7409626   0.30710524 ...  0.99999845 -0.9997349\n",
            "   0.7595797 ]\n",
            " [ 0.99090123 -1.          1.         ...  0.9999987  -0.99977845\n",
            "   0.7840101 ]\n",
            " ...\n",
            " [-0.95514673  0.8770615   0.31546322 ...  0.99999964 -0.9996505\n",
            "   0.8599542 ]\n",
            " [ 0.99999994 -1.          1.         ...  0.99999607 -0.99967337\n",
            "   0.78662765]\n",
            " [ 0.99993116 -1.          1.         ...  0.9999985  -0.99980724\n",
            "   0.87431747]], shape=(339, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.8049952  -1.          1.         ...  0.9999984  -0.9998857\n",
            "   0.85012215]\n",
            " [-0.78913695  0.625144   -0.04543136 ...  0.9999992  -0.9998897\n",
            "   0.8118112 ]\n",
            " [-0.897073    0.8292056   0.20197937 ...  0.99999744 -0.9999166\n",
            "   0.81123626]\n",
            " ...\n",
            " [ 0.14070685 -0.9996952   1.         ...  0.99999917 -0.9998681\n",
            "   0.8633766 ]\n",
            " [-0.9599224   0.91743225  0.15463781 ...  0.99999946 -0.9999222\n",
            "   0.7970957 ]\n",
            " [ 0.98908937 -1.          1.         ...  0.9999983  -0.99988425\n",
            "   0.71360147]], shape=(332, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999999  -1.          1.         ...  0.9999931  -0.9999467\n",
            "   0.94207615]\n",
            " [ 0.99630505 -1.          1.         ...  0.99999696 -0.99994695\n",
            "   0.90412503]\n",
            " [ 0.99999994 -1.          1.         ...  0.9999988  -0.9999501\n",
            "   0.563733  ]\n",
            " ...\n",
            " [ 0.9999526  -1.          1.         ...  0.9999973  -0.9999555\n",
            "   0.85145587]\n",
            " [ 0.99999994 -1.          1.         ...  0.9999981  -0.99995995\n",
            "   0.8270446 ]\n",
            " [-0.6497815   0.8011319   0.2578305  ...  0.99999917 -0.9999371\n",
            "   0.91114897]], shape=(332, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999988  -1.          1.         ...  0.9999905  -0.9999642\n",
            "   0.8598972 ]\n",
            " [ 0.99999696 -1.          1.         ...  0.9999896  -0.99996495\n",
            "   0.95091426]\n",
            " [ 0.9999994  -1.          1.         ...  0.99999166 -0.99997145\n",
            "   0.9512616 ]\n",
            " ...\n",
            " [ 0.9999109  -1.          1.         ...  0.9999954  -0.9999745\n",
            "   0.9336974 ]\n",
            " [ 0.9999846  -1.          1.         ...  0.9999957  -0.999981\n",
            "   0.9657776 ]\n",
            " [ 0.99999624 -1.          1.         ...  0.99999803 -0.99998\n",
            "   0.8697183 ]], shape=(304, 128), dtype=float32)\n",
            "batch number:  10 \tgen loss:  7.5356555\n",
            "tf.Tensor(\n",
            "[[ 0.06094259 -0.99102384  0.9999998  ...  0.99999607 -0.9999888\n",
            "   0.9569529 ]\n",
            " [-0.0966139  -0.04898304 -0.11717493 ...  0.9999932  -0.99999076\n",
            "   0.9629365 ]\n",
            " [ 0.90084153 -1.          1.         ...  0.9999966  -0.99998933\n",
            "   0.9347121 ]\n",
            " ...\n",
            " [ 0.9999229  -1.          1.         ...  1.         -1.\n",
            "   0.97092897]\n",
            " [-0.6475729   0.6381343  -0.08503318 ...  0.99999684 -0.99998903\n",
            "   0.94875765]\n",
            " [-0.94806606  0.40646908 -0.04808253 ...  0.99999505 -0.9999928\n",
            "   0.9531803 ]], shape=(439, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.868569    0.46712568 -0.02857344 ...  0.9999922  -0.99999535\n",
            "   0.96135855]\n",
            " [-0.98803043  0.996005    0.5611174  ...  0.9999968  -0.99999696\n",
            "   0.9661364 ]\n",
            " [-0.95258385  0.973397    0.528362   ...  0.9999964  -0.9999956\n",
            "   0.96192646]\n",
            " ...\n",
            " [-0.423627    0.4026475   0.33966365 ...  0.99998766 -0.99999136\n",
            "   0.93215764]\n",
            " [-0.6545289   0.6443662   0.298252   ...  0.999995   -0.9999953\n",
            "   0.9013194 ]\n",
            " [ 0.866522   -1.          1.         ...  0.99998945 -0.99999666\n",
            "   0.86827046]], shape=(360, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9536407  -1.          1.         ...  0.999998   -0.9999984\n",
            "   0.963312  ]\n",
            " [ 0.99998844 -1.          1.         ...  0.99998885 -0.9999967\n",
            "   0.9062825 ]\n",
            " [-0.4803493  -0.5349593   0.99632674 ...  0.9999965  -0.99999756\n",
            "   0.97189677]\n",
            " ...\n",
            " [-0.9772442   0.9883609   0.6778195  ...  0.9999918  -0.99999535\n",
            "   0.9825224 ]\n",
            " [-0.7438634   0.8779976   0.35893676 ...  0.99999154 -0.999996\n",
            "   0.9563599 ]\n",
            " [ 0.995024   -1.          1.         ...  0.99998724 -0.9999972\n",
            "   0.98470205]], shape=(342, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.99996674 -1.          1.         ...  0.9999923  -0.99999857\n",
            "   0.9758718 ]\n",
            " [ 0.9976015  -1.          1.         ...  0.9999923  -0.99999696\n",
            "   0.89481956]\n",
            " [-0.34760875  0.6733089   0.34566304 ...  0.9999969  -0.99999917\n",
            "   0.9728817 ]\n",
            " ...\n",
            " [-0.44075638  0.21074466 -0.6893948  ...  0.9999977  -0.99999917\n",
            "   0.9725957 ]\n",
            " [-0.9769083   0.974186    0.06614842 ...  0.99999136 -0.99999815\n",
            "   0.97807455]\n",
            " [-0.8938436   0.96076345  0.58582646 ...  0.99999577 -0.9999976\n",
            "   0.71393013]], shape=(347, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9936692   0.9955538  -0.1488212  ...  0.9999948  -0.9999989\n",
            "   0.9381368 ]\n",
            " [-0.9260996   0.66210616  0.2996469  ...  0.99999636 -0.9999995\n",
            "   0.9708139 ]\n",
            " [-0.5771042   0.5716815  -0.43129075 ...  0.999985   -0.9999986\n",
            "   0.94529074]\n",
            " ...\n",
            " [-0.4085479  -0.65053207  0.9997912  ...  0.99998796 -0.99999875\n",
            "   0.9641129 ]\n",
            " [-0.94402546  0.98036903  0.3616856  ...  0.9999972  -0.99999934\n",
            "   0.95947886]\n",
            " [-0.21172503 -0.9996317   1.         ...  0.9999942  -0.99999917\n",
            "   0.9551448 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9980132  -1.          1.         ...  0.999989   -0.9999993\n",
            "   0.97896   ]\n",
            " [ 0.8538309  -1.          1.         ...  0.9999967  -0.9999995\n",
            "   0.9748286 ]\n",
            " [ 0.9315088  -1.          1.         ...  0.99999094 -0.9999992\n",
            "   0.95565414]\n",
            " ...\n",
            " [ 0.6735375  -1.          1.         ...  0.9999887  -0.9999991\n",
            "   0.9448665 ]\n",
            " [ 0.9996809  -1.          1.         ...  0.99998873 -0.99999905\n",
            "   0.9435156 ]\n",
            " [-0.21588778 -0.99978465  1.         ...  0.99999475 -0.99999946\n",
            "   0.98060787]], shape=(382, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9851743   0.9643691   0.74699    ...  0.9999843  -0.99999934\n",
            "   0.9603816 ]\n",
            " [-0.17320403 -0.99999535  1.         ...  0.9999908  -0.99999946\n",
            "   0.9549225 ]\n",
            " [ 0.88983744 -1.          1.         ...  0.99997354 -0.99999946\n",
            "   0.96207666]\n",
            " ...\n",
            " [ 0.98865753 -1.          1.         ...  0.9999926  -0.9999997\n",
            "   0.9781029 ]\n",
            " [ 0.99849343 -1.          1.         ...  0.9999905  -0.9999996\n",
            "   0.86889863]\n",
            " [ 0.91509223 -1.          1.         ...  0.9999838  -0.9999996\n",
            "   0.9696121 ]], shape=(354, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99728215  0.99788404  0.28884524 ...  0.99998266 -0.9999997\n",
            "   0.9728544 ]\n",
            " [-0.5149957   0.4979544  -0.3993861  ...  0.9999963  -0.9999999\n",
            "   0.9726531 ]\n",
            " [-0.92599034  0.4696246  -0.871976   ...  0.99999166 -0.9999998\n",
            "   0.937493  ]\n",
            " ...\n",
            " [-0.35096067  0.8503991   0.15165095 ...  1.         -1.\n",
            "   0.96963036]\n",
            " [ 0.6050546  -1.          1.         ...  0.9999889  -0.99999964\n",
            "   0.98215604]\n",
            " [ 0.9325302  -1.          1.         ...  0.999988   -0.9999996\n",
            "   0.9360353 ]], shape=(353, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.80394226  0.9869925   0.5754868  ...  0.9999926  -0.9999998\n",
            "   0.9484223 ]\n",
            " [-0.72199243  0.8322415   0.6458342  ...  0.99997807 -0.99999964\n",
            "   0.9722288 ]\n",
            " [-0.77479625  0.9204422   0.21950696 ...  0.99999195 -0.9999998\n",
            "   0.9228362 ]\n",
            " ...\n",
            " [ 0.80081415 -1.          1.         ...  0.99997604 -0.99999976\n",
            "   0.9609719 ]\n",
            " [ 0.19600663 -1.          1.         ...  0.9999837  -0.99999976\n",
            "   0.9586816 ]\n",
            " [-0.82617813  0.49986166  0.12569344 ...  1.         -1.\n",
            "   0.9271263 ]], shape=(402, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.68900096 -0.9999998   1.         ...  0.9999863  -0.9999997\n",
            "   0.9617475 ]\n",
            " [ 0.5031137  -1.          1.         ...  0.999997   -0.9999999\n",
            "   0.95415294]\n",
            " [ 0.7663229  -1.          1.         ...  0.9999885  -0.99999976\n",
            "   0.9459998 ]\n",
            " ...\n",
            " [-0.9885852   0.99705386  0.6342774  ...  0.9999908  -0.9999998\n",
            "   0.9652954 ]\n",
            " [ 0.40145433 -1.          0.99999994 ...  0.9999941  -0.9999998\n",
            "   0.95752746]\n",
            " [ 0.8471769  -1.          1.         ...  0.9999797  -0.9999997\n",
            "   0.9682695 ]], shape=(413, 128), dtype=float32)\n",
            "batch number:  20 \tgen loss:  6.130467\n",
            "tf.Tensor(\n",
            "[[ 0.33126524 -1.          1.         ...  0.9999926  -0.99999994\n",
            "   0.9700282 ]\n",
            " [-0.9928194   0.9992784   0.8242154  ...  0.9999943  -0.99999994\n",
            "   0.9504362 ]\n",
            " [-0.6082972  -1.          1.         ...  0.9999862  -0.99999994\n",
            "   0.9693438 ]\n",
            " ...\n",
            " [-0.4044359  -1.          0.99999994 ...  0.99998605 -0.9999998\n",
            "   0.9504239 ]\n",
            " [-0.9841378   0.97445226  0.88035727 ...  0.9999878  -0.9999998\n",
            "   0.94364035]\n",
            " [ 0.4156312  -1.          1.         ...  0.9999855  -0.9999999\n",
            "   0.9803958 ]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.69886786 -1.          1.         ...  0.9999884  -0.9999999\n",
            "   0.9693583 ]\n",
            " [-0.04784239 -1.          0.99999994 ...  0.99997866 -0.9999999\n",
            "   0.9779795 ]\n",
            " [-0.2947379  -1.          1.         ...  0.9999923  -0.99999994\n",
            "   0.9770473 ]\n",
            " ...\n",
            " [ 0.04216185 -1.          1.         ...  0.9999801  -0.9999998\n",
            "   0.9591052 ]\n",
            " [ 0.27772257 -1.          1.         ...  0.9999863  -0.9999999\n",
            "   0.927139  ]\n",
            " [-0.02719835 -1.          1.         ...  0.99998546 -0.9999998\n",
            "   0.96643084]], shape=(365, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9944105   0.9980043   0.85941905 ...  0.99999624 -1.\n",
            "   0.9885782 ]\n",
            " [-0.99520576  0.99982184  0.61478305 ...  0.9999902  -0.99999994\n",
            "   0.99050975]\n",
            " [-0.9981917   0.9991854   0.4469808  ...  0.99998957 -0.99999994\n",
            "   0.9845114 ]\n",
            " ...\n",
            " [ 0.3186983  -1.          0.99999994 ...  0.9999854  -0.99999994\n",
            "   0.9773661 ]\n",
            " [-0.33123797 -1.          1.         ...  0.99999595 -0.99999994\n",
            "   0.9620418 ]\n",
            " [-0.8525255   0.949637    0.34966817 ...  0.99999696 -1.\n",
            "   0.93826425]], shape=(323, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.08591527 -1.          0.99999994 ...  0.99999136 -0.99999994\n",
            "   0.9839183 ]\n",
            " [-0.91720885 -0.99999934  0.99999994 ...  0.9999815  -0.99999994\n",
            "   0.9856094 ]\n",
            " [-0.04469269 -1.          1.         ...  0.9999963  -1.\n",
            "   0.9650721 ]\n",
            " ...\n",
            " [-0.9337689   0.80010754 -0.5771217  ...  0.99999464 -0.99999994\n",
            "   0.96401435]\n",
            " [-0.82091594  0.676745   -0.2632551  ...  0.999991   -0.99999994\n",
            "   0.9302525 ]\n",
            " [-0.7832978   0.52376807  0.05951157 ...  0.99999285 -0.99999994\n",
            "   0.9898333 ]], shape=(424, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9994922   0.99740535 -0.91506153 ...  0.9999917  -0.99999994\n",
            "   0.9534818 ]\n",
            " [-0.99695915  0.9947529  -0.93299586 ...  0.99997944 -0.99999994\n",
            "   0.9834537 ]\n",
            " [-0.5034737   0.5617831  -0.68593794 ...  0.99998075 -0.9999999\n",
            "   0.9783877 ]\n",
            " ...\n",
            " [-0.5126535  -1.          1.         ...  0.99998987 -0.99999994\n",
            "   0.9800989 ]\n",
            " [-0.39501762 -1.          0.99999994 ...  0.9999877  -0.99999994\n",
            "   0.97672   ]\n",
            " [-0.57425493 -1.          0.99999994 ...  0.99998724 -0.99999994\n",
            "   0.9906535 ]], shape=(363, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9931638   0.99931985  0.2302068  ...  0.9999705  -0.99999994\n",
            "   0.9857088 ]\n",
            " [-0.4928454  -0.8192412   0.9986269  ...  0.9999889  -0.99999994\n",
            "   0.9843828 ]\n",
            " [-0.92027694  0.8543609  -0.24877125 ...  0.9999916  -0.99999994\n",
            "   0.95093054]\n",
            " ...\n",
            " [-0.63365495 -1.          0.99999994 ...  0.99998635 -0.99999994\n",
            "   0.97784615]\n",
            " [-0.84638256 -0.9999889   0.99999994 ...  0.99999094 -0.99999994\n",
            "   0.96390057]\n",
            " [-0.7777406  -1.          0.99999994 ...  0.9999866  -0.99999994\n",
            "   0.98454565]], shape=(410, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.6840621  -1.          0.99999994 ...  0.9999757  -0.99999994\n",
            "   0.96834016]\n",
            " [-0.9612498  -0.9999883   0.99999994 ...  0.9999787  -0.99999994\n",
            "   0.98756486]\n",
            " [-0.47638953  0.9210413   0.8098837  ...  0.9999938  -0.99999994\n",
            "   0.9865431 ]\n",
            " ...\n",
            " [-0.9985863   0.9982558  -0.35526675 ...  0.99999166 -1.\n",
            "   0.97773874]\n",
            " [-0.99824166  0.99995905  0.04561644 ...  0.9999922  -1.\n",
            "   0.9723562 ]\n",
            " [-0.99977815  0.9999889  -0.64002556 ...  0.99999094 -1.\n",
            "   0.97566754]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.91740733 -1.          0.99999994 ...  0.99999386 -0.99999994\n",
            "   0.9767529 ]\n",
            " [-0.8016849  -1.          0.99999994 ...  0.99998873 -0.99999994\n",
            "   0.9870936 ]\n",
            " [-0.75764567 -1.          0.99999994 ...  0.9999968  -1.\n",
            "   0.9404619 ]\n",
            " ...\n",
            " [-0.8158395  -1.          0.99999994 ...  0.9999861  -0.99999994\n",
            "   0.9667078 ]\n",
            " [-0.21836288 -1.          0.99999994 ...  0.9999919  -0.99999994\n",
            "   0.95668626]\n",
            " [-0.50633204 -1.          0.99999994 ...  0.9999946  -0.99999994\n",
            "   0.91709095]], shape=(386, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.48098993 -1.          0.99999994 ...  0.9999838  -0.99999994\n",
            "   0.9699785 ]\n",
            " [-0.71037996 -1.          0.99999994 ...  0.999985   -0.99999994\n",
            "   0.99364126]\n",
            " [-0.80007887 -1.          0.99999994 ...  0.9999844  -0.9999999\n",
            "   0.9404205 ]\n",
            " ...\n",
            " [-0.84964406 -1.          0.99999994 ...  0.9999837  -0.99999994\n",
            "   0.98872006]\n",
            " [-0.99864787  0.99970037 -0.62135226 ...  0.9999872  -0.99999994\n",
            "   0.963211  ]\n",
            " [-0.37914297  0.75529194  0.1573461  ...  0.99998695 -0.99999994\n",
            "   0.97117144]], shape=(383, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8317393  -1.          0.99999994 ...  0.9999899  -0.99999994\n",
            "   0.97670084]\n",
            " [-0.9993205   0.9985235  -0.8556792  ...  0.99998164 -0.99999994\n",
            "   0.98582006]\n",
            " [-0.99930626  0.99940735  0.17541996 ...  0.9999869  -0.99999994\n",
            "   0.97171944]\n",
            " ...\n",
            " [-0.9489558  -0.4574811   0.9997405  ...  0.9999866  -0.99999994\n",
            "   0.97408265]\n",
            " [-0.8432605  -1.          0.99999994 ...  0.9999964  -1.\n",
            "   0.97647804]\n",
            " [-0.9437768  -1.          0.99999994 ...  0.99998856 -1.\n",
            "   0.9747583 ]], shape=(376, 128), dtype=float32)\n",
            "batch number:  30 \tgen loss:  6.1939464\n",
            "tf.Tensor(\n",
            "[[-0.55213124 -1.          0.99999994 ...  0.99999475 -1.\n",
            "   0.97074485]\n",
            " [-0.786049   -1.          0.99999994 ...  0.9999976  -1.\n",
            "   0.94801515]\n",
            " [-0.6267297  -1.          0.99999994 ...  0.99998677 -0.99999994\n",
            "   0.97058815]\n",
            " ...\n",
            " [-0.6048398   0.79287183 -0.24006508 ...  0.9999991  -1.\n",
            "   0.9756887 ]\n",
            " [-0.85792303  0.74956    -0.248158   ...  0.99998766 -1.\n",
            "   0.9801254 ]\n",
            " [-0.40431932  0.51614594 -0.0102542  ...  0.9999866  -1.\n",
            "   0.98491603]], shape=(358, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.83877635  0.84625596 -0.76264054 ...  0.99998665 -1.\n",
            "   0.9900533 ]\n",
            " [-0.99850386  0.9974104  -0.92470115 ...  0.9999864  -0.99999994\n",
            "   0.9601209 ]\n",
            " [-0.6621678   0.8689517  -0.05431483 ...  0.9999928  -1.\n",
            "   0.94767165]\n",
            " ...\n",
            " [-0.9988394   0.9996585  -0.79124355 ...  0.99998784 -0.99999994\n",
            "   0.92468464]\n",
            " [-0.74840003  0.7437113   0.2830554  ...  0.99999624 -1.\n",
            "   0.9738763 ]\n",
            " [-0.9996443   0.99995834 -0.767838   ...  0.9999857  -0.99999994\n",
            "   0.970653  ]], shape=(389, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9998608   0.9999743   0.87217224 ...  0.99999475 -1.\n",
            "   0.9812109 ]\n",
            " [-0.8758969   0.7269329  -0.88191915 ...  0.9999785  -1.\n",
            "   0.98555267]\n",
            " [-0.38720998  0.8320681   0.00494062 ...  0.9999854  -0.99999994\n",
            "   0.9509369 ]\n",
            " ...\n",
            " [-0.99963474  0.9999714   0.15744396 ...  0.99999386 -1.\n",
            "   0.98976386]\n",
            " [-0.99988675  0.99932873 -0.7335793  ...  0.9999851  -1.\n",
            "   0.9687472 ]\n",
            " [-0.9983208   0.999743    0.38506225 ...  0.9999846  -1.\n",
            "   0.9829461 ]], shape=(313, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.85207105 -1.          0.99999994 ...  0.999986   -0.99999994\n",
            "   0.9207274 ]\n",
            " [-0.99982464  0.9999932  -0.647333   ...  0.99999005 -1.\n",
            "   0.97554886]\n",
            " [-0.66580325 -1.          0.99999994 ...  0.9999969  -1.\n",
            "   0.9777043 ]\n",
            " ...\n",
            " [-0.91034347 -1.          0.99999994 ...  0.99999124 -1.\n",
            "   0.9890937 ]\n",
            " [-0.9570868  -1.          0.99999994 ...  0.99998856 -1.\n",
            "   0.98211324]\n",
            " [-0.6411699  -1.          0.99999994 ...  0.99997514 -1.\n",
            "   0.98002493]], shape=(380, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.92167807 -1.          0.99999994 ...  0.99999017 -1.\n",
            "   0.9938851 ]\n",
            " [-0.72015524 -1.          0.99999994 ...  0.9999852  -1.\n",
            "   0.92916596]\n",
            " [-0.92363507 -1.          0.99999994 ...  0.99998593 -1.\n",
            "   0.99715793]\n",
            " ...\n",
            " [-0.909747    0.87772214  0.2534343  ...  0.9999883  -1.\n",
            "   0.9700178 ]\n",
            " [-0.2794521   0.92445225  0.6765324  ...  0.99998647 -1.\n",
            "   0.95940256]\n",
            " [-0.99990714  0.99977946 -0.7738374  ...  0.9999933  -1.\n",
            "   0.9773014 ]], shape=(411, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9619797   0.9456833   0.09144042 ...  0.9999909  -1.\n",
            "   0.9887153 ]\n",
            " [-0.66573983  0.2636527  -0.9334162  ...  0.99999756 -1.\n",
            "   0.989096  ]\n",
            " [-0.6287442   0.7926398  -0.906039   ...  0.99998766 -1.\n",
            "   0.98726106]\n",
            " ...\n",
            " [-0.6979917   0.52539295 -0.41808635 ...  0.99999577 -1.\n",
            "   0.96672416]\n",
            " [-0.65235037  0.68485105 -0.8365594  ...  0.9999903  -1.\n",
            "   0.9532598 ]\n",
            " [-0.7169332   0.5393533  -0.88707846 ...  0.99998766 -0.99999994\n",
            "   0.957768  ]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.91107625  0.44602942 -0.9406183  ...  0.9999967  -1.\n",
            "   0.9800988 ]\n",
            " [-0.999829    0.999995    0.35001862 ...  0.99999094 -1.\n",
            "   0.95890665]\n",
            " [-0.9067019  -1.          1.         ...  0.99999386 -1.\n",
            "   0.98465663]\n",
            " ...\n",
            " [-0.88752174 -1.          0.99999994 ...  0.99999326 -1.\n",
            "   0.9836317 ]\n",
            " [-0.8530534  -1.          0.99999994 ...  0.9999935  -1.\n",
            "   0.9562534 ]\n",
            " [-0.90085804 -1.          0.99999994 ...  0.9999922  -1.\n",
            "   0.9923968 ]], shape=(310, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.73490965 -1.          0.99999994 ...  0.9999809  -0.99999994\n",
            "   0.98951036]\n",
            " [-0.98552185  0.9799754   0.72945124 ...  0.9999851  -1.\n",
            "   0.97650677]\n",
            " [-0.9659861  -1.          1.         ...  0.99998957 -1.\n",
            "   0.9893763 ]\n",
            " ...\n",
            " [-0.76360387 -1.          0.99999994 ...  0.99998707 -1.\n",
            "   0.97891253]\n",
            " [-0.550638   -1.          0.99999994 ...  0.99999434 -1.\n",
            "   0.95747936]\n",
            " [-0.98888636  0.976097    0.8134162  ...  0.9999879  -1.\n",
            "   0.99359137]], shape=(394, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.88640857 -1.          0.99999994 ...  0.99998856 -1.\n",
            "   0.99042237]\n",
            " [-0.95922714 -1.          0.99999994 ...  0.99999475 -1.\n",
            "   0.91949546]\n",
            " [-0.23382986 -1.          0.99999994 ...  0.9999927  -1.\n",
            "   0.9746669 ]\n",
            " ...\n",
            " [-0.6119982   0.8255272  -0.3683725  ...  0.99999547 -1.\n",
            "   0.9700509 ]\n",
            " [-0.56987524 -0.9999859   0.99999994 ...  0.9999974  -1.\n",
            "   0.98045254]\n",
            " [-0.9392044  -1.          0.99999994 ...  0.99999243 -1.\n",
            "   0.9907529 ]], shape=(439, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98296314 -1.          0.99999994 ...  0.99999624 -1.\n",
            "   0.9701111 ]\n",
            " [-0.99724627  0.82655144 -0.7592302  ...  0.99998736 -1.\n",
            "   0.9961805 ]\n",
            " [-0.9718163  -0.9569741   0.99972266 ...  0.99998873 -1.\n",
            "   0.980102  ]\n",
            " ...\n",
            " [-0.97239    -0.9999994   1.         ...  0.99999017 -1.\n",
            "   0.98823863]\n",
            " [-0.94742155 -1.          0.99999994 ...  0.99999195 -1.\n",
            "   0.98595023]\n",
            " [-0.98319304 -1.          0.99999994 ...  0.99999446 -1.\n",
            "   0.9748824 ]], shape=(379, 128), dtype=float32)\n",
            "batch number:  40 \tgen loss:  5.995929\n",
            "tf.Tensor(\n",
            "[[-0.8832505   0.80881906  0.8446136  ...  0.99999124 -1.\n",
            "   0.984755  ]\n",
            " [-0.5495641   0.8042427   0.10484    ...  0.99999535 -1.\n",
            "   0.98386925]\n",
            " [-0.98563105  0.96452475  0.1343096  ...  0.99999523 -1.\n",
            "   0.9924179 ]\n",
            " ...\n",
            " [-0.9665392  -1.          1.         ...  0.99998873 -1.\n",
            "   0.9956224 ]\n",
            " [-0.99992216  0.9999264   0.55926913 ...  0.9999884  -1.\n",
            "   0.9792964 ]\n",
            " [-0.7839371   0.84708947  0.40334338 ...  0.9999924  -1.\n",
            "   0.9435897 ]], shape=(272, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98571694  0.98058563  0.713409   ...  0.9999968  -1.\n",
            "   0.9864458 ]\n",
            " [-0.46223798  0.50542957 -0.7537473  ...  0.9999868  -1.\n",
            "   0.98155296]\n",
            " [-0.87196076  0.9742853   0.9380647  ...  0.9999975  -1.\n",
            "   0.9761143 ]\n",
            " ...\n",
            " [-0.8142931   0.8443459  -0.81195474 ...  0.99998915 -1.\n",
            "   0.9761785 ]\n",
            " [-0.85513145 -1.          0.99999994 ...  1.         -1.\n",
            "   0.9866194 ]\n",
            " [-0.9870394  -1.          1.         ...  0.999989   -1.\n",
            "   0.9889949 ]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97273016  0.97693413  0.20384817 ...  0.99999446 -1.\n",
            "   0.9734484 ]\n",
            " [-0.9814412   0.9935476   0.86114514 ...  0.99999505 -1.\n",
            "   0.99252015]\n",
            " [-0.7046727   0.71023315  0.02566699 ...  0.9999973  -1.\n",
            "   0.97789323]\n",
            " ...\n",
            " [-0.97842515  0.98688537  0.9111586  ...  0.9999864  -1.\n",
            "   0.98163056]\n",
            " [-0.99065447  0.9945297   0.86403304 ...  0.9999972  -1.\n",
            "   0.97328836]\n",
            " [-0.9911513   0.9992537   0.65592474 ...  0.9999947  -1.\n",
            "   0.981208  ]], shape=(417, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9635573   0.32914722 -0.9694364  ...  0.9999906  -1.\n",
            "   0.97957766]\n",
            " [-0.9846112  -1.          0.99999994 ...  0.99999523 -1.\n",
            "   0.99237496]\n",
            " [-0.4262405   0.5129392  -0.93612856 ...  0.99999076 -1.\n",
            "   0.9940689 ]\n",
            " ...\n",
            " [-0.99011827 -1.          0.99999994 ...  0.9999887  -1.\n",
            "   0.96664923]\n",
            " [-0.2504715  -1.          0.99999994 ...  0.9999907  -1.\n",
            "   0.98774314]\n",
            " [-0.62845707  0.8001439   0.7186223  ...  0.99999005 -1.\n",
            "   0.9727812 ]], shape=(383, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97954416 -1.          0.99999994 ...  0.99999493 -1.\n",
            "   0.9528443 ]\n",
            " [-0.9596174  -1.          1.         ...  0.99999213 -1.\n",
            "   0.98631436]\n",
            " [-0.9467343  -1.          1.         ...  0.9999961  -1.\n",
            "   0.9944426 ]\n",
            " ...\n",
            " [-0.76229566  0.90054584  0.42326337 ...  0.99998695 -1.\n",
            "   0.9554418 ]\n",
            " [-0.7673977  -1.          0.99999994 ...  0.9999892  -1.\n",
            "   0.9863669 ]\n",
            " [-0.8411621   0.8958493   0.37795243 ...  0.99998647 -1.\n",
            "   0.9680508 ]], shape=(346, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99992025  0.99998176  0.6345386  ...  0.9999931  -1.\n",
            "   0.9850655 ]\n",
            " [-0.99764246  0.9958423  -0.96732944 ...  0.99999726 -1.\n",
            "   0.9926571 ]\n",
            " [-0.6508801   0.856679    0.17876302 ...  0.99999493 -1.\n",
            "   0.987796  ]\n",
            " ...\n",
            " [-0.3495973   0.52737635 -0.15313628 ...  0.9999972  -1.\n",
            "   0.9904237 ]\n",
            " [-0.93993056  0.97440535  0.54650146 ...  0.99999124 -1.\n",
            "   0.9910899 ]\n",
            " [-0.8692191   0.7650841  -0.02145692 ...  0.9999938  -1.\n",
            "   0.96286666]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.7088469   0.9549365   0.57255596 ...  0.9999767  -1.\n",
            "   0.9858487 ]\n",
            " [-0.98809475  0.9771319   0.88521194 ...  0.9999889  -1.\n",
            "   0.9799192 ]\n",
            " [-0.83935964  0.6230135   0.525194   ...  0.99999106 -1.\n",
            "   0.984192  ]\n",
            " ...\n",
            " [-0.63954747  0.7742445  -0.6227713  ...  0.99999124 -1.\n",
            "   0.9603723 ]\n",
            " [-0.23808843  0.7609495   0.13006257 ...  0.99998975 -1.\n",
            "   0.9760484 ]\n",
            " [-0.9454851  -1.          1.         ...  0.99998957 -1.\n",
            "   0.9680586 ]], shape=(446, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9814439  -1.          1.         ...  0.99998707 -1.\n",
            "   0.9806754 ]\n",
            " [-0.9635286   0.9328313  -0.59770006 ...  0.99998605 -1.\n",
            "   0.98892874]\n",
            " [-0.39515874  0.8436047   0.1272908  ...  0.9999937  -1.\n",
            "   0.98000395]\n",
            " ...\n",
            " [-0.97089404 -1.          0.99999994 ...  0.99999225 -1.\n",
            "   0.96883947]\n",
            " [-0.83949524  0.59081566 -0.25493744 ...  0.9999921  -1.\n",
            "   0.9840973 ]\n",
            " [-0.99238193  0.99248314  0.10236435 ...  0.99999905 -1.\n",
            "   0.99398714]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9902687   0.5185914  -0.97473407 ...  0.99999624 -1.\n",
            "   0.97544   ]\n",
            " [-0.9854855  -1.          1.         ...  0.9999957  -1.\n",
            "   0.98029643]\n",
            " [-0.97884405 -1.          1.         ...  0.99998933 -1.\n",
            "   0.98650813]\n",
            " ...\n",
            " [-0.5963691   0.40469941 -0.94546926 ...  0.999987   -1.\n",
            "   0.98597306]\n",
            " [-0.9791047   0.5076631  -0.9525524  ...  0.99999106 -1.\n",
            "   0.9918713 ]\n",
            " [-0.9817368   0.9987626   0.46889138 ...  0.999979   -1.\n",
            "   0.98809886]], shape=(339, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9993297   0.9999067   0.5751098  ...  0.9999887  -1.\n",
            "   0.9942629 ]\n",
            " [-0.9640337   0.992591   -0.51763994 ...  0.9999946  -1.\n",
            "   0.9677213 ]\n",
            " [-0.79389715  0.9517829   0.77441686 ...  0.9999975  -1.\n",
            "   0.9911502 ]\n",
            " ...\n",
            " [-0.9955976   0.9872703   0.83929414 ...  0.99999523 -1.\n",
            "   0.9820388 ]\n",
            " [-0.3177024   0.6756501  -0.73990756 ...  0.9999882  -1.\n",
            "   0.9500263 ]\n",
            " [-0.82226104  0.66166186  0.02800798 ...  0.99999166 -1.\n",
            "   0.9886584 ]], shape=(343, 128), dtype=float32)\n",
            "batch number:  50 \tgen loss:  6.080747\n",
            "tf.Tensor(\n",
            "[[-0.9638614   0.7186367  -0.85796416 ...  0.9999878  -1.\n",
            "   0.9504815 ]\n",
            " [-0.9800348  -1.          1.         ...  0.99998873 -1.\n",
            "   0.9643267 ]\n",
            " [-0.9645711   0.9957431  -0.03931696 ...  0.99998623 -1.\n",
            "   0.9897545 ]\n",
            " ...\n",
            " [-0.99811083  0.99960124 -0.08791177 ...  0.9999926  -1.\n",
            "   0.9884067 ]\n",
            " [-0.9993739   0.9997235  -0.90904284 ...  0.99999875 -1.\n",
            "   0.9888566 ]\n",
            " [-0.98001117  0.9977984   0.49093708 ...  0.9999955  -1.\n",
            "   0.9743066 ]], shape=(395, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9513603  -1.          0.99999994 ...  0.9999971  -1.\n",
            "   0.99569166]\n",
            " [-0.5927998  -1.          0.99999994 ...  0.9999938  -1.\n",
            "   0.98467284]\n",
            " [-0.53482693  0.73668283  0.439269   ...  0.9999829  -1.\n",
            "   0.98669946]\n",
            " ...\n",
            " [-0.8290251   0.9931672   0.8617062  ...  0.99999714 -1.\n",
            "   0.98689824]\n",
            " [-0.91806144  0.9902542   0.8005266  ...  0.99999595 -1.\n",
            "   0.9880006 ]\n",
            " [-0.9975766   0.99967384 -0.5723476  ...  0.9999934  -1.\n",
            "   0.9965998 ]], shape=(406, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.7232476  -1.          0.99999994 ...  0.9999943  -1.\n",
            "   0.969946  ]\n",
            " [-0.9628095   0.92314136 -0.02349641 ...  0.9999843  -1.\n",
            "   0.9940412 ]\n",
            " [-0.9458802  -1.          0.99999994 ...  0.9999947  -1.\n",
            "   0.98918295]\n",
            " ...\n",
            " [-0.84734744 -1.          0.99999994 ...  0.9999969  -1.\n",
            "   0.97888094]\n",
            " [-0.8536782  -1.          0.99999994 ...  0.99999607 -1.\n",
            "   0.99615425]\n",
            " [-0.700233   -1.          0.99999994 ...  0.99999106 -1.\n",
            "   0.9704181 ]], shape=(273, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.857506   -1.          1.         ...  0.99998826 -1.\n",
            "   0.987197  ]\n",
            " [-0.99980366  0.9999516  -0.78767383 ...  0.9999906  -1.\n",
            "   0.96623546]\n",
            " [-0.99962467  0.99996597  0.6908566  ...  0.9999948  -1.\n",
            "   0.9865612 ]\n",
            " ...\n",
            " [-0.8290305   0.6948308  -0.35143498 ...  0.999994   -1.\n",
            "   0.9661651 ]\n",
            " [-0.9459246   0.6488369  -0.25665578 ...  0.99999326 -1.\n",
            "   0.9908715 ]\n",
            " [-0.79920834  0.78902    -0.42280734 ...  0.99999815 -1.\n",
            "   0.99394745]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99989784  0.9999829   0.2759503  ...  0.9999957  -1.\n",
            "   0.98151445]\n",
            " [-0.99983597  0.9999578   0.451124   ...  0.9999871  -1.\n",
            "   0.979849  ]\n",
            " [-0.99953204  0.99972254 -0.14784427 ...  0.9999952  -1.\n",
            "   0.99400294]\n",
            " ...\n",
            " [-0.9303417  -1.          1.         ...  0.99998826 -1.\n",
            "   0.97916347]\n",
            " [-0.988234   -1.          0.99999994 ...  0.9999904  -1.\n",
            "   0.98340625]\n",
            " [-0.86786354 -1.          0.99999994 ...  0.9999847  -1.\n",
            "   0.98283154]], shape=(375, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9855922  -1.          1.         ...  0.99998987 -1.\n",
            "   0.9846222 ]\n",
            " [-0.8335711  -1.          0.99999994 ...  0.99999136 -1.\n",
            "   0.9834227 ]\n",
            " [-0.9999293   0.9999788   0.41166216 ...  0.9999897  -1.\n",
            "   0.98142016]\n",
            " ...\n",
            " [-0.35490233  0.63392794 -0.72197276 ...  0.9999935  -1.\n",
            "   0.9915884 ]\n",
            " [-0.94677967 -1.          1.         ...  0.9999749  -1.\n",
            "   0.98912984]\n",
            " [-0.9996014   0.99951684 -0.8845064  ...  0.9999926  -1.\n",
            "   0.9929532 ]], shape=(422, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97484475 -1.          1.         ...  0.99999213 -1.\n",
            "   0.9786083 ]\n",
            " [-0.96952766 -1.          1.         ...  0.99999845 -1.\n",
            "   0.97033036]\n",
            " [-0.99168336  0.975169    0.86129284 ...  0.9999928  -1.\n",
            "   0.99061227]\n",
            " ...\n",
            " [-0.973019   -1.          0.99999994 ...  0.99999464 -1.\n",
            "   0.974606  ]\n",
            " [-0.9950385   0.5669288  -0.97224426 ...  0.99999106 -1.\n",
            "   0.9051315 ]\n",
            " [-0.426702    0.82247466 -0.18299225 ...  0.99999386 -1.\n",
            "   0.9923163 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99008846 -1.          1.         ...  0.9999974  -1.\n",
            "   0.97153336]\n",
            " [-0.7083098  -1.          0.99999994 ...  0.99999756 -1.\n",
            "   0.963548  ]\n",
            " [-0.8780694  -0.99908227  0.99999994 ...  0.99999666 -1.\n",
            "   0.98126924]\n",
            " ...\n",
            " [-0.89096767 -1.          1.         ...  0.9999927  -1.\n",
            "   0.98690134]\n",
            " [-0.9876945  -1.          1.         ...  0.9999956  -1.\n",
            "   0.9810249 ]\n",
            " [-0.98859143 -1.          1.         ...  0.9999906  -1.\n",
            "   0.95473033]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.88743854 -1.          0.99999994 ...  0.99999356 -1.\n",
            "   0.98491496]\n",
            " [-0.99098754 -1.          0.99999994 ...  0.9999963  -1.\n",
            "   0.97736055]\n",
            " [-0.9883688  -1.          0.99999994 ...  0.9999852  -1.\n",
            "   0.9947775 ]\n",
            " ...\n",
            " [-0.9154018  -1.          1.         ...  0.999996   -1.\n",
            "   0.99519014]\n",
            " [-0.92437226 -1.          1.         ...  0.99999774 -1.\n",
            "   0.9842791 ]\n",
            " [-0.86674416 -1.          1.         ...  1.         -1.\n",
            "   0.9897832 ]], shape=(405, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5242086  -1.          0.99999994 ...  0.9999942  -1.\n",
            "   0.9947963 ]\n",
            " [-0.9630769   0.95374906  0.7443413  ...  0.99998087 -1.\n",
            "   0.99035263]\n",
            " [-0.98913896 -1.          1.         ...  0.9999986  -1.\n",
            "   0.9912298 ]\n",
            " ...\n",
            " [-0.71277714 -1.          0.99999994 ...  0.99999475 -1.\n",
            "   0.9823002 ]\n",
            " [-0.76333994  0.85783094  0.07961222 ...  0.9999968  -1.\n",
            "   0.985692  ]\n",
            " [-0.9937186   0.99663335  0.34930673 ...  0.9999926  -1.\n",
            "   0.98173267]], shape=(398, 128), dtype=float32)\n",
            "batch number:  60 \tgen loss:  6.148316\n",
            "tf.Tensor(\n",
            "[[-0.9987374   0.6827667   0.04437535 ...  0.99999344 -1.\n",
            "   0.9798313 ]\n",
            " [-0.99369365 -1.          0.99999994 ...  0.99998784 -1.\n",
            "   0.9890881 ]\n",
            " [-0.99249136  0.99834603  0.52719057 ...  0.99998844 -1.\n",
            "   0.98676133]\n",
            " ...\n",
            " [-0.73150516  0.87004864  0.53532076 ...  0.999996   -1.\n",
            "   0.9471819 ]\n",
            " [-0.99232036  0.93032914 -0.7710425  ...  0.999992   -1.\n",
            "   0.9886718 ]\n",
            " [-0.96544206  0.81659293  0.2715139  ...  0.9999973  -1.\n",
            "   0.981676  ]], shape=(344, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9857557  -0.9997913   0.99999994 ...  0.99999183 -1.\n",
            "   0.9882097 ]\n",
            " [-0.6696892   0.6608358  -0.6128387  ...  0.99999595 -1.\n",
            "   0.992648  ]\n",
            " [-0.9991872   0.99989605  0.65959865 ...  0.99999094 -1.\n",
            "   0.99231946]\n",
            " ...\n",
            " [-0.99947107  0.99572366  0.75984526 ...  0.9999981  -1.\n",
            "   0.99081725]\n",
            " [-0.94608206  0.8645766  -0.89114547 ...  0.99999136 -1.\n",
            "   0.9811436 ]\n",
            " [-0.99289066  0.6512291  -0.93859667 ...  0.9999981  -1.\n",
            "   0.9892947 ]], shape=(354, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.80456686  0.8299339   0.19508295 ...  0.99999684 -1.\n",
            "   0.97915137]\n",
            " [-0.9204483   0.94261855 -0.08378363 ...  0.99999565 -1.\n",
            "   0.9921291 ]\n",
            " [-0.86568224  0.7009726  -0.5619862  ...  0.99998975 -1.\n",
            "   0.97999376]\n",
            " ...\n",
            " [-0.9355146   0.861414   -0.8674267  ...  0.99999297 -1.\n",
            "   0.9843624 ]\n",
            " [-0.99047637  0.9045508  -0.7554166  ...  0.99999183 -1.\n",
            "   0.9914492 ]\n",
            " [-0.7529171   0.8943742   0.7258356  ...  0.99999756 -1.\n",
            "   0.9909513 ]], shape=(354, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9777079   0.9394785   0.3736891  ...  0.999986   -1.\n",
            "   0.99335   ]\n",
            " [-0.76779145 -1.          0.99999994 ...  0.9999943  -1.\n",
            "   0.9787363 ]\n",
            " [-0.9382695  -1.          1.         ...  0.9999966  -1.\n",
            "   0.9840967 ]\n",
            " ...\n",
            " [-0.984192   -0.30843717  0.9998998  ...  0.9999974  -1.\n",
            "   0.9868856 ]\n",
            " [-0.97237545 -1.          1.         ...  0.9999951  -1.\n",
            "   0.94997054]\n",
            " [-0.9999589   0.99999696  0.85592705 ...  0.99999344 -1.\n",
            "   0.98805493]], shape=(355, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99549437 -0.9644065   0.99999994 ...  0.9999858  -1.\n",
            "   0.9951791 ]\n",
            " [-0.973463    0.9271557   0.56074786 ...  0.99999505 -1.\n",
            "   0.9911174 ]\n",
            " [-0.9678452  -1.          1.         ...  0.9999912  -1.\n",
            "   0.9875923 ]\n",
            " ...\n",
            " [-0.9912901  -1.          1.         ...  0.9999934  -1.\n",
            "   0.9913793 ]\n",
            " [-0.990116   -1.          0.99999994 ...  0.99999493 -1.\n",
            "   0.97792053]\n",
            " [-0.9927706  -1.          1.         ...  0.99998605 -1.\n",
            "   0.9858417 ]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9830332   0.9954225   0.56781304 ...  0.9999979  -1.\n",
            "   0.97749925]\n",
            " [-0.8889683   0.7284988  -0.2467492  ...  1.         -1.\n",
            "   0.9746845 ]\n",
            " [-0.9901683  -1.          1.         ...  0.999995   -1.\n",
            "   0.99231255]\n",
            " ...\n",
            " [-0.9900203   0.95506227  0.85157317 ...  0.9999929  -1.\n",
            "   0.9920776 ]\n",
            " [-0.99847126  0.999672   -0.6746995  ...  0.99999744 -1.\n",
            "   0.9506982 ]\n",
            " [-0.9969692   0.99691904  0.77369833 ...  0.99999297 -1.\n",
            "   0.9878439 ]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9521982  -0.9999988   0.99999994 ...  0.9999962  -1.\n",
            "   0.992155  ]\n",
            " [-0.9708407  -1.          1.         ...  0.9999973  -1.\n",
            "   0.97007155]\n",
            " [-0.94063634 -1.          0.99999994 ...  0.99998915 -1.\n",
            "   0.99180156]\n",
            " ...\n",
            " [-0.9821684  -1.          1.         ...  0.99999887 -1.\n",
            "   0.9813044 ]\n",
            " [-0.99016815 -1.          1.         ...  0.9999957  -1.\n",
            "   0.979909  ]\n",
            " [-0.9847458  -1.          1.         ...  0.99999815 -1.\n",
            "   0.9736357 ]], shape=(356, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.95782256 -1.          0.99999994 ...  0.9999981  -1.\n",
            "   0.99706364]\n",
            " [-0.7690566  -1.          0.99999994 ...  0.99999726 -1.\n",
            "   0.98638576]\n",
            " [-0.6425882   0.7435465   0.4508783  ...  0.99998736 -1.\n",
            "   0.99038893]\n",
            " ...\n",
            " [-0.75131595  0.6632598   0.27003074 ...  0.999987   -1.\n",
            "   0.98968565]\n",
            " [-0.9906705  -0.7617799   0.99943304 ...  0.9999784  -1.\n",
            "   0.99324185]\n",
            " [-0.9924164   0.9947394  -0.9135379  ...  0.99998695 -1.\n",
            "   0.9861095 ]], shape=(423, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.78251714  0.8622198   0.31183895 ...  0.99999785 -1.\n",
            "   0.9898794 ]\n",
            " [-0.8328204  -1.          0.99999994 ...  0.9999904  -1.\n",
            "   0.9881512 ]\n",
            " [-0.82103324 -1.          0.99999994 ...  0.99999726 -1.\n",
            "   0.9879307 ]\n",
            " ...\n",
            " [-0.6573877   0.8080544  -0.75331724 ...  0.99998873 -1.\n",
            "   0.99526966]\n",
            " [-0.8945636   0.8314419  -0.8184518  ...  0.99999875 -1.\n",
            "   0.9826036 ]\n",
            " [-0.999931    0.9999832   0.3152492  ...  0.999986   -1.\n",
            "   0.9898372 ]], shape=(319, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9555988   0.8714704  -0.02826435 ...  0.99999845 -1.\n",
            "   0.9887175 ]\n",
            " [-0.99588376 -1.          1.         ...  0.99999875 -1.\n",
            "   0.98088384]\n",
            " [-0.99975544  0.99997526  0.6285102  ...  0.9999981  -1.\n",
            "   0.98143   ]\n",
            " ...\n",
            " [-0.9976811  -0.91498286  0.99973685 ...  0.9999976  -1.\n",
            "   0.9898996 ]\n",
            " [-0.99090576  0.9957852  -0.8495916  ...  0.9999925  -1.\n",
            "   0.97729665]\n",
            " [-0.9916059  -1.          1.         ...  0.9999954  -1.\n",
            "   0.9827749 ]], shape=(345, 128), dtype=float32)\n",
            "batch number:  70 \tgen loss:  6.0244994\n",
            "tf.Tensor(\n",
            "[[-0.9015011   0.49095348 -0.9450078  ...  0.9999974  -1.\n",
            "   0.988757  ]\n",
            " [-0.97228414  0.70077425  0.15937041 ...  0.99999565 -1.\n",
            "   0.9913373 ]\n",
            " [-0.99039197  0.99027467  0.5890476  ...  0.99999    -1.\n",
            "   0.98475814]\n",
            " ...\n",
            " [-0.9744018  -1.          0.99999994 ...  0.9999962  -1.\n",
            "   0.9903496 ]\n",
            " [-0.9658978  -1.          1.         ...  0.9999978  -1.\n",
            "   0.9753499 ]\n",
            " [-0.7263819  -1.          0.99999994 ...  0.9999949  -1.\n",
            "   0.98224735]], shape=(410, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.71841025 -0.99821514  0.99999994 ...  0.999992   -1.\n",
            "   0.9851752 ]\n",
            " [-0.9885633  -1.          1.         ...  0.999992   -1.\n",
            "   0.987185  ]\n",
            " [-0.9888603  -0.6097286   0.99995375 ...  0.9999918  -1.\n",
            "   0.98943603]\n",
            " ...\n",
            " [-0.99796635  0.99170756 -0.83184975 ...  0.9999992  -1.\n",
            "   0.98386806]\n",
            " [-0.95168513  0.95298046  0.6426249  ...  0.9999972  -1.\n",
            "   0.98277456]\n",
            " [-0.75235116  0.9322804   0.42165548 ...  0.99999636 -1.\n",
            "   0.99041605]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9833668  -1.          0.99999994 ...  0.99999946 -1.\n",
            "   0.98653626]\n",
            " [-0.99954355  0.9997098  -0.87658906 ...  0.9999996  -1.\n",
            "   0.9972632 ]\n",
            " [-0.87736106 -1.          0.99999994 ...  0.999999   -1.\n",
            "   0.9940196 ]\n",
            " ...\n",
            " [-0.8776132   0.91146183  0.65222675 ...  0.9999989  -1.\n",
            "   0.99212724]\n",
            " [-0.9965799  -0.3010418   0.9992009  ...  0.9999988  -1.\n",
            "   0.9821941 ]\n",
            " [-0.99912935  0.9999315   0.7315585  ...  0.99999887 -1.\n",
            "   0.99201876]], shape=(341, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.5988004   0.7424702  -0.50759506 ...  0.99999654 -1.\n",
            "   0.9820433 ]\n",
            " [-0.9996814   0.9999568   0.02875762 ...  0.9999981  -1.\n",
            "   0.98121727]\n",
            " [-0.94414645  0.7717485  -0.00617543 ...  0.99999654 -1.\n",
            "   0.9850677 ]\n",
            " ...\n",
            " [-0.9990964   0.9999418  -0.6193667  ...  0.99999785 -1.\n",
            "   0.9897434 ]\n",
            " [-0.9839573  -1.          0.99999994 ...  0.99999404 -1.\n",
            "   0.9888917 ]\n",
            " [-0.78683305 -1.          0.99999994 ...  0.99998844 -1.\n",
            "   0.9888992 ]], shape=(400, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8184934   0.8480188  -0.06863856 ...  0.99999815 -1.\n",
            "   0.99240255]\n",
            " [-0.9808808  -1.          1.         ...  0.99999183 -1.\n",
            "   0.9752275 ]\n",
            " [-0.80941516  0.8049144  -0.10902356 ...  0.99998534 -1.\n",
            "   0.9729953 ]\n",
            " ...\n",
            " [-0.99741554  0.99819875  0.6560624  ...  0.9999992  -1.\n",
            "   0.9895791 ]\n",
            " [-0.9057369  -1.          0.99999994 ...  0.9999985  -1.\n",
            "   0.98267305]\n",
            " [-0.99857855 -0.5180694   0.99993104 ...  0.9999917  -1.\n",
            "   0.9896694 ]], shape=(365, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.89370745 -1.          0.99999994 ...  0.99999136 -1.\n",
            "   0.9898786 ]\n",
            " [-0.99887735  0.99990046  0.4026337  ...  0.99999607 -1.\n",
            "   0.9958911 ]\n",
            " [-0.9886622  -1.          1.         ...  0.9999801  -1.\n",
            "   0.98518926]\n",
            " ...\n",
            " [-0.98837805  0.9902548   0.90238464 ...  0.99999815 -1.\n",
            "   0.98659295]\n",
            " [-0.708768   -0.99857193  0.99999994 ...  0.9999968  -1.\n",
            "   0.97565687]\n",
            " [-0.66787386  0.4894298  -0.8740794  ...  0.99999535 -1.\n",
            "   0.9775892 ]], shape=(464, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9974973   0.99989533 -0.36279783 ...  0.99999183 -1.\n",
            "   0.9845411 ]\n",
            " [-0.9807253   0.30113    -0.97858304 ...  0.9999926  -1.\n",
            "   0.98529625]\n",
            " [-0.9840543   0.51778173 -0.9388321  ...  0.9999935  -1.\n",
            "   0.99082685]\n",
            " ...\n",
            " [-0.98929745 -1.          1.         ...  0.999995   -1.\n",
            "   0.98934215]\n",
            " [-0.98206025 -1.          1.         ...  0.9999963  -1.\n",
            "   0.98419285]\n",
            " [-0.99272126 -1.          0.99999994 ...  0.99999046 -1.\n",
            "   0.97993207]], shape=(359, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8153504   0.6520801  -0.70220685 ...  0.99999315 -1.\n",
            "   0.9714247 ]\n",
            " [-0.88998014  0.56173164 -0.15280725 ...  0.9999987  -1.\n",
            "   0.98986137]\n",
            " [-0.99976325  0.99940616 -0.8501859  ...  0.99999505 -1.\n",
            "   0.9952581 ]\n",
            " ...\n",
            " [-0.9433264  -1.          0.99999994 ...  0.999995   -1.\n",
            "   0.95663816]\n",
            " [-0.8894159  -1.          0.99999994 ...  0.9999842  -1.\n",
            "   0.9764937 ]\n",
            " [-0.9856431  -1.          1.         ...  0.9999967  -1.\n",
            "   0.99789965]], shape=(370, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9741341   0.99222815  0.36081812 ...  0.9999929  -1.\n",
            "   0.9927433 ]\n",
            " [-0.9460646   0.9613229   0.9191398  ...  0.9999829  -1.\n",
            "   0.9952158 ]\n",
            " [-0.98852515  0.99393976  0.9472068  ...  0.9999941  -1.\n",
            "   0.9839044 ]\n",
            " ...\n",
            " [-0.9949262  -1.          0.99999994 ...  0.9999867  -1.\n",
            "   0.99604785]\n",
            " [-0.9991097   0.999279    0.17267022 ...  0.9999904  -1.\n",
            "   0.9862196 ]\n",
            " [-0.9563739   0.8820079   0.2718775  ...  0.99999356 -1.\n",
            "   0.947879  ]], shape=(348, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9922939  -0.96307504  0.99999994 ...  0.99999416 -1.\n",
            "   0.9825818 ]\n",
            " [-0.95192343  0.8594231  -0.16352628 ...  0.9999954  -1.\n",
            "   0.99293756]\n",
            " [-0.98504806  0.8821102  -0.8748214  ...  0.9999993  -1.\n",
            "   0.98888016]\n",
            " ...\n",
            " [-0.95264685 -0.9999999   0.99999994 ...  0.9999907  -1.\n",
            "   0.98907584]\n",
            " [-0.9780688  -1.          0.99999994 ...  0.9999967  -1.\n",
            "   0.9926115 ]\n",
            " [-0.9692713  -1.          0.99999994 ...  0.9999936  -1.\n",
            "   0.995361  ]], shape=(389, 128), dtype=float32)\n",
            "batch number:  80 \tgen loss:  6.0270905\n",
            "tf.Tensor(\n",
            "[[-0.99389213 -1.          1.         ...  0.99999106 -1.\n",
            "   0.9862252 ]\n",
            " [-0.974916   -1.          0.99999994 ...  0.9999986  -1.\n",
            "   0.9935788 ]\n",
            " [-0.9296883  -1.          0.99999994 ...  0.9999976  -1.\n",
            "   0.99455196]\n",
            " ...\n",
            " [-0.99159896 -1.          1.         ...  0.99999344 -1.\n",
            "   0.9823622 ]\n",
            " [-0.99144995  0.8644111   0.3374972  ...  0.99999774 -1.\n",
            "   0.99406594]\n",
            " [-0.9990659   0.99769425 -0.91616315 ...  0.9999983  -1.\n",
            "   0.99133486]], shape=(416, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.92551005 -0.99999994  0.99999994 ...  0.9999922  -1.\n",
            "   0.98868495]\n",
            " [-0.9839678  -1.          0.99999994 ...  0.99999875 -1.\n",
            "   0.9845007 ]\n",
            " [-0.9509683  -1.          0.99999994 ...  0.999992   -1.\n",
            "   0.99602604]\n",
            " ...\n",
            " [-0.9965345   0.99578285 -0.28008536 ...  0.9999881  -1.\n",
            "   0.9797053 ]\n",
            " [-0.99202853  0.99072146  0.7620977  ...  0.99999684 -1.\n",
            "   0.98238635]\n",
            " [-0.99869144  0.99196607 -0.92236376 ...  0.99999535 -1.\n",
            "   0.99563265]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8313487   0.9778693   0.9580392  ...  0.9999939  -1.\n",
            "   0.9853674 ]\n",
            " [-0.8790701   0.86483175  0.05721834 ...  0.9999953  -1.\n",
            "   0.9855304 ]\n",
            " [-0.98875415  0.9485073   0.6431573  ...  0.9999968  -1.\n",
            "   0.99055463]\n",
            " ...\n",
            " [-0.994813   -1.          0.99999994 ...  0.99999577 -1.\n",
            "   0.9905389 ]\n",
            " [-0.9312293  -1.          0.99999994 ...  0.99999696 -1.\n",
            "   0.9935551 ]\n",
            " [-0.94430816  0.95430213  0.5669526  ...  0.9999957  -1.\n",
            "   0.9895665 ]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99219054 -1.          0.99999994 ...  0.999998   -1.\n",
            "   0.99294585]\n",
            " [-0.95727247 -1.          0.99999994 ...  0.99996716 -1.\n",
            "   0.9966965 ]\n",
            " [-0.7889305  -1.          0.99999994 ...  0.9999863  -1.\n",
            "   0.9956372 ]\n",
            " ...\n",
            " [-0.9389338   0.8203846  -0.2803356  ...  0.99999624 -1.\n",
            "   0.9958099 ]\n",
            " [-0.98267335 -1.          0.99999994 ...  0.9999959  -1.\n",
            "   0.990933  ]\n",
            " [-0.99693185  0.98429585  0.14939854 ...  0.99998826 -1.\n",
            "   0.9940896 ]], shape=(413, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96951884 -0.9976145   0.99999994 ...  0.99999505 -1.\n",
            "   0.99473107]\n",
            " [-0.99902624  0.9959193   0.20758882 ...  0.99999875 -1.\n",
            "   0.99003553]\n",
            " [-0.9949356  -1.          0.99999994 ...  0.9999991  -1.\n",
            "   0.9853545 ]\n",
            " ...\n",
            " [-0.9476362  -1.          1.         ...  0.999997   -1.\n",
            "   0.98862344]\n",
            " [-0.937789   -1.          0.99999994 ...  0.9999972  -1.\n",
            "   0.9863954 ]\n",
            " [-0.975042   -1.          0.99999994 ...  0.99999744 -1.\n",
            "   0.99565196]], shape=(429, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.83896756 -0.99988866  0.99999994 ...  0.9999943  -1.\n",
            "   0.98190063]\n",
            " [-0.98725253 -1.          0.99999994 ...  0.9999997  -1.\n",
            "   0.98988533]\n",
            " [-0.91162556 -0.9496971   0.99999994 ...  0.9999934  -1.\n",
            "   0.9911773 ]\n",
            " ...\n",
            " [-0.9989863   0.99631643 -0.772779   ...  0.99999326 -1.\n",
            "   0.99367803]\n",
            " [-0.97365993 -1.          0.99999994 ...  1.         -1.\n",
            "   0.9920741 ]\n",
            " [-0.99610543 -1.          1.         ...  0.9999908  -1.\n",
            "   0.98816615]], shape=(335, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98734653  0.9804892   0.03709223 ...  0.999995   -1.\n",
            "   0.99605185]\n",
            " [-0.9997787   0.9999822   0.85686296 ...  0.99999845 -1.\n",
            "   0.9825271 ]\n",
            " [-0.9959981  -1.          1.         ...  0.999996   -1.\n",
            "   0.9933482 ]\n",
            " ...\n",
            " [-0.9997825   0.99997526  0.9077003  ...  0.9999991  -1.\n",
            "   0.9961861 ]\n",
            " [-0.6584879   0.41405186  0.03653944 ...  0.99999934 -1.\n",
            "   0.9956309 ]\n",
            " [-0.99547315  0.986934    0.8915179  ...  0.99999905 -1.\n",
            "   0.9901761 ]], shape=(418, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9631614  -1.          0.99999994 ...  0.99999905 -1.\n",
            "   0.9944431 ]\n",
            " [-0.99287456 -1.          0.99999994 ...  0.999994   -1.\n",
            "   0.99117523]\n",
            " [-0.7941906  -1.          0.99999994 ...  0.9999957  -1.\n",
            "   0.9931502 ]\n",
            " ...\n",
            " [-0.9762202  -1.          0.99999994 ...  0.99999887 -1.\n",
            "   0.9662469 ]\n",
            " [-0.8879924  -1.          0.99999994 ...  0.999996   -1.\n",
            "   0.996072  ]\n",
            " [-0.95967704 -1.          0.99999994 ...  0.9999906  -1.\n",
            "   0.9809133 ]], shape=(386, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.91597736 -1.          1.         ...  0.99999475 -1.\n",
            "   0.9786785 ]\n",
            " [-0.99545765 -1.          0.99999994 ...  0.9999918  -1.\n",
            "   0.97814924]\n",
            " [-0.98850185 -1.          1.         ...  0.999976   -1.\n",
            "   0.99657327]\n",
            " ...\n",
            " [-0.97896904 -0.1604862  -0.95171237 ...  0.999987   -1.\n",
            "   0.9945986 ]\n",
            " [-0.99070185  0.94304866 -0.02412417 ...  0.9999997  -1.\n",
            "   0.9891337 ]\n",
            " [-0.8952942  -1.          0.99999994 ...  0.99998707 -1.\n",
            "   0.9114327 ]], shape=(333, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9990095   0.9963479  -0.8721798  ...  0.99999654 -1.\n",
            "   0.98646915]\n",
            " [-0.9998009   0.9996585   0.23543482 ...  0.999996   -1.\n",
            "   0.99617124]\n",
            " [-0.99207574 -1.          0.99999994 ...  0.9999985  -1.\n",
            "   0.98734814]\n",
            " ...\n",
            " [-0.92955273 -1.          0.99999994 ...  0.9999951  -1.\n",
            "   0.9929432 ]\n",
            " [-0.99665684 -1.          0.99999994 ...  0.9999977  -1.\n",
            "   0.99589145]\n",
            " [-0.99328625 -1.          0.99999994 ...  0.999992   -1.\n",
            "   0.99194974]], shape=(344, 128), dtype=float32)\n",
            "batch number:  90 \tgen loss:  5.821007\n",
            "tf.Tensor(\n",
            "[[-0.9767766   0.44339886 -0.90248686 ...  0.9999924  -1.\n",
            "   0.98793685]\n",
            " [-0.99973524  0.99987733  0.96255374 ...  0.999997   -1.\n",
            "   0.99822766]\n",
            " [-0.9741811   0.99568725  0.99939835 ...  0.9999988  -1.\n",
            "   0.9838777 ]\n",
            " ...\n",
            " [-0.97415537 -1.          0.99999994 ...  0.99999756 -1.\n",
            "   0.99158895]\n",
            " [-0.9998279   0.99994695  0.46545982 ...  0.9999985  -1.\n",
            "   0.9926615 ]\n",
            " [-0.9304415  -1.          0.99999994 ...  0.9999945  -1.\n",
            "   0.97511935]], shape=(436, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.95103574  0.9581721   0.85686886 ...  0.9999995  -1.\n",
            "   0.9946931 ]\n",
            " [-0.9441761   0.9500925   0.68212473 ...  0.99999344 -1.\n",
            "   0.98764265]\n",
            " [-0.83355993  0.54093194 -0.01698195 ...  0.9999993  -1.\n",
            "   0.99431425]\n",
            " ...\n",
            " [-0.99593836 -1.          0.99999994 ...  0.99999684 -1.\n",
            "   0.9848938 ]\n",
            " [-0.9853417   0.9984161   0.8667412  ...  0.9999961  -1.\n",
            "   0.9896335 ]\n",
            " [-0.8516406  -1.          0.99999994 ...  0.9999953  -1.\n",
            "   0.9941349 ]], shape=(390, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99991375  0.99995583  0.43193555 ...  0.9999949  -1.\n",
            "   0.99340075]\n",
            " [-0.9998766   0.99947107 -0.37579107 ...  0.9999946  -1.\n",
            "   0.9694148 ]\n",
            " [-0.9926603  -1.          0.99999994 ...  0.99999905 -1.\n",
            "   0.98666686]\n",
            " ...\n",
            " [-0.96157193  0.9384831   0.69274205 ...  0.99999547 -1.\n",
            "   0.9966929 ]\n",
            " [-0.9073017  -1.          1.         ...  0.9999931  -1.\n",
            "   0.9916992 ]\n",
            " [-0.993095   -1.          1.         ...  0.99999344 -1.\n",
            "   0.98909307]], shape=(394, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9856327  -1.          0.99999994 ...  0.9999941  -1.\n",
            "   0.9916504 ]\n",
            " [-0.9635495  -1.          0.99999994 ...  0.9999918  -1.\n",
            "   0.9231188 ]\n",
            " [-0.95138365 -1.          0.99999994 ...  0.99999815 -1.\n",
            "   0.98377824]\n",
            " ...\n",
            " [-0.9984912   0.99922454 -0.8130042  ...  0.99999875 -1.\n",
            "   0.99678844]\n",
            " [-0.97162133  0.5332927  -0.9484084  ...  0.9999972  -1.\n",
            "   0.9882785 ]\n",
            " [-0.98790056  0.8781562  -0.7020193  ...  0.9999996  -1.\n",
            "   0.9930309 ]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99977034  0.99996924 -0.19071582 ...  0.9999986  -1.\n",
            "   0.9936177 ]\n",
            " [-0.93273926  0.4316382  -0.05574506 ...  0.99999934 -1.\n",
            "   0.9906154 ]\n",
            " [-0.9983633   0.9955919   0.6824112  ...  1.         -1.\n",
            "   0.9746139 ]\n",
            " ...\n",
            " [-0.8036408  -1.          0.99999994 ...  0.999997   -1.\n",
            "   0.9936392 ]\n",
            " [-0.94719386 -1.          0.99999994 ...  0.99999356 -1.\n",
            "   0.99512887]\n",
            " [-0.8814183  -0.99999094  0.99999994 ...  0.9999964  -1.\n",
            "   0.99107385]], shape=(370, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9823796  -1.          1.         ...  0.9999973  -1.\n",
            "   0.94437534]\n",
            " [-0.99310404  0.6853909  -0.934983   ...  0.99999243 -1.\n",
            "   0.9831718 ]\n",
            " [-0.9927987  -1.          0.99999994 ...  0.9999985  -1.\n",
            "   0.98982304]\n",
            " ...\n",
            " [-0.99564904 -1.          1.         ...  0.9999941  -1.\n",
            "   0.9929595 ]\n",
            " [-0.9742617  -1.          0.99999994 ...  0.99999994 -1.\n",
            "   0.9930124 ]\n",
            " [-0.9860462   0.6839545  -0.88388824 ...  0.9999967  -1.\n",
            "   0.99643975]], shape=(364, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9321451  -0.2155269  -0.88159794 ...  0.9999962  -1.\n",
            "   0.9943289 ]\n",
            " [-0.9992738  -0.9999922   1.         ...  0.9999967  -1.\n",
            "   0.99636024]\n",
            " [-0.9572912  -1.          0.99999994 ...  0.9999933  -1.\n",
            "   0.9945834 ]\n",
            " ...\n",
            " [-0.9957154  -1.          0.99999994 ...  0.99999565 -1.\n",
            "   0.98742676]\n",
            " [-0.9508253  -1.          0.99999994 ...  0.99998415 -1.\n",
            "   0.98704696]\n",
            " [-0.9778745  -1.          0.99999994 ...  0.9999897  -1.\n",
            "   0.9836048 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98117846 -1.          0.99999994 ...  0.99999964 -1.\n",
            "   0.9924312 ]\n",
            " [-0.99914396  0.9999519   0.8613654  ...  0.9999956  -1.\n",
            "   0.9947977 ]\n",
            " [-0.97428817 -1.          1.         ...  0.9999898  -1.\n",
            "   0.99471474]\n",
            " ...\n",
            " [-0.9303045  -1.          0.99999994 ...  0.999996   -1.\n",
            "   0.97577226]\n",
            " [-0.9853935   0.67643476  0.01029825 ...  0.99999946 -1.\n",
            "   0.99004626]\n",
            " [-0.99971604  0.99999195  0.64440995 ...  0.9999988  -1.\n",
            "   0.9901188 ]], shape=(364, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97109973  0.7113073  -0.90717006 ...  0.9999868  -1.\n",
            "   0.987834  ]\n",
            " [-0.96209055 -1.          0.99999994 ...  0.9999964  -1.\n",
            "   0.9931977 ]\n",
            " [-0.97744864  0.81702524  0.03148833 ...  0.99999607 -1.\n",
            "   0.98976606]\n",
            " ...\n",
            " [-0.9705718  -1.          0.99999994 ...  0.9999991  -1.\n",
            "   0.9914722 ]\n",
            " [-0.93608016 -1.          0.99999994 ...  0.99999624 -1.\n",
            "   0.98865825]\n",
            " [-0.99662256 -1.          0.99999994 ...  0.9999941  -1.\n",
            "   0.9915552 ]], shape=(437, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9810754  -1.          0.99999994 ...  0.9999996  -1.\n",
            "   0.97411686]\n",
            " [-0.9940066  -1.          1.         ...  0.9999987  -1.\n",
            "   0.99010223]\n",
            " [-0.9468704   0.7920221   0.18601279 ...  0.9999978  -1.\n",
            "   0.9898306 ]\n",
            " ...\n",
            " [-0.94878227 -1.          0.99999994 ...  0.9999997  -1.\n",
            "   0.9768974 ]\n",
            " [-0.9749342  -1.          0.99999994 ...  0.9999941  -1.\n",
            "   0.9914758 ]\n",
            " [-0.988776    0.60896486 -0.9204863  ...  0.99998903 -1.\n",
            "   0.99122614]], shape=(395, 128), dtype=float32)\n",
            "batch number:  100 \tgen loss:  5.8909774\n",
            "tf.Tensor(\n",
            "[[-0.899782   -1.          1.         ...  0.9999949  -1.\n",
            "   0.9638976 ]\n",
            " [-0.99794674  0.9994626   0.13279925 ...  0.99997914 -1.\n",
            "   0.9820655 ]\n",
            " [-0.9979465   0.99946254  0.13274367 ...  0.99997914 -1.\n",
            "   0.982032  ]\n",
            " ...\n",
            " [-0.9998211   0.9999766   0.40991032 ...  0.9999976  -1.\n",
            "   0.98960036]\n",
            " [-0.9934809   0.9721892   0.6563674  ...  0.99999917 -1.\n",
            "   0.99238753]\n",
            " [-0.9999191   0.99998367  0.6858292  ...  0.9999961  -1.\n",
            "   0.9866875 ]], shape=(356, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9866643  -1.          0.99999994 ...  0.9999974  -1.\n",
            "   0.98835915]\n",
            " [-0.98477274 -1.          0.99999994 ...  0.99999356 -1.\n",
            "   0.99103177]\n",
            " [-0.9528878  -0.999991    0.99999994 ...  0.9999983  -1.\n",
            "   0.99399745]\n",
            " ...\n",
            " [-0.9866973  -0.99977607  0.99999994 ...  0.9999948  -1.\n",
            "   0.9909946 ]\n",
            " [-0.9782848  -1.          0.99999994 ...  0.9999965  -1.\n",
            "   0.99083334]\n",
            " [-0.9717253   0.9930375   0.6386406  ...  1.         -1.\n",
            "   0.99585944]], shape=(393, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99321777 -1.          1.         ...  0.9999989  -1.\n",
            "   0.68723494]\n",
            " [-0.98783654  0.9917198  -0.55846506 ...  0.9999945  -1.\n",
            "   0.9960912 ]\n",
            " [-0.93178344 -1.          0.99999994 ...  0.99999493 -1.\n",
            "   0.99463886]\n",
            " ...\n",
            " [-0.964499    0.9764024   0.7658051  ...  1.         -1.\n",
            "   0.99417883]\n",
            " [-0.9980424   0.99651074  0.6699994  ...  0.9999992  -1.\n",
            "   0.9894221 ]\n",
            " [-0.94284433 -0.5513318   0.99941283 ...  0.99999976 -1.\n",
            "   0.98964214]], shape=(338, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.7671123   0.87849206  0.49625722 ...  0.99999946 -1.\n",
            "   0.987342  ]\n",
            " [-0.9956133   0.9796277   0.74985933 ...  0.9999972  -1.\n",
            "   0.99199796]\n",
            " [-0.963104    0.9961865   0.61824435 ...  0.9999995  -1.\n",
            "   0.9964413 ]\n",
            " ...\n",
            " [-0.99387574 -1.          0.99999994 ...  0.99999666 -1.\n",
            "   0.9938528 ]\n",
            " [-0.999591    0.9997109   0.3510474  ...  0.9999987  -1.\n",
            "   0.9904786 ]\n",
            " [-0.7838667  -1.          0.99999994 ...  0.99999887 -1.\n",
            "   0.74568456]], shape=(378, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9988669  -1.          1.         ...  0.9999961  -1.\n",
            "   0.9838834 ]\n",
            " [-0.99514294 -1.          1.         ...  0.9999971  -1.\n",
            "   0.9820906 ]\n",
            " [-0.996901   -1.          1.         ...  0.999995   -1.\n",
            "   0.9802636 ]\n",
            " ...\n",
            " [-0.9959592   0.84473544 -0.8527493  ...  0.9999966  -1.\n",
            "   0.99435115]\n",
            " [-0.9988889   0.999828    0.678836   ...  0.99999714 -1.\n",
            "   0.99039394]\n",
            " [-0.9567093  -1.          0.99999994 ...  0.999998   -1.\n",
            "   0.991457  ]], shape=(337, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9998238   0.9993793  -0.82887465 ...  0.9999986  -1.\n",
            "   0.9947826 ]\n",
            " [-0.99214715  0.8609405   0.01262291 ...  0.9999964  -1.\n",
            "   0.9934049 ]\n",
            " [-0.9587749   0.63132817 -0.90254986 ...  0.999998   -1.\n",
            "   0.98716116]\n",
            " ...\n",
            " [-0.9977101  -0.99997354  0.99999994 ...  0.99999046 -1.\n",
            "   0.9918126 ]\n",
            " [-0.99273896  0.9668673   0.7192424  ...  0.99999887 -1.\n",
            "   0.985935  ]\n",
            " [-0.9677852   0.98169297 -0.5037606  ...  0.9999934  -1.\n",
            "   0.9885144 ]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9948396  -1.          1.         ...  0.9999994  -1.\n",
            "   0.98833656]\n",
            " [-0.98281133 -1.          1.         ...  0.99999946 -1.\n",
            "   0.96380746]\n",
            " [-0.9727224  -1.          0.99999994 ...  0.9999966  -1.\n",
            "   0.991018  ]\n",
            " ...\n",
            " [-0.9385968   0.98478085  0.9979394  ...  0.9999992  -1.\n",
            "   0.9964297 ]\n",
            " [-0.9841407  -0.89787036  0.99999994 ...  0.9999911  -1.\n",
            "   0.9962824 ]\n",
            " [-0.982815    0.9925156   0.5469582  ...  0.9999927  -1.\n",
            "   0.9957028 ]], shape=(435, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99342775 -1.          0.99999994 ...  0.9999987  -1.\n",
            "   0.99595827]\n",
            " [-0.84328574  0.8522653   0.34301773 ...  0.9999993  -1.\n",
            "   0.992336  ]\n",
            " [-0.96404713 -1.          1.         ...  0.9999995  -1.\n",
            "   0.99377286]\n",
            " ...\n",
            " [-0.8602443  -0.99996555  0.99999994 ...  0.9999952  -1.\n",
            "   0.9858459 ]\n",
            " [-0.99978     0.99995434  0.82208925 ...  0.9999909  -1.\n",
            "   0.99827665]\n",
            " [-0.9485155   0.74532825  0.0969359  ...  0.9999951  -1.\n",
            "   0.990498  ]], shape=(408, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99666953  0.9738883   0.6088816  ...  0.9999969  -1.\n",
            "   0.99309117]\n",
            " [-0.945273   -0.99997777  0.99999994 ...  0.9999959  -1.\n",
            "   0.98946434]\n",
            " [-0.995985   -1.          1.         ...  0.99999946 -1.\n",
            "   0.98823905]\n",
            " ...\n",
            " [-0.97506493  0.48489845 -0.9634594  ...  0.99999464 -1.\n",
            "   0.99543214]\n",
            " [-0.9404697  -1.          0.99999994 ...  0.9999984  -1.\n",
            "   0.9936606 ]\n",
            " [-0.99932283  0.9995617   0.06572025 ...  0.99999833 -1.\n",
            "   0.990491  ]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9890333   0.60719216 -0.23056133 ...  0.9999976  -1.\n",
            "   0.9967471 ]\n",
            " [-0.9986664   0.9998202   0.6409172  ...  0.9999959  -1.\n",
            "   0.9946486 ]\n",
            " [-0.9736744  -0.991444    0.99999994 ...  0.9999991  -1.\n",
            "   0.9890126 ]\n",
            " ...\n",
            " [-0.99719805  0.5579972  -0.93947387 ...  0.9999983  -1.\n",
            "   0.98945916]\n",
            " [-0.9913842  -1.          1.         ...  0.9999856  -1.\n",
            "   0.99229854]\n",
            " [-0.993558   -1.          1.         ...  0.99999756 -1.\n",
            "   0.9949257 ]], shape=(360, 128), dtype=float32)\n",
            "batch number:  110 \tgen loss:  5.863479\n",
            "tf.Tensor(\n",
            "[[-0.9381855  -1.          0.99999994 ...  0.9999964  -1.\n",
            "   0.98946905]\n",
            " [-0.99323785 -1.          0.99999994 ...  0.9999986  -1.\n",
            "   0.9944789 ]\n",
            " [-0.9852412  -1.          0.99999994 ...  0.9999979  -1.\n",
            "   0.9932087 ]\n",
            " ...\n",
            " [-0.91017145 -1.          0.99999994 ...  0.9999992  -1.\n",
            "   0.98472726]\n",
            " [-0.98794556 -1.          0.99999994 ...  0.99999833 -1.\n",
            "   0.9800268 ]\n",
            " [-0.99994504  0.9999834  -0.2709958  ...  0.9999993  -1.\n",
            "   0.9886156 ]], shape=(335, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.7973729   0.72776306  0.27418387 ...  0.9999998  -1.\n",
            "   0.9852868 ]\n",
            " [-0.9929158  -1.          1.         ...  0.9999992  -1.\n",
            "   0.989204  ]\n",
            " [-0.9928924  -1.          0.99999994 ...  0.9999967  -1.\n",
            "   0.99615633]\n",
            " ...\n",
            " [-0.99492466 -1.          0.99999994 ...  0.99999404 -1.\n",
            "   0.99230164]\n",
            " [-0.9909273  -1.          0.99999994 ...  0.9999971  -1.\n",
            "   0.9946588 ]\n",
            " [-0.90656656 -1.          0.99999994 ...  0.99999416 -1.\n",
            "   0.99249125]], shape=(381, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9877587  -1.          0.99999994 ...  0.9999968  -1.\n",
            "   0.9867187 ]\n",
            " [-0.95901394 -1.          1.         ...  1.         -1.\n",
            "   0.98899454]\n",
            " [-0.96660775 -1.          0.99999994 ...  0.9999973  -1.\n",
            "   0.97779465]\n",
            " ...\n",
            " [-0.974127   -1.          1.         ...  0.9999984  -1.\n",
            "   0.98686963]\n",
            " [-0.9962646  -1.          1.         ...  0.999993   -1.\n",
            "   0.3837731 ]\n",
            " [-0.99618924 -1.          1.         ...  0.9999982  -1.\n",
            "   0.99247855]], shape=(362, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9763226  -1.          1.         ...  0.99999815 -1.\n",
            "   0.98200047]\n",
            " [-0.9812421  -1.          1.         ...  0.9999991  -1.\n",
            "   0.98953015]\n",
            " [-0.9677262  -1.          1.         ...  0.99999785 -1.\n",
            "   0.99330986]\n",
            " ...\n",
            " [-0.9931188  -1.          0.99999994 ...  0.9999987  -1.\n",
            "   0.99604636]\n",
            " [-0.96425116 -1.          1.         ...  0.99999505 -1.\n",
            "   0.98955876]\n",
            " [-0.9246475   0.7244428   0.41764173 ...  0.99999684 -1.\n",
            "   0.99345624]], shape=(324, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9828336  -0.4430589   0.99979025 ...  0.99999726 -1.\n",
            "   0.9854228 ]\n",
            " [-0.980067    0.8606289   0.22783718 ...  0.9999941  -1.\n",
            "   0.9899528 ]\n",
            " [-0.9940907  -1.          0.99999994 ...  0.9999982  -1.\n",
            "   0.9978754 ]\n",
            " ...\n",
            " [-0.9814657   0.99755937  0.6074762  ...  0.9999992  -1.\n",
            "   0.99553543]\n",
            " [-0.9866887   0.699481   -0.8987625  ...  0.999997   -1.\n",
            "   0.99711347]\n",
            " [-0.9977739   0.99269485  0.83582956 ...  0.9999983  -1.\n",
            "   0.9931381 ]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.87232125 -1.          1.         ...  0.9999966  -1.\n",
            "   0.9615875 ]\n",
            " [-0.99590534 -1.          1.         ...  0.99999464 -1.\n",
            "   0.89872354]\n",
            " [-0.98619103 -1.          1.         ...  0.9999998  -1.\n",
            "   0.99057734]\n",
            " ...\n",
            " [-0.98816264 -1.          1.         ...  0.9999945  -1.\n",
            "   0.9819467 ]\n",
            " [-0.9880777  -1.          1.         ...  0.9999947  -1.\n",
            "   0.9884745 ]\n",
            " [-0.9881481  -1.          1.         ...  0.9999915  -1.\n",
            "   0.98617303]], shape=(321, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99978787  0.9984118  -0.75526065 ...  0.9999964  -1.\n",
            "   0.9963532 ]\n",
            " [-0.9805809  -1.          1.         ...  0.99999994 -1.\n",
            "   0.9954487 ]\n",
            " [-0.9960639  -1.          1.         ...  0.99999934 -1.\n",
            "   0.9928592 ]\n",
            " ...\n",
            " [-0.9947508  -1.          1.         ...  0.999998   -1.\n",
            "   0.9879484 ]\n",
            " [-0.9957421  -1.          1.         ...  0.999992   -1.\n",
            "   0.99310714]\n",
            " [-0.99608344 -1.          1.         ...  0.99999046 -1.\n",
            "   0.9607321 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9950639  -1.          1.         ...  0.9999983  -1.\n",
            "   0.99455017]\n",
            " [-0.9772266  -0.8807597   0.99999994 ...  0.99999845 -1.\n",
            "   0.9924821 ]\n",
            " [-0.97206706 -1.          1.         ...  0.9999977  -1.\n",
            "   0.98555887]\n",
            " ...\n",
            " [-0.9951385  -1.          1.         ...  0.99999803 -1.\n",
            "   0.9914949 ]\n",
            " [-0.98809737 -1.          1.         ...  0.9999993  -1.\n",
            "   0.9877801 ]\n",
            " [-0.99570197 -1.          1.         ...  0.9999972  -1.\n",
            "   0.98866874]], shape=(388, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99033403 -1.          1.         ...  0.9999984  -1.\n",
            "   0.99622196]\n",
            " [-0.99541986 -1.          1.         ...  0.9999962  -1.\n",
            "   0.983789  ]\n",
            " [-0.85769147  0.80186903  0.08540771 ...  0.99999964 -1.\n",
            "   0.9958743 ]\n",
            " ...\n",
            " [-0.99256647 -1.          1.         ...  0.99999154 -1.\n",
            "   0.99295527]\n",
            " [-0.99295384 -1.          1.         ...  0.99999154 -1.\n",
            "   0.9929425 ]\n",
            " [-0.97762096  0.9239409   0.30759627 ...  0.9999825  -1.\n",
            "   0.99356204]], shape=(364, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97430867 -1.          1.         ...  0.99999774 -1.\n",
            "   0.9863213 ]\n",
            " [-0.9874877  -1.          1.         ...  0.9999941  -1.\n",
            "   0.9909532 ]\n",
            " [-0.9349792  -1.          1.         ...  0.9999996  -1.\n",
            "   0.99446964]\n",
            " ...\n",
            " [-0.99624527 -1.          1.         ...  0.9999971  -1.\n",
            "   0.9458614 ]\n",
            " [-0.9961057  -1.          1.         ...  0.9999973  -1.\n",
            "   0.9680159 ]\n",
            " [-0.99552894 -1.          1.         ...  0.9999973  -1.\n",
            "   0.99091315]], shape=(336, 128), dtype=float32)\n",
            "batch number:  120 \tgen loss:  6.0408735\n",
            "tf.Tensor(\n",
            "[[-0.9950891   0.95759606  0.10629316 ...  0.99999726 -1.\n",
            "   0.9725104 ]\n",
            " [-0.9205612   0.878586    0.70711696 ...  0.99999654 -1.\n",
            "   0.9949193 ]\n",
            " [-0.99984604  0.9999856  -0.5980335  ...  0.9999956  -1.\n",
            "   0.9884536 ]\n",
            " ...\n",
            " [-0.9618011  -1.          1.         ...  0.999999   -1.\n",
            "   0.98552793]\n",
            " [-0.95966876 -0.99192023  0.99999994 ...  0.99999684 -1.\n",
            "   0.9963859 ]\n",
            " [-0.9762789  -1.          0.99999994 ...  0.9999971  -1.\n",
            "   0.9955124 ]], shape=(433, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9994051   0.99933094 -0.31849283 ...  0.999994   -1.\n",
            "   0.9890685 ]\n",
            " [-0.9315139   0.9759621   0.8206857  ...  0.999993   -1.\n",
            "   0.9846052 ]\n",
            " [-0.99686646  0.9997179   0.908831   ...  0.9999989  -1.\n",
            "   0.9877367 ]\n",
            " ...\n",
            " [-0.9384275  -1.          1.         ...  0.99999934 -1.\n",
            "   0.99355304]\n",
            " [-0.9987091   0.9921546   0.9726716  ...  0.9999994  -1.\n",
            "   0.9947771 ]\n",
            " [-0.9999318   0.9999813  -0.07365406 ...  0.99999785 -1.\n",
            "   0.9851076 ]], shape=(360, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9773387   0.8638662   0.11555354 ...  0.99999845 -1.\n",
            "   0.9964265 ]\n",
            " [-0.9749307   0.7484642  -0.31535143 ...  0.9999977  -1.\n",
            "   0.988241  ]\n",
            " [-0.99550414 -0.9999998   1.         ...  0.9999983  -1.\n",
            "   0.9954284 ]\n",
            " ...\n",
            " [-0.97528726 -1.          1.         ...  0.9999976  -1.\n",
            "   0.9829323 ]\n",
            " [-0.97105163  0.98050594  0.7966758  ...  0.9999954  -1.\n",
            "   0.98942035]\n",
            " [-0.9929983   0.95066863  0.90589654 ...  0.9999989  -1.\n",
            "   0.9924704 ]], shape=(428, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9924485   0.97922814  0.53571594 ...  0.99999607 -1.\n",
            "   0.9944935 ]\n",
            " [-0.9942103  -0.8626993   1.         ...  0.9999986  -1.\n",
            "   0.9938168 ]\n",
            " [-0.9364387   0.7807874  -0.3659331  ...  0.99999595 -1.\n",
            "   0.997155  ]\n",
            " ...\n",
            " [-0.9982534   0.99917024  0.6013716  ...  0.999999   -1.\n",
            "   0.9934309 ]\n",
            " [-0.9993851   0.9998958   0.93826157 ...  0.999998   -1.\n",
            "   0.99038017]\n",
            " [-0.99426997  0.9776322   0.7725993  ...  0.99999475 -1.\n",
            "   0.99194866]], shape=(374, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99853003 -1.          1.         ...  0.9999957  -1.\n",
            "   0.99461627]\n",
            " [-0.9776054  -1.          1.         ...  0.9999957  -1.\n",
            "   0.9963135 ]\n",
            " [-0.9908694  -0.9999398   1.         ...  0.99999845 -1.\n",
            "   0.96332675]\n",
            " ...\n",
            " [-0.98808056  0.64512116 -0.15033665 ...  0.99999464 -1.\n",
            "   0.99301976]\n",
            " [-0.974362   -1.          1.         ...  0.99999917 -1.\n",
            "   0.9914754 ]\n",
            " [-0.99751204  0.9959618   0.9576345  ...  0.99999535 -1.\n",
            "   0.996411  ]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99768275  0.97833544  0.88369167 ...  0.99999666 -1.\n",
            "   0.98880965]\n",
            " [-0.9979377  -1.          1.         ...  0.9999984  -1.\n",
            "   0.99098957]\n",
            " [-0.9998515   0.99979156  0.5544672  ...  0.9999974  -1.\n",
            "   0.9957228 ]\n",
            " ...\n",
            " [-0.99618995 -1.          1.         ...  0.9999953  -1.\n",
            "   0.96909875]\n",
            " [-0.9980245  -1.          1.         ...  0.99998945 -1.\n",
            "   0.99438936]\n",
            " [-0.88033456 -0.9881018   1.         ...  0.999999   -1.\n",
            "   0.98538685]], shape=(378, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98787105 -1.          1.         ...  0.99999464 -1.\n",
            "   0.99418247]\n",
            " [-0.9978533   0.99908805  0.8625638  ...  0.9999974  -1.\n",
            "   0.9919732 ]\n",
            " [-0.9775703  -1.          1.         ...  0.9999934  -1.\n",
            "   0.992828  ]\n",
            " ...\n",
            " [-0.9790572  -1.          1.         ...  0.9999993  -1.\n",
            "   0.9937066 ]\n",
            " [-0.9914709  -0.99993455  1.         ...  0.9999992  -1.\n",
            "   0.9903336 ]\n",
            " [-0.874686   -1.          1.         ...  0.99999726 -1.\n",
            "   0.9883142 ]], shape=(347, 128), dtype=float32)\n",
            "\n",
            "\n",
            "Adversarial Train:\n",
            "batch number:  0 \t\tgen loss:  0.3670233 \t\t\tdisc loss:  0.20524408\n",
            "batch number:  5 \t\tgen loss:  0.107704334 \t\t\tdisc loss:  0.17657322\n",
            "batch number:  10 \t\tgen loss:  0.106030114 \t\t\tdisc loss:  0.15266952\n",
            "batch number:  15 \t\tgen loss:  0.21793276 \t\t\tdisc loss:  0.1557625\n",
            "batch number:  20 \t\tgen loss:  0.07906955 \t\t\tdisc loss:  0.13842152\n",
            "batch number:  25 \t\tgen loss:  0.19256666 \t\t\tdisc loss:  0.12563801\n",
            "batch number:  30 \t\tgen loss:  0.10972751 \t\t\tdisc loss:  0.11397498\n",
            "batch number:  35 \t\tgen loss:  0.1316501 \t\t\tdisc loss:  0.107035175\n",
            "batch number:  40 \t\tgen loss:  0.2145045 \t\t\tdisc loss:  0.104844205\n",
            "batch number:  45 \t\tgen loss:  0.10800254 \t\t\tdisc loss:  0.09062347\n",
            "batch number:  50 \t\tgen loss:  0.12751062 \t\t\tdisc loss:  0.08971309\n",
            "batch number:  55 \t\tgen loss:  0.17654496 \t\t\tdisc loss:  0.08416348\n",
            "batch number:  60 \t\tgen loss:  0.13168424 \t\t\tdisc loss:  0.07393938\n",
            "\n",
            "\n",
            "Generator Test:\n",
            "batch number:  0 \tgen loss:  9.936813\n",
            "batch number:  5 \tgen loss:  9.963425\n",
            "batch number:  10 \tgen loss:  9.901436\n",
            "batch number:  15 \tgen loss:  9.874685\n",
            "Saved checkpoint for epoch 2: ./tf_ckpts/ckpt-2\n",
            "\n",
            "\n",
            "epoch :  2\n",
            "********************************************* PMF Model Training Turn *********************************************\n",
            "\n",
            "Training RMSE: 8.892353, Test RMSE 1.185809\n",
            "\n",
            "\n",
            "******************************************* Seq2Seq Model Training Turn *******************************************\n",
            "\n",
            "\n",
            "Teacher Forcing Train:\n",
            "tf.Tensor(\n",
            "[[-0.9772425  -1.          1.         ...  0.9999966  -1.\n",
            "   0.9963857 ]\n",
            " [-0.94252646 -1.          1.         ...  0.9999987  -1.\n",
            "   0.9950457 ]\n",
            " [-0.8906259  -0.85504884  1.         ...  0.9999904  -1.\n",
            "   0.9909671 ]\n",
            " ...\n",
            " [-0.9956668  -1.          1.         ...  0.9999982  -1.\n",
            "   0.97862107]\n",
            " [-0.9674893  -1.          1.         ...  0.9999985  -1.\n",
            "   0.9832131 ]\n",
            " [-0.9958521  -1.          1.         ...  0.99999934 -1.\n",
            "   0.96681494]], shape=(350, 128), dtype=float32)\n",
            "batch number:  0 \tgen loss:  6.0214176\n",
            "tf.Tensor(\n",
            "[[-0.98736376 -1.          1.         ...  0.9999982  -1.\n",
            "   0.997661  ]\n",
            " [-0.99210864 -1.          1.         ...  0.9999967  -1.\n",
            "   0.9706223 ]\n",
            " [-0.9958973  -1.          1.         ...  0.9999963  -1.\n",
            "   0.99106884]\n",
            " ...\n",
            " [-0.9985313  -0.9999996   1.         ...  0.99999845 -1.\n",
            "   0.99475425]\n",
            " [-0.9872485  -1.          1.         ...  0.9999983  -1.\n",
            "   0.9963102 ]\n",
            " [-0.9994056  -0.99999946  1.         ...  0.99999267 -1.\n",
            "   0.9877221 ]], shape=(360, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.994489    0.8988973   0.19956993 ...  0.99999917 -1.\n",
            "   0.99018973]\n",
            " [-0.9954617   0.99450845 -0.19764104 ...  0.99999875 -1.\n",
            "   0.99624014]\n",
            " [-0.8579743  -1.          0.99999994 ...  0.99999255 -1.\n",
            "   0.9939859 ]\n",
            " ...\n",
            " [-0.95251846 -1.          1.         ...  0.99999595 -1.\n",
            "   0.95058566]\n",
            " [-0.9906578  -1.          1.         ...  0.9999993  -1.\n",
            "   0.9763025 ]\n",
            " [-0.99289966 -1.          1.         ...  0.9999901  -1.\n",
            "   0.99680513]], shape=(406, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9515556   0.9958195   0.9274598  ...  0.9999991  -1.\n",
            "   0.9964174 ]\n",
            " [-0.980288   -0.99999243  1.         ...  0.9999899  -1.\n",
            "   0.9957915 ]\n",
            " [-0.9995218   0.99997675  0.8191218  ...  0.99999964 -1.\n",
            "   0.994719  ]\n",
            " ...\n",
            " [-0.94143605 -1.          0.99999994 ...  0.999998   -1.\n",
            "   0.9931477 ]\n",
            " [-0.9978981  -1.          1.         ...  0.99999464 -1.\n",
            "   0.9939424 ]\n",
            " [-0.9914115  -1.          1.         ...  0.9999949  -1.\n",
            "   0.99242365]], shape=(337, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8874644   0.8935235   0.604578   ...  0.9999964  -1.\n",
            "   0.99482   ]\n",
            " [-0.9974515   0.96763694  0.7103138  ...  0.9999936  -1.\n",
            "   0.9958919 ]\n",
            " [-0.99359363  0.9975086   0.6367528  ...  0.9999964  -1.\n",
            "   0.99120104]\n",
            " ...\n",
            " [-0.9980436  -1.          1.         ...  0.9999942  -1.\n",
            "   0.99380326]\n",
            " [-0.9989808  -1.          1.         ...  1.         -1.\n",
            "   0.990434  ]\n",
            " [-0.97993064 -1.          1.         ...  0.99999666 -1.\n",
            "   0.9953818 ]], shape=(388, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9966056   0.99773085  0.8746552  ...  0.9999994  -1.\n",
            "   0.98683316]\n",
            " [-0.99740297  0.9989379   0.38686758 ...  0.9999983  -1.\n",
            "   0.99602   ]\n",
            " [-0.89284134  0.73238766  0.66393024 ...  0.999999   -1.\n",
            "   0.9923932 ]\n",
            " ...\n",
            " [-0.9326576   0.33939034 -0.85295516 ...  0.9999942  -1.\n",
            "   0.9928175 ]\n",
            " [-0.98353803  0.7835564   0.4577834  ...  0.9999993  -1.\n",
            "   0.9982281 ]\n",
            " [-0.8515443  -0.01279921  0.36218694 ...  0.9999991  -1.\n",
            "   0.97418624]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9722351   0.9726387   0.5472483  ...  0.9999963  -1.\n",
            "   0.9893366 ]\n",
            " [-0.99531037 -1.          1.         ...  0.9999979  -1.\n",
            "   0.99300426]\n",
            " [-0.9690784  -0.9770898   1.         ...  0.99999374 -1.\n",
            "   0.9888013 ]\n",
            " ...\n",
            " [-0.95286936 -1.          1.         ...  0.9999968  -1.\n",
            "   0.22679761]\n",
            " [-0.982376   -1.          1.         ...  0.99999934 -1.\n",
            "   0.99532104]\n",
            " [-0.95181286 -1.          1.         ...  0.9999871  -1.\n",
            "   0.89873576]], shape=(406, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9998006   0.99996525  0.9026658  ...  0.99999964 -1.\n",
            "   0.99058217]\n",
            " [-0.968774    0.62135166 -0.83812535 ...  0.9999982  -1.\n",
            "   0.99301285]\n",
            " [-0.9982544   0.97477007  0.56661266 ...  0.9999995  -1.\n",
            "   0.9634261 ]\n",
            " ...\n",
            " [-0.99823296  0.74162185 -0.78384846 ...  0.99999964 -1.\n",
            "   0.9967506 ]\n",
            " [-0.9892519  -0.9778838   1.         ...  0.99999946 -1.\n",
            "   0.9916916 ]\n",
            " [-0.9936491  -1.          1.         ...  0.999973   -1.\n",
            "   0.99716103]], shape=(408, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9875084   0.9987648   0.65664154 ...  0.99999845 -1.\n",
            "   0.99361324]\n",
            " [-0.9977721   0.99956745  0.5816823  ...  0.99999857 -1.\n",
            "   0.99442095]\n",
            " [-0.9703347   0.66890055 -0.7315127  ...  0.9999991  -1.\n",
            "   0.9964889 ]\n",
            " ...\n",
            " [-0.99454874 -1.          1.         ...  0.9999969  -1.\n",
            "   0.9924156 ]\n",
            " [-0.9929163  -1.          1.         ...  0.9999992  -1.\n",
            "   0.99322385]\n",
            " [-0.99006444 -1.          1.         ...  0.99999994 -1.\n",
            "   0.9888083 ]], shape=(385, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9547851  -1.          1.         ...  0.9999943  -1.\n",
            "   0.99131966]\n",
            " [-0.9977739  -1.          1.         ...  0.99999976 -1.\n",
            "   0.9902134 ]\n",
            " [-0.98316574 -1.          1.         ...  0.9999991  -1.\n",
            "   0.9899682 ]\n",
            " ...\n",
            " [-0.91931635 -1.          0.99999994 ...  0.9999996  -1.\n",
            "   0.9898106 ]\n",
            " [-0.9762816  -0.99760854  1.         ...  0.9999998  -1.\n",
            "   0.99338675]\n",
            " [-0.8846426  -1.          1.         ...  0.9999976  -1.\n",
            "   0.9864182 ]], shape=(359, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9969507   0.99248093 -0.82676136 ...  0.9999927  -1.\n",
            "   0.98473793]\n",
            " [-0.984824   -1.          1.         ...  0.9999948  -1.\n",
            "   0.99157673]\n",
            " [-0.99990857  0.99910265 -0.81619394 ...  0.9999979  -1.\n",
            "   0.9957939 ]\n",
            " ...\n",
            " [-0.99700654 -1.          1.         ...  0.9999929  -1.\n",
            "   0.9901933 ]\n",
            " [-0.920459   -1.          1.         ...  0.9999952  -1.\n",
            "   0.97999054]\n",
            " [-0.96385795 -0.99720234  0.99999994 ...  0.9999985  -1.\n",
            "   0.9930552 ]], shape=(369, 128), dtype=float32)\n",
            "batch number:  10 \tgen loss:  5.8269243\n",
            "tf.Tensor(\n",
            "[[-0.99911726  0.9798989  -0.8251341  ...  0.9999989  -1.\n",
            "   0.99350846]\n",
            " [-0.99835044 -1.          1.         ...  0.9999967  -1.\n",
            "   0.9921162 ]\n",
            " [-0.99739504 -1.          1.         ...  0.99999946 -1.\n",
            "   0.9880333 ]\n",
            " ...\n",
            " [-0.9891624   0.9990401   0.83543    ...  0.9999995  -1.\n",
            "   0.9932455 ]\n",
            " [-0.8825455   0.6598328  -0.8314538  ...  0.9999993  -1.\n",
            "   0.994835  ]\n",
            " [-0.97537404  0.95703715  0.7020174  ...  0.9999982  -1.\n",
            "   0.9843768 ]], shape=(342, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9945782  -1.          0.99999994 ...  0.9999996  -1.\n",
            "   0.99201137]\n",
            " [-0.9973594  -1.          1.         ...  0.9999927  -1.\n",
            "   0.9933883 ]\n",
            " [-0.8690042  -0.99999845  1.         ...  0.99999624 -1.\n",
            "   0.991157  ]\n",
            " ...\n",
            " [-0.9947077  -1.          0.99999994 ...  0.99999744 -1.\n",
            "   0.9948882 ]\n",
            " [-0.98721445 -1.          1.         ...  0.9999971  -1.\n",
            "   0.9847956 ]\n",
            " [-0.9866798   0.6326288  -0.87685657 ...  1.         -1.\n",
            "   0.9858858 ]], shape=(341, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9689834   0.97743154  0.48923036 ...  0.99999917 -1.\n",
            "   0.97207755]\n",
            " [-0.9916081   0.9327542   0.37210834 ...  0.9999933  -1.\n",
            "   0.9980991 ]\n",
            " [-0.9883126   0.9133708  -0.58949417 ...  0.99999875 -1.\n",
            "   0.9944951 ]\n",
            " ...\n",
            " [-0.9600248   0.8964432   0.7420726  ...  0.9999982  -1.\n",
            "   0.9951519 ]\n",
            " [-0.96079403  0.41758806  0.99991393 ...  0.99999905 -1.\n",
            "   0.99016696]\n",
            " [-0.944924   -1.          1.         ...  0.9999966  -1.\n",
            "   0.9964627 ]], shape=(374, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9915335   0.8064783   0.30380628 ...  0.9999985  -1.\n",
            "   0.99338955]\n",
            " [-0.9995928   0.99928033  0.9595415  ...  0.9999929  -1.\n",
            "   0.992988  ]\n",
            " [-0.90851355  0.54161143  0.6106746  ...  0.99999595 -1.\n",
            "   0.9921652 ]\n",
            " ...\n",
            " [-0.8672683  -1.          1.         ...  0.9999981  -1.\n",
            "   0.9959397 ]\n",
            " [-0.99803454  0.9996391   0.6312032  ...  0.99999934 -1.\n",
            "   0.9945061 ]\n",
            " [-0.98242366 -0.99972373  0.99999994 ...  0.9999985  -1.\n",
            "   0.9956757 ]], shape=(333, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98438245 -1.          1.         ...  0.9999984  -1.\n",
            "   0.9971138 ]\n",
            " [-0.9997347   0.9999731   0.75759774 ...  0.9999994  -1.\n",
            "   0.9951451 ]\n",
            " [-0.990927    0.9388122   0.4227162  ...  0.99999976 -1.\n",
            "   0.9971693 ]\n",
            " ...\n",
            " [-0.99919045 -1.          1.         ...  0.9999991  -1.\n",
            "   0.9964372 ]\n",
            " [-0.9889961  -1.          1.         ...  0.99999976 -1.\n",
            "   0.991084  ]\n",
            " [-0.92949647 -1.          1.         ...  0.99999654 -1.\n",
            "   0.8981996 ]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9970643   0.9367518   0.20080611 ...  0.9999992  -1.\n",
            "   0.995706  ]\n",
            " [-0.98342127 -1.          1.         ...  0.99999607 -1.\n",
            "   0.99535525]\n",
            " [-0.9873117  -1.          1.         ...  0.9999978  -1.\n",
            "   0.9839635 ]\n",
            " ...\n",
            " [-0.96872556  0.8143599   0.35577503 ...  0.9999972  -1.\n",
            "   0.9966913 ]\n",
            " [-0.9915874   0.7847477  -0.8554188  ...  0.9999971  -1.\n",
            "   0.99489856]\n",
            " [-0.9821754   0.9980435   0.30790293 ...  0.9999973  -1.\n",
            "   0.9886925 ]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9861876   0.9667861   0.67358285 ...  0.9999997  -1.\n",
            "   0.9913427 ]\n",
            " [-0.95611006  0.8904585  -0.81323814 ...  0.99999636 -1.\n",
            "   0.99549943]\n",
            " [-0.9710236   0.9319921   0.25521696 ...  0.99999684 -1.\n",
            "   0.9948489 ]\n",
            " ...\n",
            " [-0.9715818  -1.          1.         ...  0.99999714 -1.\n",
            "   0.99274844]\n",
            " [-0.99901927 -0.9999345   1.         ...  0.99999404 -1.\n",
            "   0.9953741 ]\n",
            " [-0.99708056 -1.          1.         ...  0.99999976 -1.\n",
            "   0.99115556]], shape=(345, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99981326  0.9998665   0.11766148 ...  0.9999974  -1.\n",
            "   0.99569225]\n",
            " [-0.9364433  -1.          1.         ...  0.999999   -1.\n",
            "   0.99543667]\n",
            " [-0.99777347 -1.          1.         ...  0.9999996  -1.\n",
            "   0.9978693 ]\n",
            " ...\n",
            " [-0.9975139  -1.          1.         ...  0.99999857 -1.\n",
            "   0.9657094 ]\n",
            " [-0.99817675  0.9780315   0.633558   ...  0.99999845 -1.\n",
            "   0.98890245]\n",
            " [-0.96348923 -1.          1.         ...  0.999996   -1.\n",
            "   0.99792427]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99749213 -1.          1.         ...  0.9999938  -1.\n",
            "   0.99268615]\n",
            " [-0.9875583  -1.          1.         ...  0.9999998  -1.\n",
            "   0.99495906]\n",
            " [-0.98405284 -1.          1.         ...  0.9999998  -1.\n",
            "   0.9851006 ]\n",
            " ...\n",
            " [-0.9243861   0.92969066  0.05740662 ...  0.9999998  -1.\n",
            "   0.9976066 ]\n",
            " [-0.93955785  0.9519462   0.8336335  ...  0.9999912  -1.\n",
            "   0.99721855]\n",
            " [-0.9778438   0.5732929   0.60568213 ...  0.99999946 -1.\n",
            "   0.9879965 ]], shape=(432, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9976329  -1.          1.         ...  0.99999547 -1.\n",
            "   0.9943003 ]\n",
            " [-0.9933635  -1.          1.         ...  0.999998   -1.\n",
            "   0.9919797 ]\n",
            " [-0.99364805 -1.          1.         ...  0.99999917 -1.\n",
            "   0.98492515]\n",
            " ...\n",
            " [-0.9786912   0.7197074  -0.5165102  ...  0.99999565 -1.\n",
            "   0.99056447]\n",
            " [-0.99973506  0.99906737 -0.6942164  ...  0.9999976  -1.\n",
            "   0.9971841 ]\n",
            " [-0.9989793   0.9999366   0.82613516 ...  0.999999   -1.\n",
            "   0.99390006]], shape=(367, 128), dtype=float32)\n",
            "batch number:  20 \tgen loss:  5.8715944\n",
            "tf.Tensor(\n",
            "[[-0.9998271   0.99972075 -0.5788255  ...  0.9999972  -1.\n",
            "   0.98961604]\n",
            " [-0.9427212   0.9907882   0.9338049  ...  0.99999946 -1.\n",
            "   0.99039924]\n",
            " [-0.9728306   0.9071235  -0.6934018  ...  0.9999983  -1.\n",
            "   0.9951231 ]\n",
            " ...\n",
            " [-0.960317    0.75404465 -0.57640207 ...  0.9999997  -1.\n",
            "   0.9923001 ]\n",
            " [-0.99375594  0.9703479   0.8548062  ...  0.9999993  -1.\n",
            "   0.9477526 ]\n",
            " [-0.9916211  -0.9999972   1.         ...  0.99999565 -1.\n",
            "   0.9942348 ]], shape=(335, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99847525 -1.          1.         ...  0.9999998  -1.\n",
            "   0.9951692 ]\n",
            " [-0.99715525 -1.          1.         ...  0.9999995  -1.\n",
            "   0.98908854]\n",
            " [-0.97982717 -1.          1.         ...  0.9999986  -1.\n",
            "   0.98843414]\n",
            " ...\n",
            " [-0.8820091   0.4696237  -0.10251974 ...  0.9999992  -1.\n",
            "   0.9970707 ]\n",
            " [-0.9965582   0.9852359   0.8956722  ...  0.9999992  -1.\n",
            "   0.99070466]\n",
            " [-0.9892893  -0.18812811  0.99971396 ...  0.99999875 -1.\n",
            "   0.9966886 ]], shape=(381, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8801459   0.6832516   0.31676134 ...  0.9999995  -1.\n",
            "   0.9822012 ]\n",
            " [-0.91752094  0.74408287  0.65957177 ...  0.9999984  -1.\n",
            "   0.992749  ]\n",
            " [-0.9990761   0.99829835  0.3802554  ...  0.9999999  -1.\n",
            "   0.994368  ]\n",
            " ...\n",
            " [-0.98951113  0.68428314 -0.47830343 ...  0.9999989  -1.\n",
            "   0.9857404 ]\n",
            " [-0.999231    0.9991726  -0.859432   ...  0.99999917 -1.\n",
            "   0.99327326]\n",
            " [-0.99695724 -1.          0.99999994 ...  0.9999922  -1.\n",
            "   0.9956523 ]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97214395  0.8658259   0.628536   ...  0.9999999  -1.\n",
            "   0.9912046 ]\n",
            " [-0.9989131   0.9997479   0.24084897 ...  0.99999267 -1.\n",
            "   0.9910259 ]\n",
            " [-0.97855425  0.67147064 -0.8605331  ...  0.9999974  -1.\n",
            "   0.9949784 ]\n",
            " ...\n",
            " [-0.95482194 -1.          0.99999994 ...  0.9999967  -1.\n",
            "   0.9886116 ]\n",
            " [-0.99688435 -1.          1.         ...  0.9999961  -1.\n",
            "   0.98376113]\n",
            " [-0.9842601  -1.          1.         ...  0.99999875 -1.\n",
            "   0.9862416 ]], shape=(421, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.91507107  0.61690056 -0.65648586 ...  0.99999624 -1.\n",
            "   0.9962845 ]\n",
            " [-0.9828283   0.8092465   0.23264769 ...  0.9999985  -1.\n",
            "   0.99508923]\n",
            " [-0.99357903  0.8403505  -0.3895018  ...  0.999998   -1.\n",
            "   0.9951393 ]\n",
            " ...\n",
            " [-0.98553616  0.95042247  0.62434554 ...  0.9999989  -1.\n",
            "   0.9937214 ]\n",
            " [-0.93150663  0.9654839   0.85342354 ...  0.99999905 -1.\n",
            "   0.9933908 ]\n",
            " [-0.9915374   0.91196436  0.56363994 ...  0.99999875 -1.\n",
            "   0.9932587 ]], shape=(373, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9562679   0.60938936  0.08017663 ...  0.9999986  -1.\n",
            "   0.98737836]\n",
            " [-0.9644396   0.6983261  -0.9155057  ...  0.9999988  -1.\n",
            "   0.9954011 ]\n",
            " [-0.99824977  0.99948317  0.59426713 ...  0.9999997  -1.\n",
            "   0.99458313]\n",
            " ...\n",
            " [-0.98895985 -0.99999994  1.         ...  0.99999243 -1.\n",
            "   0.98936415]\n",
            " [-0.9951162  -0.99999994  1.         ...  0.9999986  -1.\n",
            "   0.9964709 ]\n",
            " [-0.9970489  -1.          1.         ...  0.99999917 -1.\n",
            "   0.9753266 ]], shape=(307, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9668477   0.98636127  0.87503123 ...  0.9999963  -1.\n",
            "   0.99367505]\n",
            " [-0.97283435  0.9395799   0.75341105 ...  0.99999905 -1.\n",
            "   0.991763  ]\n",
            " [-0.99575096  0.98998064  0.9377711  ...  0.99999845 -1.\n",
            "   0.9925599 ]\n",
            " ...\n",
            " [-0.9915345  -1.          1.         ...  0.9999991  -1.\n",
            "   0.99126   ]\n",
            " [-0.9898719  -1.          1.         ...  0.9999981  -1.\n",
            "   0.9909328 ]\n",
            " [-0.90953654 -1.          1.         ...  0.9999987  -1.\n",
            "   0.99097365]], shape=(345, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9851509   0.75942963  0.4117271  ...  0.9999973  -1.\n",
            "   0.99557626]\n",
            " [-0.9825799   0.9849917   0.8144965  ...  0.9999995  -1.\n",
            "   0.99171835]\n",
            " [-0.9989877   0.99964297  0.89483    ...  0.9999982  -1.\n",
            "   0.99536043]\n",
            " ...\n",
            " [-0.9990728   0.816976   -0.96712345 ...  0.99999815 -1.\n",
            "   0.99489015]\n",
            " [-0.9893591   0.85534686  0.6983464  ...  0.9999991  -1.\n",
            "   0.9900743 ]\n",
            " [-0.9827694   0.976037    0.86369115 ...  0.9999939  -1.\n",
            "   0.9951915 ]], shape=(402, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9934643  -1.          1.         ...  0.9999942  -1.\n",
            "   0.9955544 ]\n",
            " [-0.978195    0.75872445  0.0589539  ...  0.9999995  -1.\n",
            "   0.9926848 ]\n",
            " [-0.99410903 -1.          1.         ...  0.99999994 -1.\n",
            "   0.9945976 ]\n",
            " ...\n",
            " [-0.9966234  -1.          1.         ...  0.99999905 -1.\n",
            "   0.9903126 ]\n",
            " [-0.9959505  -0.9999874   1.         ...  0.9999904  -1.\n",
            "   0.9710073 ]\n",
            " [-0.9929678   0.9441979   0.26560703 ...  0.9999952  -1.\n",
            "   0.9938749 ]], shape=(313, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99637973  0.774048   -0.79487675 ...  0.9999996  -1.\n",
            "   0.99076456]\n",
            " [-0.97021407  0.58229154 -0.90731776 ...  0.9999998  -1.\n",
            "   0.99369174]\n",
            " [-0.99638784  0.99959904  0.51719356 ...  0.99999917 -1.\n",
            "   0.9947283 ]\n",
            " ...\n",
            " [-0.9982688   0.9996175   0.19136626 ...  0.99999744 -1.\n",
            "   0.9939167 ]\n",
            " [-0.99779963 -1.          1.         ...  0.9999964  -1.\n",
            "   0.9940582 ]\n",
            " [-0.9994792   0.9998471   0.14189707 ...  0.9999992  -1.\n",
            "   0.99322194]], shape=(422, 128), dtype=float32)\n",
            "batch number:  30 \tgen loss:  5.887365\n",
            "tf.Tensor(\n",
            "[[-0.9804391  -0.9988006   0.99999994 ...  0.9999985  -1.\n",
            "   0.9872315 ]\n",
            " [-0.99785906 -1.          1.         ...  0.9999986  -1.\n",
            "   0.99696296]\n",
            " [-0.99567413 -0.99999994  1.         ...  0.99999905 -1.\n",
            "   0.99608785]\n",
            " ...\n",
            " [-0.99293303 -1.          1.         ...  0.9999992  -1.\n",
            "   0.9950126 ]\n",
            " [-0.98785996  0.95351285  0.7106892  ...  0.9999953  -1.\n",
            "   0.9935983 ]\n",
            " [-0.9988166  -1.          1.         ...  0.999999   -1.\n",
            "   0.9931058 ]], shape=(372, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9933486   0.7893921  -0.69857186 ...  0.9999969  -1.\n",
            "   0.99358994]\n",
            " [-0.99980175  0.9999822   0.81302774 ...  0.99999726 -1.\n",
            "   0.9944194 ]\n",
            " [-0.99723226  0.9988457   0.5580711  ...  0.9999989  -1.\n",
            "   0.9949812 ]\n",
            " ...\n",
            " [-0.977458    0.94360334  0.8199972  ...  0.99999934 -1.\n",
            "   0.9943474 ]\n",
            " [-0.9898317   0.8752882   0.40686715 ...  0.99999815 -1.\n",
            "   0.9860098 ]\n",
            " [-0.99395317 -1.          1.         ...  0.99999696 -1.\n",
            "   0.9935921 ]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98322797  0.9036483  -0.8050393  ...  0.9999993  -1.\n",
            "   0.9929699 ]\n",
            " [-0.9505695   0.9048581   0.68688756 ...  0.9999994  -1.\n",
            "   0.99482363]\n",
            " [-0.9493849  -1.          1.         ...  0.99999946 -1.\n",
            "   0.88273   ]\n",
            " ...\n",
            " [-0.99904513  0.9934249   0.44769043 ...  0.99999535 -1.\n",
            "   0.99279755]\n",
            " [-0.9999203   0.99998087  0.6762975  ...  0.9999989  -1.\n",
            "   0.9939445 ]\n",
            " [-0.99887186  0.99660784  0.49015796 ...  0.9999997  -1.\n",
            "   0.98922884]], shape=(348, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9910293  -1.          1.         ...  0.9999973  -1.\n",
            "   0.9877943 ]\n",
            " [-0.9816211   0.94598925  0.27850747 ...  0.99999577 -1.\n",
            "   0.9927376 ]\n",
            " [-0.9990803   0.9999789   0.55532587 ...  0.9999992  -1.\n",
            "   0.994366  ]\n",
            " ...\n",
            " [-0.99987954  0.9966741  -0.8288892  ...  0.9999997  -1.\n",
            "   0.9863173 ]\n",
            " [-0.99435645  0.9917065   0.9820389  ...  0.9999999  -1.\n",
            "   0.9957041 ]\n",
            " [-0.9964558  -0.9978786   1.         ...  0.99999976 -1.\n",
            "   0.9932899 ]], shape=(393, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.92108965 -0.15179347 -0.73429024 ...  0.9999982  -1.\n",
            "   0.99834347]\n",
            " [-0.9988786   0.9997282   0.8228595  ...  0.999997   -1.\n",
            "   0.9983166 ]\n",
            " [-0.9975471   0.9998803   0.5835338  ...  0.9999988  -1.\n",
            "   0.99447846]\n",
            " ...\n",
            " [-0.931167    0.71765196  0.6989035  ...  0.9999998  -1.\n",
            "   0.9899165 ]\n",
            " [-0.97556716  0.94745797  0.90029323 ...  0.99999845 -1.\n",
            "   0.995703  ]\n",
            " [-0.9850079   0.9807044   0.6456848  ...  0.99999875 -1.\n",
            "   0.9960083 ]], shape=(384, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99618953 -1.          1.         ...  0.99999756 -1.\n",
            "   0.96760654]\n",
            " [-0.99822414 -1.          1.         ...  0.99999887 -1.\n",
            "   0.99164635]\n",
            " [-0.9977554  -1.          1.         ...  0.99999535 -1.\n",
            "   0.8307277 ]\n",
            " ...\n",
            " [-0.9929638  -1.          1.         ...  0.99999857 -1.\n",
            "   0.9956598 ]\n",
            " [-0.9970669  -1.          1.         ...  0.9999961  -1.\n",
            "   0.9935357 ]\n",
            " [-0.99187934  0.957025    0.6019848  ...  0.99999857 -1.\n",
            "   0.99338937]], shape=(411, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98896825 -1.          1.         ...  0.9999981  -1.\n",
            "   0.98547286]\n",
            " [-0.9732048  -1.          1.         ...  0.9999982  -1.\n",
            "   0.3781921 ]\n",
            " [-0.9795731  -1.          1.         ...  0.999999   -1.\n",
            "   0.9074885 ]\n",
            " ...\n",
            " [-0.9964978   0.7559181  -0.8665758  ...  0.99999934 -1.\n",
            "   0.98925537]\n",
            " [-0.99640614 -1.          1.         ...  0.9999995  -1.\n",
            "   0.9710194 ]\n",
            " [-0.99317473 -1.          1.         ...  0.9999986  -1.\n",
            "   0.9937456 ]], shape=(395, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9976487   0.8876779   0.98876476 ...  0.9999999  -1.\n",
            "   0.98046464]\n",
            " [-0.99982536  0.9999729  -0.44764188 ...  0.99999994 -1.\n",
            "   0.98886675]\n",
            " [-0.9998239   0.9999741   0.40257075 ...  0.9999997  -1.\n",
            "   0.98432505]\n",
            " ...\n",
            " [-0.9905486  -1.          1.         ...  0.99999166 -1.\n",
            "   0.99360305]\n",
            " [-0.989382   -1.          1.         ...  0.9999998  -1.\n",
            "   0.9919639 ]\n",
            " [-0.9941622  -1.          1.         ...  0.9999995  -1.\n",
            "   0.9902467 ]], shape=(341, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98665994  0.45596737  0.5392514  ...  0.9999865  -1.\n",
            "   0.9939015 ]\n",
            " [-0.9057634  -1.          1.         ...  0.99999887 -1.\n",
            "   0.98853534]\n",
            " [-0.9923596  -0.99928606  1.         ...  0.999999   -1.\n",
            "   0.995796  ]\n",
            " ...\n",
            " [-0.99630326 -1.          1.         ...  0.99999785 -1.\n",
            "   0.96856767]\n",
            " [-0.9800781  -1.          1.         ...  0.9999997  -1.\n",
            "   0.9801118 ]\n",
            " [-0.9971513  -1.          1.         ...  0.99999946 -1.\n",
            "   0.9533659 ]], shape=(416, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9904798  -1.          1.         ...  0.9999987  -1.\n",
            "   0.98737264]\n",
            " [-0.9979152  -1.          1.         ...  0.99999946 -1.\n",
            "   0.9490759 ]\n",
            " [-0.9897482   0.97520685  0.86976326 ...  0.9999993  -1.\n",
            "   0.99481463]\n",
            " ...\n",
            " [-0.955496   -1.          1.         ...  0.9999957  -1.\n",
            "   0.99395543]\n",
            " [-0.9380785  -1.          1.         ...  0.9999996  -1.\n",
            "   0.99408454]\n",
            " [-0.97636884 -1.          1.         ...  0.9999959  -1.\n",
            "   0.9514009 ]], shape=(409, 128), dtype=float32)\n",
            "batch number:  40 \tgen loss:  5.9732585\n",
            "tf.Tensor(\n",
            "[[-0.8679676   0.889062    0.83328384 ...  0.9999961  -1.\n",
            "   0.9954474 ]\n",
            " [-0.9582004   0.72656286 -0.67698586 ...  0.9999998  -1.\n",
            "   0.9938782 ]\n",
            " [-0.9986028  -1.          1.         ...  0.9999996  -1.\n",
            "   0.99331737]\n",
            " ...\n",
            " [-0.9752867  -0.98871654  1.         ...  0.9999987  -1.\n",
            "   0.9896164 ]\n",
            " [-0.99386925 -1.          1.         ...  0.9999991  -1.\n",
            "   0.86184347]\n",
            " [-0.9993861   0.7735579  -0.952929   ...  0.9999995  -1.\n",
            "   0.9938023 ]], shape=(352, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9934148  -1.          1.         ...  0.99999857 -1.\n",
            "   0.7475959 ]\n",
            " [-0.99421567 -1.          1.         ...  0.9999992  -1.\n",
            "   0.9606881 ]\n",
            " [-0.9978532  -1.          1.         ...  0.9999996  -1.\n",
            "   0.99001616]\n",
            " ...\n",
            " [-0.9535906  -0.99999565  1.         ...  0.9999983  -1.\n",
            "   0.99357873]\n",
            " [-0.99666035 -1.          1.         ...  0.9999998  -1.\n",
            "   0.99596125]\n",
            " [-0.99819684  0.95778584  0.8477533  ...  0.99999875 -1.\n",
            "   0.99557245]], shape=(379, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9953173  -0.9994607   1.         ...  0.9999995  -1.\n",
            "   0.99045974]\n",
            " [-0.99938756  0.9995147   0.90583056 ...  0.99999434 -1.\n",
            "   0.99393886]\n",
            " [-0.9436312   0.6974593  -0.6816774  ...  0.99999565 -1.\n",
            "   0.989727  ]\n",
            " ...\n",
            " [-0.96518934  0.93434966  0.7089676  ...  0.99999356 -1.\n",
            "   0.9944356 ]\n",
            " [-0.9364503   0.6601446  -0.785091   ...  0.999999   -1.\n",
            "   0.9960819 ]\n",
            " [-0.9964519  -1.          1.         ...  0.99999917 -1.\n",
            "   0.9895894 ]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9992056   0.9997672   0.7155893  ...  0.9999982  -1.\n",
            "   0.99391556]\n",
            " [-0.9600266   0.9859348   0.04599584 ...  0.9999995  -1.\n",
            "   0.9877341 ]\n",
            " [-0.9889906   0.95752084  0.8912939  ...  0.9999998  -1.\n",
            "   0.99716836]\n",
            " ...\n",
            " [-0.99469006 -1.          1.         ...  0.9999995  -1.\n",
            "   0.990206  ]\n",
            " [-0.9993921   0.999013   -0.460008   ...  0.9999975  -1.\n",
            "   0.9939108 ]\n",
            " [-0.97555137  0.3982524  -0.5724742  ...  0.9999995  -1.\n",
            "   0.9948751 ]], shape=(439, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9862877  -1.          1.         ...  0.9999977  -1.\n",
            "   0.9288621 ]\n",
            " [-0.98135954 -1.          1.         ...  0.99999774 -1.\n",
            "   0.9905585 ]\n",
            " [-0.99784195 -1.          1.         ...  0.999995   -1.\n",
            "   0.98989433]\n",
            " ...\n",
            " [-0.99975926  0.9999771  -0.47204795 ...  0.99999976 -1.\n",
            "   0.9947938 ]\n",
            " [-0.9972075   0.9988797   0.31491253 ...  0.9999996  -1.\n",
            "   0.98919713]\n",
            " [-0.9782251   0.730522   -0.79615617 ...  0.99999696 -1.\n",
            "   0.99645954]], shape=(291, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9985931   0.99293613 -0.7505423  ...  0.9999998  -1.\n",
            "   0.99372536]\n",
            " [-0.99987775  0.9999931   0.3668564  ...  0.99999845 -1.\n",
            "   0.99264675]\n",
            " [-0.99171376  0.98804694  0.6989814  ...  0.9999995  -1.\n",
            "   0.9933196 ]\n",
            " ...\n",
            " [-0.98489916 -1.          1.         ...  0.9999989  -1.\n",
            "   0.9838133 ]\n",
            " [-0.9887049  -1.          1.         ...  0.9999985  -1.\n",
            "   0.98858637]\n",
            " [-0.968989   -1.          1.         ...  0.9999983  -1.\n",
            "   0.99367374]], shape=(401, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9804179  -1.          1.         ...  0.99999976 -1.\n",
            "   0.33174142]\n",
            " [-0.9964998  -1.          1.         ...  0.9999982  -1.\n",
            "   0.9914693 ]\n",
            " [-0.98948526 -1.          1.         ...  0.99999565 -1.\n",
            "   0.9896366 ]\n",
            " ...\n",
            " [-0.9931357   0.9591468   0.7427346  ...  0.999999   -1.\n",
            "   0.9937702 ]\n",
            " [-0.94297045  0.7214829   0.26284385 ...  0.9999991  -1.\n",
            "   0.9942212 ]\n",
            " [-0.9898436   0.99597913  0.7290994  ...  0.9999993  -1.\n",
            "   0.99098   ]], shape=(362, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99718255  0.99530846  0.51866883 ...  0.99999934 -1.\n",
            "   0.9933753 ]\n",
            " [-0.9566767   0.7755152   0.5233849  ...  0.99999654 -1.\n",
            "   0.98971903]\n",
            " [-0.996951    0.9968285   0.9674511  ...  0.999999   -1.\n",
            "   0.9904494 ]\n",
            " ...\n",
            " [-0.9925219   0.99995047  0.42008954 ...  0.9999947  -1.\n",
            "   0.9934362 ]\n",
            " [-0.99521244 -0.99999994  1.         ...  0.9999997  -1.\n",
            "   0.98925143]\n",
            " [-0.9997892   0.9999759  -0.59653133 ...  0.99999976 -1.\n",
            "   0.98746413]], shape=(309, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98643094 -0.9999999   1.         ...  0.99999684 -1.\n",
            "   0.98935145]\n",
            " [-0.9660079   0.94214916  0.80947053 ...  0.99999857 -1.\n",
            "   0.99403363]\n",
            " [-0.9849014  -1.          1.         ...  0.99999785 -1.\n",
            "   0.9939504 ]\n",
            " ...\n",
            " [-0.99572605 -1.          1.         ...  0.9999985  -1.\n",
            "   0.9944218 ]\n",
            " [-0.9646294  -1.          1.         ...  0.99999154 -1.\n",
            "   0.98313415]\n",
            " [-0.9912891   0.9708188   0.8861814  ...  0.9999995  -1.\n",
            "   0.99032485]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98074806 -1.          1.         ...  0.99999887 -1.\n",
            "   0.988673  ]\n",
            " [-0.99403805 -0.999928    1.         ...  0.999998   -1.\n",
            "   0.990805  ]\n",
            " [-0.9960255  -1.          1.         ...  0.9999931  -1.\n",
            "   0.99092543]\n",
            " ...\n",
            " [-0.9981656   0.99659944  0.6141816  ...  0.9999987  -1.\n",
            "   0.9935395 ]\n",
            " [-0.9995788   0.9998484   0.5981963  ...  0.9999998  -1.\n",
            "   0.98199254]\n",
            " [-0.99977005  0.9999571   0.69492024 ...  0.9999992  -1.\n",
            "   0.99179816]], shape=(402, 128), dtype=float32)\n",
            "batch number:  50 \tgen loss:  5.925675\n",
            "tf.Tensor(\n",
            "[[-0.9873399  -1.          1.         ...  0.9999997  -1.\n",
            "   0.9574153 ]\n",
            " [-0.9979407  -1.          1.         ...  0.9999986  -1.\n",
            "   0.9897284 ]\n",
            " [-0.99628323 -1.          1.         ...  0.9999994  -1.\n",
            "   0.98789775]\n",
            " ...\n",
            " [-0.95858127 -0.9999945   1.         ...  0.99999595 -1.\n",
            "   0.9888966 ]\n",
            " [-0.9995195   0.99952465 -0.6169969  ...  0.9999995  -1.\n",
            "   0.99381864]\n",
            " [-0.97685826  0.89071065 -0.673836   ...  0.99999946 -1.\n",
            "   0.99794257]], shape=(350, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9852628   0.9976041   0.52501714 ...  0.99999505 -1.\n",
            "   0.98968744]\n",
            " [-0.99874705  0.9996884   0.7728602  ...  0.99999636 -1.\n",
            "   0.9938496 ]\n",
            " [-0.9994598   0.9999774   0.9589684  ...  0.9999979  -1.\n",
            "   0.9960699 ]\n",
            " ...\n",
            " [-0.9980491   0.9998825   0.8783382  ...  0.99999964 -1.\n",
            "   0.9910338 ]\n",
            " [-0.9949516   0.34242234  0.9997145  ...  0.99999565 -1.\n",
            "   0.9927611 ]\n",
            " [-0.9978028   0.99363357 -0.43888837 ...  0.99999875 -1.\n",
            "   0.9925593 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.91088194 -1.          1.         ...  0.9999969  -1.\n",
            "   0.9910498 ]\n",
            " [-0.9962772  -1.          1.         ...  0.99999905 -1.\n",
            "   0.9814797 ]\n",
            " [-0.99850655 -1.          1.         ...  0.9999998  -1.\n",
            "   0.996218  ]\n",
            " ...\n",
            " [-0.9880797   0.98976475  0.92733324 ...  0.9999995  -1.\n",
            "   0.99321586]\n",
            " [-0.9397651   0.8543273   0.56540465 ...  0.99999934 -1.\n",
            "   0.99168307]\n",
            " [-0.9155976   0.58096504 -0.9274379  ...  0.9999962  -1.\n",
            "   0.9925797 ]], shape=(376, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.8325621  -1.          1.         ...  0.9999988  -1.\n",
            "   0.0123143 ]\n",
            " [-0.9032004  -1.          1.         ...  0.99999744 -1.\n",
            "   0.05050552]\n",
            " [-0.9920626  -1.          1.         ...  0.9999982  -1.\n",
            "   0.9820755 ]\n",
            " ...\n",
            " [-0.99981344  0.99997425  0.70773625 ...  0.9999988  -1.\n",
            "   0.9981572 ]\n",
            " [-0.9911101  -1.          1.         ...  0.9999995  -1.\n",
            "   0.99451876]\n",
            " [-0.9938727   0.9939962   0.7031097  ...  0.999998   -1.\n",
            "   0.9926222 ]], shape=(400, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98298293  0.98465174  0.8054491  ...  0.9999976  -1.\n",
            "   0.99271023]\n",
            " [-0.9973351  -1.          1.         ...  0.99999666 -1.\n",
            "   0.99254936]\n",
            " [-0.977784   -1.          1.         ...  0.9999996  -1.\n",
            "   0.99076664]\n",
            " ...\n",
            " [-0.9999282   0.99998313 -0.19556218 ...  0.9999985  -1.\n",
            "   0.986026  ]\n",
            " [-0.9971486   0.98999655  0.94921064 ...  0.9999989  -1.\n",
            "   0.9829931 ]\n",
            " [-0.9903991   0.842938   -0.34616512 ...  0.99999994 -1.\n",
            "   0.9945991 ]], shape=(359, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99933344 -0.9999983   1.         ...  0.99999976 -1.\n",
            "   0.9720734 ]\n",
            " [-0.97560763 -0.99739635  1.         ...  0.9999996  -1.\n",
            "   0.9912971 ]\n",
            " [-0.98231494 -1.          1.         ...  0.99999815 -1.\n",
            "   0.9799335 ]\n",
            " ...\n",
            " [-0.99873763 -1.          1.         ...  0.99999964 -1.\n",
            "   0.99121827]\n",
            " [-0.99341387  0.99253994  0.8425354  ...  0.99999815 -1.\n",
            "   0.9908383 ]\n",
            " [-0.99080366  0.9989392   0.76843303 ...  0.999999   -1.\n",
            "   0.98993933]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.997672   -1.          1.         ...  0.9999998  -1.\n",
            "   0.99325407]\n",
            " [-0.9951295  -0.95078945  1.         ...  0.99999815 -1.\n",
            "   0.9940356 ]\n",
            " [-0.9974151  -1.          1.         ...  0.99999917 -1.\n",
            "   0.99418443]\n",
            " ...\n",
            " [-0.94829255 -1.          1.         ...  0.9999979  -1.\n",
            "   0.99190295]\n",
            " [-0.96193105  0.90970105 -0.4135195  ...  0.99999976 -1.\n",
            "   0.9891695 ]\n",
            " [-0.99530655  0.99816173  0.71949214 ...  0.9999988  -1.\n",
            "   0.9978063 ]], shape=(336, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9973831   0.99938583  0.91792226 ...  0.99999905 -1.\n",
            "   0.994205  ]\n",
            " [-0.9934617   0.9980628   0.9327083  ...  0.9999988  -1.\n",
            "   0.9908165 ]\n",
            " [-0.99948937  0.99991083  0.7256274  ...  1.         -1.\n",
            "   0.99379754]\n",
            " ...\n",
            " [-0.9986626  -1.          1.         ...  0.99999934 -1.\n",
            "   0.98927337]\n",
            " [-0.9905609  -1.          1.         ...  0.9999992  -1.\n",
            "   0.9908955 ]\n",
            " [-0.99986535  0.9997901   0.4312233  ...  0.99999875 -1.\n",
            "   0.99390817]], shape=(373, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9908829  -1.          1.         ...  0.99999905 -1.\n",
            "   0.9894772 ]\n",
            " [-0.96917325 -1.          1.         ...  0.9999994  -1.\n",
            "   0.8528791 ]\n",
            " [-0.97658134  0.58638376  0.99997246 ...  0.9999991  -1.\n",
            "   0.99795663]\n",
            " ...\n",
            " [-0.88239884  0.8228178   0.8459812  ...  0.99999857 -1.\n",
            "   0.9886267 ]\n",
            " [-0.99486065  0.8157545  -0.71532303 ...  0.9999938  -1.\n",
            "   0.9964675 ]\n",
            " [-0.98812103  0.856899   -0.13650988 ...  0.99999934 -1.\n",
            "   0.9928713 ]], shape=(385, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96608466 -1.          1.         ...  0.9999994  -1.\n",
            "   0.8573133 ]\n",
            " [-0.9994765  -0.9993537   1.         ...  0.9999995  -1.\n",
            "   0.9949855 ]\n",
            " [-0.9694946  -1.          1.         ...  0.99999964 -1.\n",
            "   0.9853215 ]\n",
            " ...\n",
            " [-0.93210757 -1.          1.         ...  0.9999992  -1.\n",
            "   0.9954997 ]\n",
            " [-0.97690034 -1.          1.         ...  0.9999951  -1.\n",
            "   0.99407244]\n",
            " [-0.99847615 -1.          1.         ...  0.99999833 -1.\n",
            "   0.98150885]], shape=(383, 128), dtype=float32)\n",
            "batch number:  60 \tgen loss:  5.8668237\n",
            "tf.Tensor(\n",
            "[[-0.9987237   0.92363185 -0.84787107 ...  0.99999917 -1.\n",
            "   0.9972085 ]\n",
            " [-0.97209316  0.66629094  0.23699848 ...  0.99999833 -1.\n",
            "   0.99199015]\n",
            " [-0.98653543 -0.99999994  1.         ...  0.9999975  -1.\n",
            "   0.9917093 ]\n",
            " ...\n",
            " [-0.9450026  -0.9999994   1.         ...  0.99999917 -1.\n",
            "   0.9914357 ]\n",
            " [-0.99941635  0.9999205  -0.62299675 ...  0.99999756 -1.\n",
            "   0.99263585]\n",
            " [-0.9907648   0.92667586  0.57748455 ...  0.99998933 -1.\n",
            "   0.99063313]], shape=(405, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99268275  0.9392545   0.83139974 ...  0.999999   -1.\n",
            "   0.9964813 ]\n",
            " [-0.9970164  -1.          1.         ...  0.9999995  -1.\n",
            "   0.9730782 ]\n",
            " [-0.99610305 -1.          1.         ...  0.9999998  -1.\n",
            "   0.9904191 ]\n",
            " ...\n",
            " [-0.9991078   0.9884473  -0.641094   ...  0.99999994 -1.\n",
            "   0.991232  ]\n",
            " [-0.9715689   0.94634414  0.66240025 ...  0.9999995  -1.\n",
            "   0.99285954]\n",
            " [-0.9018387   0.9283946   0.6616276  ...  0.9999987  -1.\n",
            "   0.99045914]], shape=(399, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99960744  0.9997856   0.9434776  ...  0.9999988  -1.\n",
            "   0.99670327]\n",
            " [-0.9582039   0.9478727   0.77220464 ...  0.9999998  -1.\n",
            "   0.9922953 ]\n",
            " [-0.9578268   0.7117819  -0.562575   ...  0.99999845 -1.\n",
            "   0.9912783 ]\n",
            " ...\n",
            " [-0.99825937 -0.98789763  1.         ...  0.9999982  -1.\n",
            "   0.9913834 ]\n",
            " [-0.886747    0.73405546  0.69960916 ...  0.99999803 -1.\n",
            "   0.98859215]\n",
            " [-0.9426117   0.6242155  -0.7257479  ...  0.9999901  -1.\n",
            "   0.9926322 ]], shape=(361, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9950973   0.7574543  -0.93652433 ...  0.9999987  -1.\n",
            "   0.9914111 ]\n",
            " [-0.99287635  0.89000106 -0.90477407 ...  0.9999963  -1.\n",
            "   0.99208134]\n",
            " [-0.98055416  0.818887    0.0144638  ...  0.99999815 -1.\n",
            "   0.9914743 ]\n",
            " ...\n",
            " [-0.93817985  0.73715776  0.68236405 ...  0.99999744 -1.\n",
            "   0.9927996 ]\n",
            " [-0.9783257  -0.9999998   1.         ...  0.99999946 -1.\n",
            "   0.9853347 ]\n",
            " [-0.98729527  0.7364348  -0.2575808  ...  0.9999992  -1.\n",
            "   0.99296284]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9996105   0.9997962   0.80896854 ...  0.99999684 -1.\n",
            "   0.99662524]\n",
            " [-0.98634785  0.9913609   0.96417403 ...  0.99999964 -1.\n",
            "   0.9954902 ]\n",
            " [-0.9978491   0.99495673  0.94202465 ...  0.99999684 -1.\n",
            "   0.99558973]\n",
            " ...\n",
            " [-0.90930504 -1.          1.         ...  0.9999998  -1.\n",
            "   0.9077184 ]\n",
            " [-0.97220474 -1.          1.         ...  0.99999976 -1.\n",
            "   0.99202585]\n",
            " [-0.96684104 -1.          1.         ...  0.999999   -1.\n",
            "   0.94394815]], shape=(428, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.994224   -0.99930173  1.         ...  0.9999987  -1.\n",
            "   0.98536086]\n",
            " [-0.99678785 -1.          1.         ...  0.9999991  -1.\n",
            "   0.9860435 ]\n",
            " [-0.98528796 -1.          1.         ...  0.9999962  -1.\n",
            "   0.9917437 ]\n",
            " ...\n",
            " [-0.9872165  -0.999998    1.         ...  0.9999971  -1.\n",
            "   0.98450726]\n",
            " [-0.99908364 -0.99999696  1.         ...  0.99999917 -1.\n",
            "   0.96855676]\n",
            " [-0.99622136 -1.          1.         ...  0.9999998  -1.\n",
            "   0.9770816 ]], shape=(366, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97920454  0.696947   -0.9025078  ...  0.99999726 -1.\n",
            "   0.99751997]\n",
            " [-0.91437924 -0.9999851   1.         ...  0.9999998  -1.\n",
            "   0.99359274]\n",
            " [-0.9984947   0.99887186  0.13156548 ...  0.999999   -1.\n",
            "   0.9954329 ]\n",
            " ...\n",
            " [-0.9759336  -1.          1.         ...  0.9999981  -1.\n",
            "   0.9800819 ]\n",
            " [-0.97426045 -1.          1.         ...  0.9999999  -1.\n",
            "   0.982573  ]\n",
            " [-0.9919383  -1.          1.         ...  0.9999999  -1.\n",
            "   0.989498  ]], shape=(351, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.934199    0.8929776   0.52273804 ...  0.99999875 -1.\n",
            "   0.98998463]\n",
            " [-0.9885796   0.80128855 -0.78938395 ...  0.9999964  -1.\n",
            "   0.99262375]\n",
            " [-0.99582446  0.94307995 -0.67615324 ...  0.99999696 -1.\n",
            "   0.9956116 ]\n",
            " ...\n",
            " [-0.9559197  -1.          1.         ...  0.9999992  -1.\n",
            "   0.9916469 ]\n",
            " [-0.9807724  -1.          1.         ...  0.9999955  -1.\n",
            "   0.9531597 ]\n",
            " [-0.9641459  -1.          1.         ...  0.9999966  -1.\n",
            "   0.9910291 ]], shape=(348, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99830264 -1.          1.         ...  0.9999993  -1.\n",
            "   0.9870503 ]\n",
            " [-0.99719626 -1.          1.         ...  0.9999986  -1.\n",
            "   0.98778844]\n",
            " [-0.99738765 -1.          1.         ...  0.99999887 -1.\n",
            "   0.98363733]\n",
            " ...\n",
            " [-0.9788658  -0.99541426  1.         ...  0.9999976  -1.\n",
            "   0.9861263 ]\n",
            " [-0.9887952  -1.          1.         ...  0.9999993  -1.\n",
            "   0.99020404]\n",
            " [-0.98903924 -1.          1.         ...  0.99999684 -1.\n",
            "   0.9631476 ]], shape=(340, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97147816  0.9419791   0.97093445 ...  0.99999976 -1.\n",
            "   0.99226516]\n",
            " [-0.99814177 -1.          1.         ...  0.9999981  -1.\n",
            "   0.9902562 ]\n",
            " [-0.99502164  0.82669777 -0.68855995 ...  0.99999857 -1.\n",
            "   0.99370885]\n",
            " ...\n",
            " [-0.99889046  0.99936986 -0.5690724  ...  0.9999937  -1.\n",
            "   0.99639857]\n",
            " [-0.9995087  -0.9995365   1.         ...  0.9999942  -1.\n",
            "   0.9969286 ]\n",
            " [-0.99543166  0.9668814   0.73395413 ...  0.9999993  -1.\n",
            "   0.99183583]], shape=(369, 128), dtype=float32)\n",
            "batch number:  70 \tgen loss:  5.7231545\n",
            "tf.Tensor(\n",
            "[[-0.9902148   0.6879184   0.9999103  ...  0.99999684 -1.\n",
            "   0.9953611 ]\n",
            " [-0.9943022   0.7944208  -0.7732658  ...  0.9999999  -1.\n",
            "   0.9918328 ]\n",
            " [-0.99898535 -1.          1.         ...  0.9999991  -1.\n",
            "   0.98429585]\n",
            " ...\n",
            " [-0.9930565   0.9843028   0.8737211  ...  0.9999975  -1.\n",
            "   0.98992646]\n",
            " [-0.9910924   0.9992115   0.9205505  ...  0.9999997  -1.\n",
            "   0.99264365]\n",
            " [-0.9414702   0.8506187   0.47180057 ...  0.9999982  -1.\n",
            "   0.9923947 ]], shape=(411, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9123215  -1.          1.         ...  0.9999995  -1.\n",
            "   0.9922368 ]\n",
            " [-0.98774165 -0.9999994   1.         ...  0.9999999  -1.\n",
            "   0.9929226 ]\n",
            " [-0.99379563  0.9965125   0.9034807  ...  0.9999993  -1.\n",
            "   0.991467  ]\n",
            " ...\n",
            " [-0.9903896   0.9799993   0.8526818  ...  0.99999917 -1.\n",
            "   0.98944944]\n",
            " [-0.9993689   0.99998224 -0.38192198 ...  0.9999981  -1.\n",
            "   0.99397117]\n",
            " [-0.9779627   0.8817567   0.5692054  ...  0.9999985  -1.\n",
            "   0.9890163 ]], shape=(421, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96087384  0.96361303  0.6701363  ...  0.99999976 -1.\n",
            "   0.9909633 ]\n",
            " [-0.9782363   0.91260993  0.01794099 ...  0.99999726 -1.\n",
            "   0.9951332 ]\n",
            " [-0.9865002   0.99910283  0.5885219  ...  0.9999998  -1.\n",
            "   0.98717654]\n",
            " ...\n",
            " [-0.98982453 -1.          1.         ...  0.9999994  -1.\n",
            "   0.9301766 ]\n",
            " [-0.9912999  -1.          1.         ...  0.99999964 -1.\n",
            "   0.9863443 ]\n",
            " [-0.9920089  -1.          1.         ...  0.9999999  -1.\n",
            "   0.9760643 ]], shape=(360, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.999636    0.9970615   0.521436   ...  0.9999999  -1.\n",
            "   0.9915424 ]\n",
            " [-0.9882506   0.972697    0.66300195 ...  0.9999897  -1.\n",
            "   0.9943956 ]\n",
            " [-0.9997756   0.9999364   0.9286228  ...  0.99999976 -1.\n",
            "   0.99228334]\n",
            " ...\n",
            " [-0.997379    0.9942332   0.64865255 ...  0.99999344 -1.\n",
            "   0.9931774 ]\n",
            " [-0.9216204   0.82077587  0.5911183  ...  0.9999961  -1.\n",
            "   0.9890477 ]\n",
            " [-0.9530995  -0.9987904   1.         ...  0.99999595 -1.\n",
            "   0.9781858 ]], shape=(402, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99049604 -1.          1.         ...  0.99998987 -1.\n",
            "   0.95818245]\n",
            " [-0.99726784  0.88479453  0.26935473 ...  0.99999857 -1.\n",
            "   0.9966703 ]\n",
            " [-0.97946745 -1.          1.         ...  0.9999984  -1.\n",
            "   0.98533714]\n",
            " ...\n",
            " [-0.99912286  0.99328655 -0.1084114  ...  0.99999356 -1.\n",
            "   0.9908306 ]\n",
            " [-0.9971054  -1.          1.         ...  0.99999607 -1.\n",
            "   0.9878729 ]\n",
            " [-0.99910086  0.7031323   0.99975187 ...  0.99999845 -1.\n",
            "   0.9927248 ]], shape=(427, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9812802  -0.96385497  1.         ...  0.9999999  -1.\n",
            "   0.97572047]\n",
            " [-0.9737621   0.94431216  0.6583649  ...  0.9999979  -1.\n",
            "   0.9888415 ]\n",
            " [-0.93034697  0.6007324  -0.49493206 ...  0.99999905 -1.\n",
            "   0.9954905 ]\n",
            " ...\n",
            " [-0.9933726   0.96995896  0.86730814 ...  0.99999964 -1.\n",
            "   0.992074  ]\n",
            " [-0.9980983   0.99956834  0.6974832  ...  0.9999967  -1.\n",
            "   0.983787  ]\n",
            " [-0.964085   -0.99997854  1.         ...  0.9999992  -1.\n",
            "   0.9889305 ]], shape=(408, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99793726 -1.          1.         ...  0.99999964 -1.\n",
            "   0.9909891 ]\n",
            " [-0.9666453  -1.          1.         ...  0.99999934 -1.\n",
            "   0.9516611 ]\n",
            " [-0.9890289  -0.99999994  1.         ...  0.9999995  -1.\n",
            "   0.9904664 ]\n",
            " ...\n",
            " [-0.9990095   0.99778247 -0.45044923 ...  0.9999981  -1.\n",
            "   0.9949726 ]\n",
            " [-0.96444654 -1.          1.         ...  0.9999972  -1.\n",
            "   0.88101095]\n",
            " [-0.9382956  -1.          1.         ...  0.9999967  -1.\n",
            "   0.5801041 ]], shape=(329, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9973669  -1.          1.         ...  0.9999957  -1.\n",
            "   0.77854526]\n",
            " [-0.9699396  -1.          1.         ...  0.99999714 -1.\n",
            "   0.58921283]\n",
            " [-0.77258223 -1.          1.         ...  0.9999995  -1.\n",
            "   0.98753273]\n",
            " ...\n",
            " [-0.970377    0.6863048  -0.91647226 ...  0.9999977  -1.\n",
            "   0.9910269 ]\n",
            " [-0.9945583   0.8213504  -0.75311303 ...  0.9999993  -1.\n",
            "   0.99204504]\n",
            " [-0.9625973   0.29421842  0.99997693 ...  0.99999875 -1.\n",
            "   0.9937243 ]], shape=(402, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9952828   0.9415368   0.4672586  ...  0.9999995  -1.\n",
            "   0.992857  ]\n",
            " [-0.9979942   0.99226564  0.70196855 ...  0.99999994 -1.\n",
            "   0.9879186 ]\n",
            " [-0.9993211   0.9999716   0.79015326 ...  0.9999993  -1.\n",
            "   0.98792785]\n",
            " ...\n",
            " [-0.9988892  -0.9999729   1.         ...  0.9999985  -1.\n",
            "   0.97801876]\n",
            " [-0.9967732  -1.          1.         ...  0.9999987  -1.\n",
            "   0.98859495]\n",
            " [-0.8849148   0.867903    0.29599428 ...  0.99999845 -1.\n",
            "   0.9919341 ]], shape=(390, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9704129   0.94775355 -0.6707439  ...  0.99999565 -1.\n",
            "   0.9903116 ]\n",
            " [-0.99708855  0.99898094  0.54042774 ...  0.9999981  -1.\n",
            "   0.99287087]\n",
            " [-0.9944516  -1.          1.         ...  0.99999887 -1.\n",
            "   0.9605919 ]\n",
            " ...\n",
            " [-0.99585724  0.9271527   0.49055132 ...  0.9999988  -1.\n",
            "   0.9859619 ]\n",
            " [-0.9891398   0.8681119   0.47329816 ...  0.9999991  -1.\n",
            "   0.99384046]\n",
            " [-0.99497354  0.9380737   0.55564475 ...  0.9999969  -1.\n",
            "   0.9857039 ]], shape=(368, 128), dtype=float32)\n",
            "batch number:  80 \tgen loss:  5.831484\n",
            "tf.Tensor(\n",
            "[[-0.93658113  0.88445175  0.51857704 ...  0.9999984  -1.\n",
            "   0.9903789 ]\n",
            " [-0.9908562   0.7131313  -0.91316885 ...  0.9999998  -1.\n",
            "   0.99302024]\n",
            " [-0.947167    0.8302806  -0.5864026  ...  0.999999   -1.\n",
            "   0.989629  ]\n",
            " ...\n",
            " [-0.99783057  0.99219507  0.7442438  ...  0.99999696 -1.\n",
            "   0.9639276 ]\n",
            " [-0.9992091   0.99951845  0.43132797 ...  0.99999946 -1.\n",
            "   0.98905915]\n",
            " [-0.9991773   0.99028635  0.40991813 ...  0.9999988  -1.\n",
            "   0.9649628 ]], shape=(393, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9930361  -0.9536719   1.         ...  0.9999996  -1.\n",
            "   0.9926246 ]\n",
            " [-0.9998403   0.9999693  -0.2773442  ...  0.99999917 -1.\n",
            "   0.98714936]\n",
            " [-0.9993316   0.99224275  0.9062354  ...  0.9999998  -1.\n",
            "   0.9903957 ]\n",
            " ...\n",
            " [-0.998649   -1.          1.         ...  0.99999917 -1.\n",
            "   0.991218  ]\n",
            " [-0.92525667 -0.9999969   1.         ...  0.9999998  -1.\n",
            "   0.9738048 ]\n",
            " [-0.9781599   0.9349298  -0.17375621 ...  0.99999845 -1.\n",
            "   0.9926514 ]], shape=(419, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.977866    0.80321205 -0.6428827  ...  0.99999917 -1.\n",
            "   0.98809004]\n",
            " [-0.9985385   0.9995834   0.252581   ...  0.9999978  -1.\n",
            "   0.98671734]\n",
            " [-0.9969737  -1.          1.         ...  0.9999992  -1.\n",
            "   0.9802251 ]\n",
            " ...\n",
            " [-0.9981716  -0.9943721   1.         ...  0.9999961  -1.\n",
            "   0.99440295]\n",
            " [-0.988049   -1.          1.         ...  0.9999993  -1.\n",
            "   0.9859932 ]\n",
            " [-0.995782   -1.          1.         ...  0.9999987  -1.\n",
            "   0.99134433]], shape=(357, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9993817   0.9999448  -0.44082353 ...  0.9999991  -1.\n",
            "   0.9949884 ]\n",
            " [-0.99792105 -1.          1.         ...  0.99999875 -1.\n",
            "   0.891259  ]\n",
            " [-0.9986297   0.9991182   0.8485483  ...  1.         -1.\n",
            "   0.9623798 ]\n",
            " ...\n",
            " [-0.9984914  -1.          1.         ...  0.9999977  -1.\n",
            "   0.92158365]\n",
            " [-0.9972535   0.9025775   0.67595124 ...  0.99999946 -1.\n",
            "   0.9911361 ]\n",
            " [-0.9993521   0.9964489  -0.8396758  ...  0.9999993  -1.\n",
            "   0.99039686]], shape=(390, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9287217  -1.          1.         ...  0.9999996  -1.\n",
            "   0.98944026]\n",
            " [-0.99529076 -1.          1.         ...  0.9999997  -1.\n",
            "   0.98863846]\n",
            " [-0.99897164  0.8384666  -0.84553677 ...  0.99999756 -1.\n",
            "   0.9908805 ]\n",
            " ...\n",
            " [-0.98294455  0.8945699   0.855141   ...  0.9999993  -1.\n",
            "   0.98930573]\n",
            " [-0.9985981  -1.          1.         ...  0.99999785 -1.\n",
            "   0.9826435 ]\n",
            " [-0.97539204  0.82867575 -0.8142739  ...  0.99999845 -1.\n",
            "   0.9942565 ]], shape=(467, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99975705  0.99993145  0.8114475  ...  0.99999994 -1.\n",
            "   0.97960675]\n",
            " [-0.9719273   0.8316755  -0.07882426 ...  0.9999969  -1.\n",
            "   0.9851171 ]\n",
            " [-0.9946239   0.9996842   0.8741486  ...  0.99999994 -1.\n",
            "   0.99011844]\n",
            " ...\n",
            " [-0.99748147  0.9966701  -0.43256256 ...  0.9999996  -1.\n",
            "   0.9941349 ]\n",
            " [-0.9994084   0.999255    0.34934694 ...  0.99999976 -1.\n",
            "   0.95623416]\n",
            " [-0.94669855  0.7068899  -0.7397279  ...  0.9999998  -1.\n",
            "   0.9925124 ]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98756933  0.9096673   0.27472785 ...  0.9999997  -1.\n",
            "   0.98785746]\n",
            " [-0.99976563  0.9996266  -0.64000493 ...  0.99999905 -1.\n",
            "   0.99444574]\n",
            " [-0.99823004  0.99638236  0.7298319  ...  0.9999997  -1.\n",
            "   0.9911748 ]\n",
            " ...\n",
            " [-0.9995261   0.9997781   0.5852328  ...  0.9999983  -1.\n",
            "   0.9936894 ]\n",
            " [-0.99750364  0.7909144  -0.94302225 ...  0.99999696 -1.\n",
            "   0.99337053]\n",
            " [-0.96434957  0.94843763  0.8080259  ...  0.9999976  -1.\n",
            "   0.9918599 ]], shape=(426, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99588025 -1.          1.         ...  0.99999976 -1.\n",
            "   0.9845663 ]\n",
            " [-0.98623085 -1.          1.         ...  0.99999756 -1.\n",
            "   0.9789135 ]\n",
            " [-0.9966389  -1.          1.         ...  0.9999993  -1.\n",
            "   0.9802894 ]\n",
            " ...\n",
            " [-0.986129   -1.          1.         ...  0.9999973  -1.\n",
            "   0.93469095]\n",
            " [-0.9988543  -0.9999713   1.         ...  0.9999992  -1.\n",
            "   0.9834092 ]\n",
            " [-0.9852769  -0.9999983   1.         ...  0.9999992  -1.\n",
            "   0.98444754]], shape=(368, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98635185 -1.          1.         ...  0.9999992  -1.\n",
            "   0.9864795 ]\n",
            " [-0.9981635  -1.          1.         ...  0.99999994 -1.\n",
            "   0.9829906 ]\n",
            " [-0.9929294  -1.          1.         ...  0.99999934 -1.\n",
            "   0.97840923]\n",
            " ...\n",
            " [-0.99542975 -1.          1.         ...  0.9999981  -1.\n",
            "   0.98843753]\n",
            " [-0.98735064 -1.          1.         ...  0.9999995  -1.\n",
            "   0.9886649 ]\n",
            " [-0.9927032  -1.          1.         ...  0.9999991  -1.\n",
            "   0.9813134 ]], shape=(403, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96598077 -0.9989173   1.         ...  0.9999999  -1.\n",
            "   0.98474234]\n",
            " [-0.9999682   0.9999967  -0.33994845 ...  0.9999984  -1.\n",
            "   0.9952688 ]\n",
            " [-0.9998217   0.99997014 -0.5660856  ...  0.9999996  -1.\n",
            "   0.98694354]\n",
            " ...\n",
            " [-0.99477595 -1.          1.         ...  0.9999982  -1.\n",
            "   0.87365377]\n",
            " [-0.98472166 -1.          1.         ...  0.99999845 -1.\n",
            "   0.97867703]\n",
            " [-0.9948003  -1.          1.         ...  0.9999936  -1.\n",
            "   0.94784117]], shape=(373, 128), dtype=float32)\n",
            "batch number:  90 \tgen loss:  5.9101853\n",
            "tf.Tensor(\n",
            "[[-0.9970843  -0.9994688   1.         ...  0.99999887 -1.\n",
            "   0.990274  ]\n",
            " [-0.9999035   0.9999832  -0.35619918 ...  0.9999978  -1.\n",
            "   0.9899924 ]\n",
            " [-0.99310094  0.9828635   0.64861274 ...  0.999999   -1.\n",
            "   0.9853795 ]\n",
            " ...\n",
            " [-0.9747138   0.8548095   0.6371575  ...  0.99999917 -1.\n",
            "   0.996488  ]\n",
            " [-0.9767877  -1.          1.         ...  0.999999   -1.\n",
            "   0.9738721 ]\n",
            " [-0.98640263 -1.          1.         ...  0.9999998  -1.\n",
            "   0.96740985]], shape=(326, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9917619  -1.          1.         ...  0.99999857 -1.\n",
            "   0.95087487]\n",
            " [-0.99823886  0.99283284  0.57381344 ...  0.9999998  -1.\n",
            "   0.9889435 ]\n",
            " [-0.99375314 -0.9999999   1.         ...  0.9999996  -1.\n",
            "   0.99127686]\n",
            " ...\n",
            " [-0.99770653  0.784348   -0.928035   ...  0.99999946 -1.\n",
            "   0.99512076]\n",
            " [-0.9723168   0.2975768   1.         ...  0.9999989  -1.\n",
            "   0.9856729 ]\n",
            " [-0.9057442   0.9641219   0.7371053  ...  0.9999992  -1.\n",
            "   0.9906145 ]], shape=(332, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9776223  -0.9999997   1.         ...  0.99999535 -1.\n",
            "   0.99137354]\n",
            " [-0.9994506   0.9999111   0.9665849  ...  0.99999756 -1.\n",
            "   0.99123806]\n",
            " [-0.99919707  0.9994553   0.9111189  ...  0.9999942  -1.\n",
            "   0.9856418 ]\n",
            " ...\n",
            " [-0.9679624   0.6473889  -0.9186334  ...  0.9999992  -1.\n",
            "   0.9948954 ]\n",
            " [-0.9922034  -0.99994165  1.         ...  0.99999976 -1.\n",
            "   0.98725337]\n",
            " [-0.9504346   0.99916     0.6344746  ...  0.99999964 -1.\n",
            "   0.9911571 ]], shape=(342, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9980368  -1.          1.         ...  0.9999996  -1.\n",
            "   0.9745211 ]\n",
            " [-0.9812435  -0.999352    1.         ...  0.99999905 -1.\n",
            "   0.9874614 ]\n",
            " [-0.9846728  -1.          1.         ...  0.9999992  -1.\n",
            "   0.93527216]\n",
            " ...\n",
            " [-0.8160377  -1.          1.         ...  0.99999857 -1.\n",
            "   0.9628047 ]\n",
            " [-0.89259064 -1.          1.         ...  0.9999924  -1.\n",
            "   0.96998733]\n",
            " [-0.9864978  -1.          1.         ...  0.9999997  -1.\n",
            "   0.98879623]], shape=(425, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9875674  -1.          1.         ...  0.99999946 -1.\n",
            "   0.9876293 ]\n",
            " [-0.99699116 -0.9999997   1.         ...  0.9999991  -1.\n",
            "   0.9846066 ]\n",
            " [-0.98799276 -1.          1.         ...  0.99999714 -1.\n",
            "   0.96760994]\n",
            " ...\n",
            " [-0.92862844  0.8450122   0.6531254  ...  0.9999912  -1.\n",
            "   0.98824626]\n",
            " [-0.94261646  0.7361319  -0.6360217  ...  0.9999983  -1.\n",
            "   0.9882088 ]\n",
            " [-0.9209819   0.74918014  0.6843781  ...  0.99999875 -1.\n",
            "   0.98237914]], shape=(392, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99740875 -1.          1.         ...  0.999996   -1.\n",
            "   0.9924829 ]\n",
            " [-0.9972365  -1.          1.         ...  0.99999213 -1.\n",
            "   0.9483085 ]\n",
            " [-0.96069056 -1.          1.         ...  0.9999958  -1.\n",
            "   0.9316975 ]\n",
            " ...\n",
            " [-0.9987922  -0.99999976  1.         ...  0.9999997  -1.\n",
            "   0.9873227 ]\n",
            " [-0.99430007  0.9916884   0.8474468  ...  0.9999983  -1.\n",
            "   0.9823637 ]\n",
            " [-0.9890209   0.99858963  0.76883507 ...  0.9999991  -1.\n",
            "   0.9869712 ]], shape=(369, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9973268  -0.9997775   1.         ...  0.99999887 -1.\n",
            "   0.9828518 ]\n",
            " [-0.92423165  0.7656557   0.45117185 ...  0.9999997  -1.\n",
            "   0.98589844]\n",
            " [-0.9748018  -0.9999979   1.         ...  0.9999993  -1.\n",
            "   0.9893708 ]\n",
            " ...\n",
            " [-0.9934785  -1.          1.         ...  0.9999974  -1.\n",
            "   0.98110723]\n",
            " [-0.9988298   0.9944881   0.5969035  ...  0.99999976 -1.\n",
            "   0.98851246]\n",
            " [-0.99425244  0.9723921   0.84303665 ...  0.9999996  -1.\n",
            "   0.98215556]], shape=(393, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99868304  0.8489614  -0.7697278  ...  0.9999992  -1.\n",
            "   0.98679876]\n",
            " [-0.99982613  0.9999742   0.81076545 ...  0.99999166 -1.\n",
            "   0.9925733 ]\n",
            " [-0.9635665   0.75597256 -0.4448464  ...  0.99999946 -1.\n",
            "   0.990589  ]\n",
            " ...\n",
            " [-0.993158   -1.          1.         ...  0.9999988  -1.\n",
            "   0.98739433]\n",
            " [-0.9963619  -1.          1.         ...  0.9999872  -1.\n",
            "   0.98955053]\n",
            " [-0.9262431  -0.9990261   1.         ...  0.99999833 -1.\n",
            "   0.9888438 ]], shape=(390, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96308404 -1.          1.         ...  0.99999887 -1.\n",
            "   0.9389486 ]\n",
            " [-0.998058    0.99366695  0.8585762  ...  0.9999982  -1.\n",
            "   0.99439853]\n",
            " [-0.9973519  -0.63174826  1.         ...  0.9999995  -1.\n",
            "   0.98913157]\n",
            " ...\n",
            " [-0.97096795 -0.92608255  1.         ...  0.9999991  -1.\n",
            "   0.9924786 ]\n",
            " [-0.9989941  -0.99650455  1.         ...  0.9999985  -1.\n",
            "   0.98718965]\n",
            " [-0.9989145   0.999531    0.71283484 ...  0.9999999  -1.\n",
            "   0.98806053]], shape=(372, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9946916  -1.          1.         ...  0.9999944  -1.\n",
            "   0.9887115 ]\n",
            " [-0.99715644 -1.          1.         ...  0.99999183 -1.\n",
            "   0.19002232]\n",
            " [-0.9972214  -0.99999994  1.         ...  0.99999756 -1.\n",
            "   0.99437577]\n",
            " ...\n",
            " [-0.9663057  -1.          1.         ...  0.99999875 -1.\n",
            "   0.98798513]\n",
            " [-0.9784557  -1.          1.         ...  0.99999976 -1.\n",
            "   0.95436746]\n",
            " [-0.9978412  -1.          1.         ...  0.9999991  -1.\n",
            "   0.9780573 ]], shape=(366, 128), dtype=float32)\n",
            "batch number:  100 \tgen loss:  5.7993045\n",
            "tf.Tensor(\n",
            "[[-0.9943292  -1.          1.         ...  0.999996   -1.\n",
            "   0.97167766]\n",
            " [-0.9904396  -1.          1.         ...  0.9999959  -1.\n",
            "   0.9756539 ]\n",
            " [-0.84912467 -0.9996218   1.         ...  0.999999   -1.\n",
            "   0.99042124]\n",
            " ...\n",
            " [-0.9957952   0.9954404   0.7435568  ...  0.9999981  -1.\n",
            "   0.9954756 ]\n",
            " [-0.9967921   0.97408587  0.5832949  ...  0.9999986  -1.\n",
            "   0.99349856]\n",
            " [-0.9934466   0.9962727   0.7750506  ...  0.9999991  -1.\n",
            "   0.99474424]], shape=(368, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98204064 -1.          1.         ...  0.9999991  -1.\n",
            "   0.98872375]\n",
            " [-0.99688995  0.94735056  0.89830333 ...  0.9999998  -1.\n",
            "   0.9862101 ]\n",
            " [-0.9854487   0.96915567  0.8739274  ...  0.99999887 -1.\n",
            "   0.99122584]\n",
            " ...\n",
            " [-0.9940054  -1.          1.         ...  0.99999905 -1.\n",
            "   0.984489  ]\n",
            " [-0.9961864   0.98927444  0.8367815  ...  0.9999987  -1.\n",
            "   0.989757  ]\n",
            " [-0.98330086  0.99962556  0.94700557 ...  0.9999988  -1.\n",
            "   0.99388176]], shape=(395, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9831518  -0.9999984   1.         ...  0.9999984  -1.\n",
            "   0.987774  ]\n",
            " [-0.9988043  -0.9999973   1.         ...  0.99999887 -1.\n",
            "   0.9771803 ]\n",
            " [-0.99891937 -0.9999859   1.         ...  0.9999984  -1.\n",
            "   0.9888363 ]\n",
            " ...\n",
            " [-0.9912317  -1.          1.         ...  0.99999964 -1.\n",
            "   0.87676615]\n",
            " [-0.9783074  -0.98906994  1.         ...  0.9999996  -1.\n",
            "   0.98540235]\n",
            " [-0.99259543 -0.9999954   1.         ...  0.9999996  -1.\n",
            "   0.98523057]], shape=(373, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99214876 -0.80463964  1.         ...  0.9999993  -1.\n",
            "   0.98156625]\n",
            " [-0.99548995 -1.          1.         ...  0.99999946 -1.\n",
            "   0.88437957]\n",
            " [-0.99471074 -1.          1.         ...  0.9999997  -1.\n",
            "   0.9648928 ]\n",
            " ...\n",
            " [-0.9996399   0.9984371   0.7859338  ...  0.99999964 -1.\n",
            "   0.99146   ]\n",
            " [-0.9695007   0.76326185 -0.5717726  ...  0.9999985  -1.\n",
            "   0.98833686]\n",
            " [-0.99805135  0.9997729  -0.13337746 ...  0.99999744 -1.\n",
            "   0.98678267]], shape=(409, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.98015267  0.8239462   0.48663923 ...  0.9999985  -1.\n",
            "   0.9936136 ]\n",
            " [-0.95074403  0.8056851   0.5539523  ...  0.99999803 -1.\n",
            "   0.99105895]\n",
            " [-0.98300153  0.9694898   0.7973166  ...  0.99999857 -1.\n",
            "   0.9915849 ]\n",
            " ...\n",
            " [-0.99738365  0.99892634  0.72356844 ...  0.99999803 -1.\n",
            "   0.9877083 ]\n",
            " [-0.9792402   0.92519194 -0.63528323 ...  0.9999983  -1.\n",
            "   0.97325975]\n",
            " [-0.9495995   0.9502645  -0.5552508  ...  0.9999922  -1.\n",
            "   0.9943022 ]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9967993  -0.9999918   1.         ...  0.9999997  -1.\n",
            "   0.9835231 ]\n",
            " [-0.99354076 -0.99995077  1.         ...  0.9999991  -1.\n",
            "   0.9815503 ]\n",
            " [-0.9982023  -1.          1.         ...  0.99999946 -1.\n",
            "   0.9419877 ]\n",
            " ...\n",
            " [-0.9926299   0.9542706   0.8046905  ...  0.9999895  -1.\n",
            "   0.9898616 ]\n",
            " [-0.96611935  0.7880362   0.5964111  ...  0.99999154 -1.\n",
            "   0.9944046 ]\n",
            " [-0.99961716  0.9987724   0.23528004 ...  0.99999887 -1.\n",
            "   0.98863906]], shape=(432, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9677367  -1.          1.         ...  0.99999994 -1.\n",
            "   0.97984874]\n",
            " [-0.9994009   0.9976233   0.5710019  ...  0.99999845 -1.\n",
            "   0.99376374]\n",
            " [-0.994783   -1.          1.         ...  0.9999971  -1.\n",
            "   0.87505716]\n",
            " ...\n",
            " [-0.9899532  -0.9996314   1.         ...  0.9999991  -1.\n",
            "   0.98644906]\n",
            " [-0.9832446   0.8600724  -0.03444428 ...  0.9999989  -1.\n",
            "   0.9888807 ]\n",
            " [-0.98373127 -1.          1.         ...  0.9999971  -1.\n",
            "   0.7657494 ]], shape=(364, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9908612  -0.9948773   1.         ...  0.999998   -1.\n",
            "   0.9881435 ]\n",
            " [-0.99057525 -1.          1.         ...  0.99999124 -1.\n",
            "   0.8315795 ]\n",
            " [-0.97680646  0.8755928   0.6039582  ...  0.99999946 -1.\n",
            "   0.9697435 ]\n",
            " ...\n",
            " [-0.95402765 -0.9942826   1.         ...  0.9999999  -1.\n",
            "   0.9852511 ]\n",
            " [-0.9988954  -0.9999982   1.         ...  0.99999964 -1.\n",
            "   0.97138333]\n",
            " [-0.9996403  -0.90385956  1.         ...  0.9999979  -1.\n",
            "   0.9876377 ]], shape=(377, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99613696  0.7658581   0.5156911  ...  0.9999941  -1.\n",
            "   0.98294187]\n",
            " [-0.87893414 -1.          1.         ...  0.9999986  -1.\n",
            "   0.9547469 ]\n",
            " [-0.9932011   0.9847598  -0.37611055 ...  0.99999785 -1.\n",
            "   0.97604126]\n",
            " ...\n",
            " [-0.9770756   0.69258064 -0.73284477 ...  0.99999964 -1.\n",
            "   0.9873674 ]\n",
            " [-0.8322039   0.75197417  0.5953004  ...  0.99999887 -1.\n",
            "   0.9787914 ]\n",
            " [-0.9955423   0.997506    0.3177059  ...  0.9999986  -1.\n",
            "   0.9744996 ]], shape=(323, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9510371  -0.987381    1.         ...  0.9999888  -1.\n",
            "   0.9776099 ]\n",
            " [-0.9924581  -0.99999946  1.         ...  0.99999905 -1.\n",
            "   0.9859879 ]\n",
            " [-0.9856703   0.9450511   0.7866278  ...  0.9999996  -1.\n",
            "   0.98793054]\n",
            " ...\n",
            " [-0.9867798  -0.9816354   1.         ...  0.9999972  -1.\n",
            "   0.98708504]\n",
            " [-0.9973755  -0.9998971   1.         ...  0.99999875 -1.\n",
            "   0.9873385 ]\n",
            " [-0.97883844 -0.9999036   1.         ...  0.99999774 -1.\n",
            "   0.9611025 ]], shape=(421, 128), dtype=float32)\n",
            "batch number:  110 \tgen loss:  5.8487263\n",
            "tf.Tensor(\n",
            "[[-0.9949151  -0.99999994  1.         ...  0.9999957  -1.\n",
            "   0.92692876]\n",
            " [-0.97598565 -1.          1.         ...  0.9999972  -1.\n",
            "   0.94185245]\n",
            " [-0.9987935  -0.9999989   1.         ...  0.99999577 -1.\n",
            "   0.9780987 ]\n",
            " ...\n",
            " [-0.99950683  0.9966847  -0.67934686 ...  0.9999949  -1.\n",
            "   0.9839465 ]\n",
            " [-0.99664223  0.7657996  -0.78792685 ...  0.9999991  -1.\n",
            "   0.98164207]\n",
            " [-0.9969587   0.82093096 -0.9392706  ...  0.99999994 -1.\n",
            "   0.99207366]], shape=(371, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9923477  -0.55507946  1.         ...  0.9999978  -1.\n",
            "   0.98800665]\n",
            " [-0.9793047  -1.          1.         ...  0.9999982  -1.\n",
            "   0.20725429]\n",
            " [-0.9975479  -0.99999994  1.         ...  0.9999955  -1.\n",
            "   0.8117935 ]\n",
            " ...\n",
            " [-0.9996226  -0.10467728  1.         ...  1.         -1.\n",
            "   0.9913304 ]\n",
            " [-0.99243706 -0.75313574  1.         ...  0.9999995  -1.\n",
            "   0.9897832 ]\n",
            " [-0.999809    0.9988595  -0.86015344 ...  0.9999998  -1.\n",
            "   0.99517435]], shape=(337, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.975787    0.8509208  -0.75126296 ...  0.9999994  -1.\n",
            "   0.98046863]\n",
            " [-0.97566074  0.8507582  -0.74996287 ...  0.9999992  -1.\n",
            "   0.99012107]\n",
            " [-0.98043954 -0.99999994  1.         ...  0.99999905 -1.\n",
            "   0.9844253 ]\n",
            " ...\n",
            " [-0.99898946 -0.99999964  1.         ...  0.9999986  -1.\n",
            "   0.23701672]\n",
            " [-0.9952261   0.9539978   0.71540123 ...  0.999999   -1.\n",
            "   0.9948967 ]\n",
            " [-0.99591064 -1.          1.         ...  0.99999964 -1.\n",
            "   0.9472012 ]], shape=(338, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9964539  -0.9912169   1.         ...  0.9999942  -1.\n",
            "   0.9885832 ]\n",
            " [-0.9987016   0.9925787  -0.4676334  ...  0.999999   -1.\n",
            "   0.98810565]\n",
            " [-0.9628257   0.81775475  0.27629545 ...  0.99999934 -1.\n",
            "   0.98575205]\n",
            " ...\n",
            " [-0.99669373 -0.9999964   1.         ...  0.99999654 -1.\n",
            "   0.98311645]\n",
            " [-0.9881596  -1.          1.         ...  0.99999887 -1.\n",
            "   0.9331163 ]\n",
            " [-0.99543405 -0.99999994  1.         ...  0.9999969  -1.\n",
            "   0.953487  ]], shape=(378, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99157387 -0.89655006  1.         ...  0.9999998  -1.\n",
            "   0.98676485]\n",
            " [-0.9998362   0.9999541   0.67965984 ...  0.9999964  -1.\n",
            "   0.9925982 ]\n",
            " [-0.9986863   0.9909879   0.9999322  ...  0.9999979  -1.\n",
            "   0.9927854 ]\n",
            " ...\n",
            " [-0.9953989  -0.3696453   1.         ...  0.99999934 -1.\n",
            "   0.9871761 ]\n",
            " [-0.9998887   0.9999905   0.95433044 ...  0.9999982  -1.\n",
            "   0.98762774]\n",
            " [-0.97453344  0.7192728   0.3013326  ...  0.99999803 -1.\n",
            "   0.9870516 ]], shape=(364, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9998066   0.9998913  -0.6522929  ...  0.9999984  -1.\n",
            "   0.988446  ]\n",
            " [-0.9970557   0.9761731   0.74313366 ...  0.99999887 -1.\n",
            "   0.9838259 ]\n",
            " [-0.9698222   0.9717256   0.78920734 ...  0.9999985  -1.\n",
            "   0.98375326]\n",
            " ...\n",
            " [-0.9989446   0.9919058   0.3313527  ...  0.99999905 -1.\n",
            "   0.9930848 ]\n",
            " [-0.9990546  -0.99999905  1.         ...  0.99999976 -1.\n",
            "   0.845485  ]\n",
            " [-0.9967958  -0.99122155  1.         ...  0.9999988  -1.\n",
            "   0.9620844 ]], shape=(334, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96660614  0.81478906 -0.5763075  ...  0.99999976 -1.\n",
            "   0.9884562 ]\n",
            " [-0.9623981   0.598606   -0.8884487  ...  0.99999905 -1.\n",
            "   0.98406047]\n",
            " [-0.99560744 -0.9991295   1.         ...  0.9999999  -1.\n",
            "   0.994007  ]\n",
            " ...\n",
            " [-0.9889102   0.68753076 -0.6688528  ...  0.99999994 -1.\n",
            "   0.99174666]\n",
            " [-0.886595    0.7322223   0.30370238 ...  0.99999946 -1.\n",
            "   0.9859568 ]\n",
            " [-0.9943513   0.9615538   0.6793644  ...  0.9999999  -1.\n",
            "   0.99091905]], shape=(391, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9880287   0.8214624  -0.74457127 ...  0.99999774 -1.\n",
            "   0.98267275]\n",
            " [-0.9897866   0.824877   -0.54394406 ...  0.99999833 -1.\n",
            "   0.9873658 ]\n",
            " [-0.9695233   0.8406127  -0.74608237 ...  0.999999   -1.\n",
            "   0.98775005]\n",
            " ...\n",
            " [-0.9774431  -0.99999994  1.         ...  0.99999887 -1.\n",
            "   0.9756509 ]\n",
            " [-0.9903458   0.81285554 -0.69723254 ...  0.9999996  -1.\n",
            "   0.9836421 ]\n",
            " [-0.99291974 -0.999854    1.         ...  0.9999989  -1.\n",
            "   0.98611337]], shape=(421, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.999733    0.9997617   0.81534165 ...  0.9999996  -1.\n",
            "   0.98823464]\n",
            " [-0.9794844  -0.98931354  1.         ...  0.99999976 -1.\n",
            "   0.98509705]\n",
            " [-0.9798358  -0.8036388   1.         ...  0.99999976 -1.\n",
            "   0.9856744 ]\n",
            " ...\n",
            " [-0.99345535  0.9727809   0.48965538 ...  0.9999978  -1.\n",
            "   0.9936424 ]\n",
            " [-0.96614337  0.820393   -0.7829887  ...  0.9999959  -1.\n",
            "   0.99210703]\n",
            " [-0.9947382   0.94776124  0.28486684 ...  0.99999607 -1.\n",
            "   0.98703074]], shape=(412, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.96656525 -0.99998856  1.         ...  0.9999996  -1.\n",
            "   0.9618853 ]\n",
            " [-0.90055424  0.3077188   0.99987656 ...  0.9999966  -1.\n",
            "   0.98171   ]\n",
            " [-0.9400419  -0.8202493   1.         ...  0.9999924  -1.\n",
            "   0.91566473]\n",
            " ...\n",
            " [-0.9983246   0.99980885  0.61162466 ...  0.9999979  -1.\n",
            "   0.9858182 ]\n",
            " [-0.999842    0.99998206  0.9143792  ...  0.9999992  -1.\n",
            "   0.9903186 ]\n",
            " [-0.9790518  -0.99729127  1.         ...  0.9999999  -1.\n",
            "   0.99442655]], shape=(397, 128), dtype=float32)\n",
            "batch number:  120 \tgen loss:  5.9106703\n",
            "tf.Tensor(\n",
            "[[-0.98163015 -0.9683861   1.         ...  0.9999974  -1.\n",
            "   0.9868045 ]\n",
            " [-0.82717896 -0.9450324   1.         ...  0.99999976 -1.\n",
            "   0.98457235]\n",
            " [-0.9901113  -0.99999964  1.         ...  0.99999964 -1.\n",
            "   0.8919083 ]\n",
            " ...\n",
            " [-0.9785785  -0.99744934  1.         ...  0.9999991  -1.\n",
            "   0.992466  ]\n",
            " [-0.9065668   0.7557946   0.29311898 ...  0.99999976 -1.\n",
            "   0.9861338 ]\n",
            " [-0.9952401  -0.7353015   1.         ...  0.9999992  -1.\n",
            "   0.9767765 ]], shape=(397, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9562799   0.8758273   0.6886645  ...  0.9999981  -1.\n",
            "   0.9551977 ]\n",
            " [-0.9914047   0.98621124  0.7453421  ...  0.9999994  -1.\n",
            "   0.9867203 ]\n",
            " [-0.99979013  0.9997706   0.30856544 ...  0.9999983  -1.\n",
            "   0.98129046]\n",
            " ...\n",
            " [-0.99985015  0.9999737   0.80642176 ...  0.9999998  -1.\n",
            "   0.98534954]\n",
            " [-0.9862139   0.9433075   0.7212615  ...  0.99999845 -1.\n",
            "   0.9874008 ]\n",
            " [-0.9117984   0.6773714  -0.73919946 ...  0.99999785 -1.\n",
            "   0.98731065]], shape=(372, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9632221   0.86561346  0.67463344 ...  0.9999991  -1.\n",
            "   0.9917741 ]\n",
            " [-0.9930101   0.8672224  -0.65333486 ...  0.99999964 -1.\n",
            "   0.9852368 ]\n",
            " [-0.99913424  0.8880251  -0.8861261  ...  0.9999998  -1.\n",
            "   0.98482126]\n",
            " ...\n",
            " [-0.99658513 -0.93242973  1.         ...  1.         -1.\n",
            "   0.99448335]\n",
            " [-0.9984529  -0.14179265  1.         ...  0.9999999  -1.\n",
            "   0.9856162 ]\n",
            " [-0.99346495 -0.99999654  1.         ...  0.9999987  -1.\n",
            "   0.90500563]], shape=(335, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.97429633  0.97576225  0.8705858  ...  0.9999999  -1.\n",
            "   0.9803799 ]\n",
            " [-0.97667265  0.85516924  0.33761156 ...  0.9999964  -1.\n",
            "   0.98228586]\n",
            " [-0.9942493   0.9703586   0.7298163  ...  0.9999998  -1.\n",
            "   0.98976344]\n",
            " ...\n",
            " [-0.95387405  0.75801677 -0.4733798  ...  0.9999996  -1.\n",
            "   0.9904183 ]\n",
            " [-0.9490026   0.8856871   0.3214923  ...  0.9999995  -1.\n",
            "   0.9863336 ]\n",
            " [-0.9999075   0.9998682  -0.76555884 ...  0.9999879  -1.\n",
            "   0.9866578 ]], shape=(359, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9988408   0.90960586 -0.7773683  ...  0.9999995  -1.\n",
            "   0.98679   ]\n",
            " [-0.95151794  0.9238648   0.77195203 ...  0.9999999  -1.\n",
            "   0.9885394 ]\n",
            " [-0.9949832   0.9444723  -0.87115556 ...  0.9999996  -1.\n",
            "   0.98968816]\n",
            " ...\n",
            " [-0.97641426 -0.9995916   1.         ...  0.99999696 -1.\n",
            "   0.9842529 ]\n",
            " [-0.9961722  -0.9993761   1.         ...  0.9999942  -1.\n",
            "   0.97793823]\n",
            " [-0.993039   -0.9998487   1.         ...  0.9999943  -1.\n",
            "   0.9761134 ]], shape=(383, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.9965827   0.7996524   1.         ...  0.9999982  -1.\n",
            "   0.9850657 ]\n",
            " [-0.9936507  -0.99987346  1.         ...  0.99999386 -1.\n",
            "   0.97792286]\n",
            " [-0.9969701   0.9869177   0.8946116  ...  0.9999946  -1.\n",
            "   0.9866612 ]\n",
            " ...\n",
            " [-0.9931989   0.8631745  -0.924067   ...  0.9999991  -1.\n",
            "   0.9856975 ]\n",
            " [-0.9962054  -0.9995692   1.         ...  0.99999887 -1.\n",
            "   0.97802424]\n",
            " [-0.97641903  0.91764504 -0.29716808 ...  0.99999803 -1.\n",
            "   0.9882616 ]], shape=(343, 128), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.99559444 -0.9965215   1.         ...  0.9999976  -1.\n",
            "   0.968835  ]\n",
            " [-0.9999134   0.9999852   0.2884637  ...  0.9999994  -1.\n",
            "   0.98744524]\n",
            " [-0.98097056 -0.7564177   1.         ...  0.9999999  -1.\n",
            "   0.99018085]\n",
            " ...\n",
            " [-0.9061382  -0.67184854  1.         ...  0.9999996  -1.\n",
            "   0.98641634]\n",
            " [-0.9880414   0.9811448   0.8867302  ...  0.9999994  -1.\n",
            "   0.9670878 ]\n",
            " [-0.9592144   0.82743835  0.28519928 ...  0.9999978  -1.\n",
            "   0.9876479 ]], shape=(402, 128), dtype=float32)\n",
            "\n",
            "\n",
            "Adversarial Train:\n",
            "batch number:  0 \t\tgen loss:  0.032167435 \t\t\tdisc loss:  0.59302855\n",
            "batch number:  5 \t\tgen loss:  0.9813829 \t\t\tdisc loss:  0.11284007\n",
            "batch number:  10 \t\tgen loss:  0.084745936 \t\t\tdisc loss:  0.15361275\n",
            "batch number:  15 \t\tgen loss:  1.1460099 \t\t\tdisc loss:  0.116801865\n",
            "batch number:  20 \t\tgen loss:  0.14407794 \t\t\tdisc loss:  0.09193149\n",
            "batch number:  25 \t\tgen loss:  0.05933724 \t\t\tdisc loss:  0.08541489\n",
            "batch number:  30 \t\tgen loss:  0.31983456 \t\t\tdisc loss:  0.083944164\n",
            "batch number:  35 \t\tgen loss:  0.20380831 \t\t\tdisc loss:  0.07369456\n",
            "batch number:  40 \t\tgen loss:  0.09931828 \t\t\tdisc loss:  0.06798893\n",
            "batch number:  45 \t\tgen loss:  0.09996814 \t\t\tdisc loss:  0.064822234\n",
            "batch number:  50 \t\tgen loss:  0.11887012 \t\t\tdisc loss:  0.058976404\n",
            "batch number:  55 \t\tgen loss:  0.13417177 \t\t\tdisc loss:  0.06325576\n",
            "batch number:  60 \t\tgen loss:  0.111327566 \t\t\tdisc loss:  0.053928405\n",
            "\n",
            "\n",
            "Generator Test:\n",
            "batch number:  0 \tgen loss:  10.075433\n",
            "batch number:  5 \tgen loss:  10.030376\n",
            "batch number:  10 \tgen loss:  10.031879\n",
            "batch number:  15 \tgen loss:  10.0264225\n",
            "Saved checkpoint for epoch 3: ./tf_ckpts/ckpt-3\n",
            "\n",
            "\n",
            "epoch :  3\n",
            "********************************************* PMF Model Training Turn *********************************************\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_85875/561035493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_85875/2058565689.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"********************************************* PMF Model Training Turn *********************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n******************************************* Seq2Seq Model Training Turn *******************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_85875/1808774704.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mdw_Item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ItemID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mIx_Item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     \u001b[0mdw_User\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_UserID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mIx_User\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# Update with momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mint32\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mint64\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \"\"\"\n\u001b[0;32m--> 984\u001b[0;31m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m   \u001b[0;31m# TODO(wangpeng): Consider supporting var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_style_slicing\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m       \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/colabenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;34m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mones_rank_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mt_model.train(n_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ploting Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 65307), started 0:00:06 ago. (Use '!kill 65307' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-85a14894ac20d60f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-85a14894ac20d60f\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs\n",
        "# deactive tracking protection of the page if you get 403 error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xniWi24qcZsb"
      },
      "source": [
        "# test code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85ryd-vJrTix"
      },
      "outputs": [],
      "source": [
        "#log_ps, mse_train, mse_test= pm.train(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4meEBmwsqMYC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# dec_result,dec_state=decoder(dec_output_tokens,dec_output_tokens,context_vector= user_context_vector,state=dec_state)\n",
        "# sampled_token = tf.random.categorical(dec_result[:,-1, :], num_samples=1)\n",
        "# print( sampled_token.numpy())\n",
        "# dec_output_tokens=np.append( dec_output_tokens , sampled_token.numpy()[0])\n",
        "# print(dec_output_tokens)\n",
        "\n",
        "# vocab = np.array(input_text_processor.get_vocabulary())\n",
        "# first_word = vocab[dec_output_tokens]\n",
        "# first_word"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Explainable Recommender System.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('colabenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5859fc1fd51a29bc96a6c335b5cef2533de774a99a73e1484108bae0d11f06ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
